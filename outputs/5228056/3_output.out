####################
/var/spool/slurmd/job5259821/slurm_script
####################
--batch-size 64 --exc train --goal-reset False --model-id TRITON_QWEN_7B --model-quant fp16 --num-eval 100 --prompt-file llm_prompt_binary_rewards_zero_shot.yaml --reward-type llm --rollout-steps 2048 --text-verbosity True --total-timesteps 1000000 --train-episode-time-limit 360 --train-fps 10 --train-render-fps 120 --train-verbosity True
####################

Metadata saved to src/FM3_MicRo/control_models/2025-01-22_04-50-18_llm_triton_qwen_7b_binary_rewards_zero_shot_1000000-steps_5-obs_ep-time-360.0/metadata.txt
Contextual prompt is:
You are provided description of a 2D workspace where location of each point can be represented as (x, y) where 'x' is the x-axis co-ordinate while 'y' is the y-axis co-ordinate. The center of the workspace is at (0,0) and the top-right corner is at (360,360).
 
 You need to critique the actions of the particle. You will be provided with the goal position, the previous position of the particle and the new position of the particle. If the particle moves in the direction of the goal, you assign a score of 1. If the particle either moves away from the goal or does not move closer to the goal, you assign a score of 0.
 
 You must only output either a 0 or 1. Do not output any other text in your reponse. Do not output any code or explanation.

Using cpu device
-----------------------------
| time/              |      |
|    fps             | 9    |
|    iterations      | 1    |
|    time_elapsed    | 211  |
|    total_timesteps | 2048 |
-----------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.6e+03     |
|    ep_rew_mean          | 1.31e+03    |
| time/                   |             |
|    fps                  | 9           |
|    iterations           | 2           |
|    time_elapsed         | 417         |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.009428844 |
|    clip_fraction        | 0.114       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.162      |
|    learning_rate        | 0.0003      |
|    loss                 | 14.6        |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.0158     |
|    std                  | 0.995       |
|    value_loss           | 33.9        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.6e+03     |
|    ep_rew_mean          | 1.31e+03    |
| time/                   |             |
|    fps                  | 9           |
|    iterations           | 3           |
|    time_elapsed         | 622         |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.010682829 |
|    clip_fraction        | 0.126       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.574       |
|    learning_rate        | 0.0003      |
|    loss                 | 14.4        |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0202     |
|    std                  | 0.995       |
|    value_loss           | 34.1        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.59e+03    |
|    ep_rew_mean          | 1.37e+03    |
| time/                   |             |
|    fps                  | 9           |
|    iterations           | 4           |
|    time_elapsed         | 827         |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.009639614 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.717       |
|    learning_rate        | 0.0003      |
|    loss                 | 13.4        |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.021      |
|    std                  | 0.995       |
|    value_loss           | 33.4        |
-----------------------------------------
Eval num_timesteps=10000, episode_reward=-99.91 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.007852198 |
|    clip_fraction        | 0.0704      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.737       |
|    learning_rate        | 0.0003      |
|    loss                 | 12          |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0167     |
|    std                  | 0.996       |
|    value_loss           | 30          |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.15e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 5        |
|    time_elapsed    | 2833     |
|    total_timesteps | 10240    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 1.15e+03     |
| time/                   |              |
|    fps                  | 4            |
|    iterations           | 6            |
|    time_elapsed         | 3039         |
|    total_timesteps      | 12288        |
| train/                  |              |
|    approx_kl            | 0.0027133508 |
|    clip_fraction        | 0.00195      |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | 0.018        |
|    learning_rate        | 0.0003       |
|    loss                 | 800          |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.00425     |
|    std                  | 0.996        |
|    value_loss           | 1.04e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.4e+03     |
|    ep_rew_mean          | 1.27e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 7           |
|    time_elapsed         | 3244        |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.008537439 |
|    clip_fraction        | 0.0727      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.749       |
|    learning_rate        | 0.0003      |
|    loss                 | 15.3        |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.016      |
|    std                  | 0.995       |
|    value_loss           | 30.4        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.4e+03      |
|    ep_rew_mean          | 1.27e+03     |
| time/                   |              |
|    fps                  | 4            |
|    iterations           | 8            |
|    time_elapsed         | 3450         |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0068979566 |
|    clip_fraction        | 0.0543       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | 0.567        |
|    learning_rate        | 0.0003       |
|    loss                 | 6.37         |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.0133      |
|    std                  | 0.996        |
|    value_loss           | 26.6         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.44e+03     |
|    ep_rew_mean          | 1.37e+03     |
| time/                   |              |
|    fps                  | 5            |
|    iterations           | 9            |
|    time_elapsed         | 3655         |
|    total_timesteps      | 18432        |
| train/                  |              |
|    approx_kl            | 0.0072229644 |
|    clip_fraction        | 0.0429       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | 0.597        |
|    learning_rate        | 0.0003       |
|    loss                 | 6.07         |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.0131      |
|    std                  | 0.996        |
|    value_loss           | 27.3         |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-99.92 +/- 0.06
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.008463022 |
|    clip_fraction        | 0.0615      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.425       |
|    learning_rate        | 0.0003      |
|    loss                 | 7.49        |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.0117     |
|    std                  | 0.994       |
|    value_loss           | 22.7        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.32e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 10       |
|    time_elapsed    | 5662     |
|    total_timesteps | 20480    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.32e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 11          |
|    time_elapsed         | 5867        |
|    total_timesteps      | 22528       |
| train/                  |             |
|    approx_kl            | 0.009169731 |
|    clip_fraction        | 0.0692      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.00269     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.73e+03    |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.00948    |
|    std                  | 0.994       |
|    value_loss           | 1.07e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.37e+03    |
|    ep_rew_mean          | 1.41e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 12          |
|    time_elapsed         | 6072        |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.008949786 |
|    clip_fraction        | 0.0834      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.743       |
|    learning_rate        | 0.0003      |
|    loss                 | 5.12        |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.0134     |
|    std                  | 0.994       |
|    value_loss           | 11.3        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.37e+03    |
|    ep_rew_mean          | 1.41e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 13          |
|    time_elapsed         | 6278        |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.009657634 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.832       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.85        |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0167     |
|    std                  | 0.992       |
|    value_loss           | 12.8        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.4e+03    |
|    ep_rew_mean          | 1.47e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 14         |
|    time_elapsed         | 6483       |
|    total_timesteps      | 28672      |
| train/                  |            |
|    approx_kl            | 0.01521393 |
|    clip_fraction        | 0.152      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.3      |
|    explained_variance   | 0.54       |
|    learning_rate        | 0.0003     |
|    loss                 | 1.9        |
|    n_updates            | 130        |
|    policy_gradient_loss | -0.0109    |
|    std                  | 0.993      |
|    value_loss           | 7.32       |
----------------------------------------
Eval num_timesteps=30000, episode_reward=-100.02 +/- 0.02
Episode length: 3597.00 +/- 6.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 30000       |
| train/                  |             |
|    approx_kl            | 0.018525068 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.173       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.06        |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.00752    |
|    std                  | 0.991       |
|    value_loss           | 4.37        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.43e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 15       |
|    time_elapsed    | 8490     |
|    total_timesteps | 30720    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.43e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 16          |
|    time_elapsed         | 8695        |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.002880691 |
|    clip_fraction        | 0.0104      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.00962     |
|    learning_rate        | 0.0003      |
|    loss                 | 9.38        |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.00156    |
|    std                  | 0.991       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.36e+03     |
|    ep_rew_mean          | 1.5e+03      |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 17           |
|    time_elapsed         | 8901         |
|    total_timesteps      | 34816        |
| train/                  |              |
|    approx_kl            | 0.0146034155 |
|    clip_fraction        | 0.248        |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | -0.191       |
|    learning_rate        | 0.0003       |
|    loss                 | 0.872        |
|    n_updates            | 160          |
|    policy_gradient_loss | -0.00795     |
|    std                  | 0.992        |
|    value_loss           | 2.39         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 1.5e+03     |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 18          |
|    time_elapsed         | 9106        |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.010523338 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.577       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.4         |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.0109     |
|    std                  | 0.992       |
|    value_loss           | 7.65        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.38e+03    |
|    ep_rew_mean          | 1.56e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 19          |
|    time_elapsed         | 9311        |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.014801509 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.325      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.753       |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.0146     |
|    std                  | 0.982       |
|    value_loss           | 2.89        |
-----------------------------------------
Eval num_timesteps=40000, episode_reward=-100.04 +/- 0.03
Episode length: 3597.40 +/- 7.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 40000       |
| train/                  |             |
|    approx_kl            | 0.011367025 |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.549       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.898       |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.0126     |
|    std                  | 0.98        |
|    value_loss           | 3.01        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.53e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 20       |
|    time_elapsed    | 11320    |
|    total_timesteps | 40960    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 1.53e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 21           |
|    time_elapsed         | 11529        |
|    total_timesteps      | 43008        |
| train/                  |              |
|    approx_kl            | 0.0018342031 |
|    clip_fraction        | 0.00278      |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.2        |
|    explained_variance   | 0.0329       |
|    learning_rate        | 0.0003       |
|    loss                 | 319          |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.00106     |
|    std                  | 0.98         |
|    value_loss           | 1.06e+03     |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.35e+03   |
|    ep_rew_mean          | 1.57e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 22         |
|    time_elapsed         | 11734      |
|    total_timesteps      | 45056      |
| train/                  |            |
|    approx_kl            | 0.01656629 |
|    clip_fraction        | 0.229      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.2      |
|    explained_variance   | -0.0259    |
|    learning_rate        | 0.0003     |
|    loss                 | 1          |
|    n_updates            | 210        |
|    policy_gradient_loss | -0.00755   |
|    std                  | 0.982      |
|    value_loss           | 2.26       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.35e+03  |
|    ep_rew_mean          | 1.57e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 23        |
|    time_elapsed         | 11940     |
|    total_timesteps      | 47104     |
| train/                  |           |
|    approx_kl            | 0.0044433 |
|    clip_fraction        | 0.0208    |
|    clip_range           | 0.2       |
|    entropy_loss         | -11.2     |
|    explained_variance   | 0.621     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.27      |
|    n_updates            | 220       |
|    policy_gradient_loss | -0.00421  |
|    std                  | 0.982     |
|    value_loss           | 10.4      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.37e+03    |
|    ep_rew_mean          | 1.61e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 24          |
|    time_elapsed         | 12145       |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.008767277 |
|    clip_fraction        | 0.0349      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.68        |
|    learning_rate        | 0.0003      |
|    loss                 | 1.25        |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.00679    |
|    std                  | 0.982       |
|    value_loss           | 8.98        |
-----------------------------------------
Eval num_timesteps=50000, episode_reward=-99.96 +/- 0.04
Episode length: 3600.80 +/- 0.40
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 3.6e+03      |
|    mean_reward          | -100         |
| time/                   |              |
|    total_timesteps      | 50000        |
| train/                  |              |
|    approx_kl            | 0.0061777467 |
|    clip_fraction        | 0.0212       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.2        |
|    explained_variance   | 0.654        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.26         |
|    n_updates            | 240          |
|    policy_gradient_loss | -0.00668     |
|    std                  | 0.982        |
|    value_loss           | 9.1          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.58e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 25       |
|    time_elapsed    | 14151    |
|    total_timesteps | 51200    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.58e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 26          |
|    time_elapsed         | 14356       |
|    total_timesteps      | 53248       |
| train/                  |             |
|    approx_kl            | 0.009479023 |
|    clip_fraction        | 0.0963      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.000395    |
|    learning_rate        | 0.0003      |
|    loss                 | 741         |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.0058     |
|    std                  | 0.981       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.63e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 27          |
|    time_elapsed         | 14562       |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.018583883 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.352      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.622       |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.00936    |
|    std                  | 0.97        |
|    value_loss           | 1.91        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.36e+03     |
|    ep_rew_mean          | 1.66e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 28           |
|    time_elapsed         | 14767        |
|    total_timesteps      | 57344        |
| train/                  |              |
|    approx_kl            | 0.0040719816 |
|    clip_fraction        | 0.0475       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.1        |
|    explained_variance   | 0.57         |
|    learning_rate        | 0.0003       |
|    loss                 | 13.9         |
|    n_updates            | 270          |
|    policy_gradient_loss | -0.00249     |
|    std                  | 0.97         |
|    value_loss           | 22           |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 1.66e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 29          |
|    time_elapsed         | 14973       |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.017656822 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.669       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.56        |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.00384    |
|    std                  | 0.969       |
|    value_loss           | 8.86        |
-----------------------------------------
Eval num_timesteps=60000, episode_reward=-99.96 +/- 0.05
Episode length: 3597.20 +/- 7.11
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 60000       |
| train/                  |             |
|    approx_kl            | 0.015166202 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.573       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.881       |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.00632    |
|    std                  | 0.967       |
|    value_loss           | 3.58        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.64e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 30       |
|    time_elapsed    | 16979    |
|    total_timesteps | 61440    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 1.64e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 31           |
|    time_elapsed         | 17185        |
|    total_timesteps      | 63488        |
| train/                  |              |
|    approx_kl            | 0.0026645213 |
|    clip_fraction        | 0.0171       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.1        |
|    explained_variance   | 0.0169       |
|    learning_rate        | 0.0003       |
|    loss                 | 870          |
|    n_updates            | 300          |
|    policy_gradient_loss | -0.00282     |
|    std                  | 0.967        |
|    value_loss           | 1.05e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.67e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 32          |
|    time_elapsed         | 17390       |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.014526854 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.00446    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.839       |
|    n_updates            | 310         |
|    policy_gradient_loss | -0.00709    |
|    std                  | 0.965       |
|    value_loss           | 1.66        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.36e+03   |
|    ep_rew_mean          | 1.7e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 33         |
|    time_elapsed         | 17596      |
|    total_timesteps      | 67584      |
| train/                  |            |
|    approx_kl            | 0.01078755 |
|    clip_fraction        | 0.0842     |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.1      |
|    explained_variance   | 0.573      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.12       |
|    n_updates            | 320        |
|    policy_gradient_loss | -0.00844   |
|    std                  | 0.964      |
|    value_loss           | 4.1        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 1.7e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 34          |
|    time_elapsed         | 17801       |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.018151138 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.13        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.916       |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.0151     |
|    std                  | 0.957       |
|    value_loss           | 1.67        |
-----------------------------------------
Eval num_timesteps=70000, episode_reward=-99.97 +/- 0.03
Episode length: 3596.40 +/- 7.79
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 70000       |
| train/                  |             |
|    approx_kl            | 0.015062427 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.119       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.818       |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.0124     |
|    std                  | 0.948       |
|    value_loss           | 1.81        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.68e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 35       |
|    time_elapsed    | 19812    |
|    total_timesteps | 71680    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 36          |
|    time_elapsed         | 20019       |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 0.004861201 |
|    clip_fraction        | 0.0598      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.116       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.09e+03    |
|    n_updates            | 350         |
|    policy_gradient_loss | 0.000275    |
|    std                  | 0.948       |
|    value_loss           | 1.07e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 37          |
|    time_elapsed         | 20224       |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 0.023051504 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.702      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.594       |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.0129     |
|    std                  | 0.947       |
|    value_loss           | 1.45        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 1.73e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 38          |
|    time_elapsed         | 20429       |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.012361435 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.319      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.807       |
|    n_updates            | 370         |
|    policy_gradient_loss | -0.0112     |
|    std                  | 0.944       |
|    value_loss           | 2.19        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.36e+03   |
|    ep_rew_mean          | 1.73e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 39         |
|    time_elapsed         | 20635      |
|    total_timesteps      | 79872      |
| train/                  |            |
|    approx_kl            | 0.01437711 |
|    clip_fraction        | 0.15       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.9      |
|    explained_variance   | 0.522      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.72       |
|    n_updates            | 380        |
|    policy_gradient_loss | -0.00879   |
|    std                  | 0.942      |
|    value_loss           | 3.54       |
----------------------------------------
Eval num_timesteps=80000, episode_reward=-99.95 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 80000       |
| train/                  |             |
|    approx_kl            | 0.016963547 |
|    clip_fraction        | 0.227       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.0892      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.764       |
|    n_updates            | 390         |
|    policy_gradient_loss | -0.00653    |
|    std                  | 0.934       |
|    value_loss           | 1.54        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.72e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 40       |
|    time_elapsed    | 22641    |
|    total_timesteps | 81920    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.75e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 41          |
|    time_elapsed         | 22846       |
|    total_timesteps      | 83968       |
| train/                  |             |
|    approx_kl            | 0.006356514 |
|    clip_fraction        | 0.0777      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.0245      |
|    learning_rate        | 0.0003      |
|    loss                 | 10.8        |
|    n_updates            | 400         |
|    policy_gradient_loss | -0.0018     |
|    std                  | 0.933       |
|    value_loss           | 1.01e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.75e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 42          |
|    time_elapsed         | 23054       |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.006657938 |
|    clip_fraction        | 0.04        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.654       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.47        |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.005      |
|    std                  | 0.933       |
|    value_loss           | 20.2        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.77e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 43          |
|    time_elapsed         | 23262       |
|    total_timesteps      | 88064       |
| train/                  |             |
|    approx_kl            | 0.022496134 |
|    clip_fraction        | 0.296       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.226      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.2         |
|    n_updates            | 420         |
|    policy_gradient_loss | -0.00772    |
|    std                  | 0.928       |
|    value_loss           | 2.15        |
-----------------------------------------
Eval num_timesteps=90000, episode_reward=-99.98 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 90000       |
| train/                  |             |
|    approx_kl            | 0.012614714 |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.729       |
|    learning_rate        | 0.0003      |
|    loss                 | 8.33        |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.000761   |
|    std                  | 0.927       |
|    value_loss           | 16          |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.75e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 44       |
|    time_elapsed    | 25269    |
|    total_timesteps | 90112    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.75e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 45          |
|    time_elapsed         | 25474       |
|    total_timesteps      | 92160       |
| train/                  |             |
|    approx_kl            | 0.001658449 |
|    clip_fraction        | 0.0062      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.029       |
|    learning_rate        | 0.0003      |
|    loss                 | 10.1        |
|    n_updates            | 440         |
|    policy_gradient_loss | -0.00122    |
|    std                  | 0.927       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.77e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 46          |
|    time_elapsed         | 25680       |
|    total_timesteps      | 94208       |
| train/                  |             |
|    approx_kl            | 0.016688392 |
|    clip_fraction        | 0.232       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.018      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.06        |
|    n_updates            | 450         |
|    policy_gradient_loss | -0.00729    |
|    std                  | 0.924       |
|    value_loss           | 1.91        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.77e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 47          |
|    time_elapsed         | 25885       |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 0.014427781 |
|    clip_fraction        | 0.12        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.908       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.23        |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.00263    |
|    std                  | 0.925       |
|    value_loss           | 7.97        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.8e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 48          |
|    time_elapsed         | 26090       |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.017869638 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.0294      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.77        |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.00763    |
|    std                  | 0.925       |
|    value_loss           | 1.74        |
-----------------------------------------
Eval num_timesteps=100000, episode_reward=-99.97 +/- 0.05
Episode length: 3598.80 +/- 3.49
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 100000      |
| train/                  |             |
|    approx_kl            | 0.012700816 |
|    clip_fraction        | 0.128       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.481       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.711       |
|    n_updates            | 480         |
|    policy_gradient_loss | -0.00485    |
|    std                  | 0.924       |
|    value_loss           | 6.18        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.78e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 49       |
|    time_elapsed    | 28098    |
|    total_timesteps | 100352   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 1.78e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 50           |
|    time_elapsed         | 28304        |
|    total_timesteps      | 102400       |
| train/                  |              |
|    approx_kl            | 0.0030058858 |
|    clip_fraction        | 0.0238       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.7        |
|    explained_variance   | 0.0464       |
|    learning_rate        | 0.0003       |
|    loss                 | 2.59e+03     |
|    n_updates            | 490          |
|    policy_gradient_loss | -0.00019     |
|    std                  | 0.924        |
|    value_loss           | 1.05e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.8e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 51          |
|    time_elapsed         | 28509       |
|    total_timesteps      | 104448      |
| train/                  |             |
|    approx_kl            | 0.021363597 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.385      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.715       |
|    n_updates            | 500         |
|    policy_gradient_loss | -0.00707    |
|    std                  | 0.915       |
|    value_loss           | 1.6         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.8e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 52          |
|    time_elapsed         | 28715       |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.013856738 |
|    clip_fraction        | 0.166       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.063       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.2         |
|    n_updates            | 510         |
|    policy_gradient_loss | -0.0102     |
|    std                  | 0.912       |
|    value_loss           | 2.78        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.82e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 53          |
|    time_elapsed         | 28920       |
|    total_timesteps      | 108544      |
| train/                  |             |
|    approx_kl            | 0.013014152 |
|    clip_fraction        | 0.139       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.696       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.09        |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.00726    |
|    std                  | 0.913       |
|    value_loss           | 3.53        |
-----------------------------------------
Eval num_timesteps=110000, episode_reward=-99.92 +/- 0.03
Episode length: 3597.40 +/- 7.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 110000     |
| train/                  |            |
|    approx_kl            | 0.01975657 |
|    clip_fraction        | 0.287      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | 0.0607     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.583      |
|    n_updates            | 530        |
|    policy_gradient_loss | -0.00359   |
|    std                  | 0.908      |
|    value_loss           | 1.55       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.81e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 54       |
|    time_elapsed    | 30928    |
|    total_timesteps | 110592   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.81e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 55         |
|    time_elapsed         | 31135      |
|    total_timesteps      | 112640     |
| train/                  |            |
|    approx_kl            | 0.01034363 |
|    clip_fraction        | 0.148      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | -0.00182   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.14e+03   |
|    n_updates            | 540        |
|    policy_gradient_loss | 0.000654   |
|    std                  | 0.908      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.83e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 56          |
|    time_elapsed         | 31341       |
|    total_timesteps      | 114688      |
| train/                  |             |
|    approx_kl            | 0.026559027 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.032      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.689       |
|    n_updates            | 550         |
|    policy_gradient_loss | -0.00367    |
|    std                  | 0.901       |
|    value_loss           | 1.08        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.83e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 57          |
|    time_elapsed         | 31546       |
|    total_timesteps      | 116736      |
| train/                  |             |
|    approx_kl            | 0.016202953 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.313       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.52        |
|    n_updates            | 560         |
|    policy_gradient_loss | -0.00237    |
|    std                  | 0.898       |
|    value_loss           | 2.38        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.85e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 58          |
|    time_elapsed         | 31751       |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.019894216 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.103       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.926       |
|    n_updates            | 570         |
|    policy_gradient_loss | -0.00766    |
|    std                  | 0.895       |
|    value_loss           | 1.9         |
-----------------------------------------
Eval num_timesteps=120000, episode_reward=-99.87 +/- 0.04
Episode length: 3600.40 +/- 1.20
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 3.6e+03      |
|    mean_reward          | -99.9        |
| time/                   |              |
|    total_timesteps      | 120000       |
| train/                  |              |
|    approx_kl            | 0.0123037705 |
|    clip_fraction        | 0.126        |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.4        |
|    explained_variance   | 0.812        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.38         |
|    n_updates            | 580          |
|    policy_gradient_loss | -0.00726     |
|    std                  | 0.894        |
|    value_loss           | 3.74         |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.84e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 59       |
|    time_elapsed    | 33759    |
|    total_timesteps | 120832   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.84e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 60         |
|    time_elapsed         | 33964      |
|    total_timesteps      | 122880     |
| train/                  |            |
|    approx_kl            | 0.01546555 |
|    clip_fraction        | 0.0461     |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | -0.000579  |
|    learning_rate        | 0.0003     |
|    loss                 | 3.24       |
|    n_updates            | 590        |
|    policy_gradient_loss | -0.00339   |
|    std                  | 0.894      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.86e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 61          |
|    time_elapsed         | 34170       |
|    total_timesteps      | 124928      |
| train/                  |             |
|    approx_kl            | 0.022197733 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.0212     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.73        |
|    n_updates            | 600         |
|    policy_gradient_loss | -0.00446    |
|    std                  | 0.895       |
|    value_loss           | 1.39        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.86e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 62          |
|    time_elapsed         | 34375       |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.018520162 |
|    clip_fraction        | 0.161       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.771       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.32        |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.0008     |
|    std                  | 0.894       |
|    value_loss           | 6.28        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.88e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 63          |
|    time_elapsed         | 34580       |
|    total_timesteps      | 129024      |
| train/                  |             |
|    approx_kl            | 0.019573804 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.0588      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.699       |
|    n_updates            | 620         |
|    policy_gradient_loss | -0.00162    |
|    std                  | 0.895       |
|    value_loss           | 1.58        |
-----------------------------------------
Eval num_timesteps=130000, episode_reward=-99.85 +/- 0.02
Episode length: 3596.80 +/- 8.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 130000      |
| train/                  |             |
|    approx_kl            | 0.015867021 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.376       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.484       |
|    n_updates            | 630         |
|    policy_gradient_loss | -0.00715    |
|    std                  | 0.891       |
|    value_loss           | 2.05        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.87e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 64       |
|    time_elapsed    | 36588    |
|    total_timesteps | 131072   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 1.87e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 65           |
|    time_elapsed         | 36794        |
|    total_timesteps      | 133120       |
| train/                  |              |
|    approx_kl            | 0.0063795364 |
|    clip_fraction        | 0.0554       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.4        |
|    explained_variance   | 0.000258     |
|    learning_rate        | 0.0003       |
|    loss                 | 245          |
|    n_updates            | 640          |
|    policy_gradient_loss | -0.00143     |
|    std                  | 0.892        |
|    value_loss           | 1.05e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 66          |
|    time_elapsed         | 36999       |
|    total_timesteps      | 135168      |
| train/                  |             |
|    approx_kl            | 0.020347796 |
|    clip_fraction        | 0.248       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.0368     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.662       |
|    n_updates            | 650         |
|    policy_gradient_loss | -0.00107    |
|    std                  | 0.893       |
|    value_loss           | 1.47        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.35e+03   |
|    ep_rew_mean          | 1.9e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 67         |
|    time_elapsed         | 37204      |
|    total_timesteps      | 137216     |
| train/                  |            |
|    approx_kl            | 0.02550742 |
|    clip_fraction        | 0.275      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | 0.0352     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.786      |
|    n_updates            | 660        |
|    policy_gradient_loss | -0.00457   |
|    std                  | 0.888      |
|    value_loss           | 1.42       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.9e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 68          |
|    time_elapsed         | 37410       |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 0.022190094 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.0912      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.07        |
|    n_updates            | 670         |
|    policy_gradient_loss | -0.0123     |
|    std                  | 0.887       |
|    value_loss           | 1.39        |
-----------------------------------------
Eval num_timesteps=140000, episode_reward=-99.90 +/- 0.06
Episode length: 3597.60 +/- 5.43
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 140000      |
| train/                  |             |
|    approx_kl            | 0.018943805 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.0828      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.13        |
|    n_updates            | 680         |
|    policy_gradient_loss | -0.00888    |
|    std                  | 0.882       |
|    value_loss           | 1.8         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.9e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 69       |
|    time_elapsed    | 39418    |
|    total_timesteps | 141312   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.9e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 70          |
|    time_elapsed         | 39625       |
|    total_timesteps      | 143360      |
| train/                  |             |
|    approx_kl            | 0.017026154 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.00146     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.06e+03    |
|    n_updates            | 690         |
|    policy_gradient_loss | -0.00175    |
|    std                  | 0.88        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 71         |
|    time_elapsed         | 39830      |
|    total_timesteps      | 145408     |
| train/                  |            |
|    approx_kl            | 0.01920321 |
|    clip_fraction        | 0.22       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.3      |
|    explained_variance   | -0.00929   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.754      |
|    n_updates            | 700        |
|    policy_gradient_loss | -0.00381   |
|    std                  | 0.876      |
|    value_loss           | 1.5        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.93e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 72          |
|    time_elapsed         | 40036       |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.016850656 |
|    clip_fraction        | 0.23        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.0667      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.597       |
|    n_updates            | 710         |
|    policy_gradient_loss | -0.00616    |
|    std                  | 0.869       |
|    value_loss           | 1.17        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.93e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 73          |
|    time_elapsed         | 40241       |
|    total_timesteps      | 149504      |
| train/                  |             |
|    approx_kl            | 0.015362693 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.0738      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.768       |
|    n_updates            | 720         |
|    policy_gradient_loss | -0.000545   |
|    std                  | 0.863       |
|    value_loss           | 1.56        |
-----------------------------------------
Eval num_timesteps=150000, episode_reward=-99.90 +/- 0.05
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 150000      |
| train/                  |             |
|    approx_kl            | 0.019428825 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.0469      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.976       |
|    n_updates            | 730         |
|    policy_gradient_loss | -0.00664    |
|    std                  | 0.856       |
|    value_loss           | 1.42        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.92e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 74       |
|    time_elapsed    | 42248    |
|    total_timesteps | 151552   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.34e+03     |
|    ep_rew_mean          | 1.94e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 75           |
|    time_elapsed         | 42453        |
|    total_timesteps      | 153600       |
| train/                  |              |
|    approx_kl            | 0.0112462845 |
|    clip_fraction        | 0.136        |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.1        |
|    explained_variance   | -0.000412    |
|    learning_rate        | 0.0003       |
|    loss                 | 556          |
|    n_updates            | 740          |
|    policy_gradient_loss | 0.00219      |
|    std                  | 0.855        |
|    value_loss           | 1.06e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.94e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 76          |
|    time_elapsed         | 42659       |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.022224642 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -0.313      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.66        |
|    n_updates            | 750         |
|    policy_gradient_loss | -0.0074     |
|    std                  | 0.854       |
|    value_loss           | 1.35        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.96e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 77          |
|    time_elapsed         | 42865       |
|    total_timesteps      | 157696      |
| train/                  |             |
|    approx_kl            | 0.022092938 |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | 0.0665      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.527       |
|    n_updates            | 760         |
|    policy_gradient_loss | -0.00105    |
|    std                  | 0.85        |
|    value_loss           | 1.17        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.96e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 78          |
|    time_elapsed         | 43070       |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.010340019 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | 0.446       |
|    learning_rate        | 0.0003      |
|    loss                 | 18.7        |
|    n_updates            | 770         |
|    policy_gradient_loss | -0.00437    |
|    std                  | 0.849       |
|    value_loss           | 21.6        |
-----------------------------------------
Eval num_timesteps=160000, episode_reward=-99.90 +/- 0.05
Episode length: 3597.80 +/- 6.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.028845124 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | -0.0558     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.819       |
|    n_updates            | 780         |
|    policy_gradient_loss | -0.00782    |
|    std                  | 0.845       |
|    value_loss           | 1.43        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.95e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 79       |
|    time_elapsed    | 45076    |
|    total_timesteps | 161792   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.96e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 80          |
|    time_elapsed         | 45282       |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.015983839 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.97       |
|    explained_variance   | -0.000694   |
|    learning_rate        | 0.0003      |
|    loss                 | 5.06        |
|    n_updates            | 790         |
|    policy_gradient_loss | 0.0036      |
|    std                  | 0.844       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.96e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 81          |
|    time_elapsed         | 45487       |
|    total_timesteps      | 165888      |
| train/                  |             |
|    approx_kl            | 0.018054206 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.96       |
|    explained_variance   | -0.871      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.73        |
|    n_updates            | 800         |
|    policy_gradient_loss | -0.00463    |
|    std                  | 0.842       |
|    value_loss           | 3.78        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.98e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 82          |
|    time_elapsed         | 45692       |
|    total_timesteps      | 167936      |
| train/                  |             |
|    approx_kl            | 0.018861577 |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.92       |
|    explained_variance   | 0.039       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.557       |
|    n_updates            | 810         |
|    policy_gradient_loss | 0.00273     |
|    std                  | 0.837       |
|    value_loss           | 1.4         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.98e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 83          |
|    time_elapsed         | 45898       |
|    total_timesteps      | 169984      |
| train/                  |             |
|    approx_kl            | 0.012309735 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.9        |
|    explained_variance   | 0.851       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.5         |
|    n_updates            | 820         |
|    policy_gradient_loss | 0.000165    |
|    std                  | 0.837       |
|    value_loss           | 6.43        |
-----------------------------------------
Eval num_timesteps=170000, episode_reward=-99.90 +/- 0.03
Episode length: 3600.40 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 170000      |
| train/                  |             |
|    approx_kl            | 0.024409123 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.87       |
|    explained_variance   | 0.0201      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.53        |
|    n_updates            | 830         |
|    policy_gradient_loss | -0.00512    |
|    std                  | 0.832       |
|    value_loss           | 1.2         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.97e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 84       |
|    time_elapsed    | 47904    |
|    total_timesteps | 172032   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.98e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 85          |
|    time_elapsed         | 48109       |
|    total_timesteps      | 174080      |
| train/                  |             |
|    approx_kl            | 0.009982837 |
|    clip_fraction        | 0.0984      |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.85       |
|    explained_variance   | 0.0204      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.49        |
|    n_updates            | 840         |
|    policy_gradient_loss | -0.00409    |
|    std                  | 0.832       |
|    value_loss           | 928         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.98e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 86          |
|    time_elapsed         | 48314       |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.022786118 |
|    clip_fraction        | 0.155       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.85       |
|    explained_variance   | 0.87        |
|    learning_rate        | 0.0003      |
|    loss                 | 3           |
|    n_updates            | 850         |
|    policy_gradient_loss | -0.00107    |
|    std                  | 0.832       |
|    value_loss           | 4.49        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2e+03       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 87          |
|    time_elapsed         | 48520       |
|    total_timesteps      | 178176      |
| train/                  |             |
|    approx_kl            | 0.029009156 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.84       |
|    explained_variance   | 0.0379      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.645       |
|    n_updates            | 860         |
|    policy_gradient_loss | 0.0104      |
|    std                  | 0.829       |
|    value_loss           | 1.15        |
-----------------------------------------
Eval num_timesteps=180000, episode_reward=-99.85 +/- 0.05
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 180000      |
| train/                  |             |
|    approx_kl            | 0.025198825 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.81       |
|    explained_variance   | 0.0555      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.567       |
|    n_updates            | 870         |
|    policy_gradient_loss | -0.00213    |
|    std                  | 0.826       |
|    value_loss           | 1.14        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.99e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 88       |
|    time_elapsed    | 50526    |
|    total_timesteps | 180224   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.99e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 89          |
|    time_elapsed         | 50732       |
|    total_timesteps      | 182272      |
| train/                  |             |
|    approx_kl            | 0.020433724 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.8        |
|    explained_variance   | 0.00012     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.12e+03    |
|    n_updates            | 880         |
|    policy_gradient_loss | -0.00275    |
|    std                  | 0.826       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.01e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 90         |
|    time_elapsed         | 50941      |
|    total_timesteps      | 184320     |
| train/                  |            |
|    approx_kl            | 0.02890244 |
|    clip_fraction        | 0.252      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.78      |
|    explained_variance   | 0.0528     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.445      |
|    n_updates            | 890        |
|    policy_gradient_loss | -0.00184   |
|    std                  | 0.823      |
|    value_loss           | 1.16       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.01e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 91          |
|    time_elapsed         | 51147       |
|    total_timesteps      | 186368      |
| train/                  |             |
|    approx_kl            | 0.019650508 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.76       |
|    explained_variance   | 0.887       |
|    learning_rate        | 0.0003      |
|    loss                 | 11.9        |
|    n_updates            | 900         |
|    policy_gradient_loss | 0.00123     |
|    std                  | 0.822       |
|    value_loss           | 7.73        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.02e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 92          |
|    time_elapsed         | 51352       |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 0.026724469 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.73       |
|    explained_variance   | 0.0526      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.655       |
|    n_updates            | 910         |
|    policy_gradient_loss | 0.00478     |
|    std                  | 0.818       |
|    value_loss           | 1.26        |
-----------------------------------------
Eval num_timesteps=190000, episode_reward=-99.85 +/- 0.11
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 190000     |
| train/                  |            |
|    approx_kl            | 0.03142453 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.71      |
|    explained_variance   | 0.806      |
|    learning_rate        | 0.0003     |
|    loss                 | 11.9       |
|    n_updates            | 920        |
|    policy_gradient_loss | 0.0123     |
|    std                  | 0.817      |
|    value_loss           | 72.1       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.01e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 93       |
|    time_elapsed    | 53360    |
|    total_timesteps | 190464   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 3.33e+03      |
|    ep_rew_mean          | 2.01e+03      |
| time/                   |               |
|    fps                  | 3             |
|    iterations           | 94            |
|    time_elapsed         | 53565         |
|    total_timesteps      | 192512        |
| train/                  |               |
|    approx_kl            | 0.00090595783 |
|    clip_fraction        | 0.00112       |
|    clip_range           | 0.2           |
|    entropy_loss         | -9.71         |
|    explained_variance   | 0.531         |
|    learning_rate        | 0.0003        |
|    loss                 | 36.1          |
|    n_updates            | 930           |
|    policy_gradient_loss | -0.00231      |
|    std                  | 0.817         |
|    value_loss           | 1.07e+03      |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.01e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 95          |
|    time_elapsed         | 53770       |
|    total_timesteps      | 194560      |
| train/                  |             |
|    approx_kl            | 0.009047661 |
|    clip_fraction        | 0.0596      |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.71       |
|    explained_variance   | 0.953       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.9         |
|    n_updates            | 940         |
|    policy_gradient_loss | -0.00972    |
|    std                  | 0.818       |
|    value_loss           | 27          |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.01e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 96          |
|    time_elapsed         | 53976       |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.042011864 |
|    clip_fraction        | 0.266       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.7        |
|    explained_variance   | 0.707       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.64        |
|    n_updates            | 950         |
|    policy_gradient_loss | -0.00141    |
|    std                  | 0.814       |
|    value_loss           | 7.71        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 97          |
|    time_elapsed         | 54181       |
|    total_timesteps      | 198656      |
| train/                  |             |
|    approx_kl            | 0.040187933 |
|    clip_fraction        | 0.38        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.68       |
|    explained_variance   | -0.0133     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.497       |
|    n_updates            | 960         |
|    policy_gradient_loss | 0.0108      |
|    std                  | 0.815       |
|    value_loss           | 1.07        |
-----------------------------------------
Eval num_timesteps=200000, episode_reward=-99.73 +/- 0.12
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 200000      |
| train/                  |             |
|    approx_kl            | 0.025694668 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.64       |
|    explained_variance   | 0.0683      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.591       |
|    n_updates            | 970         |
|    policy_gradient_loss | -0.00187    |
|    std                  | 0.808       |
|    value_loss           | 1.45        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 98       |
|    time_elapsed    | 56187    |
|    total_timesteps | 200704   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.02e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 99          |
|    time_elapsed         | 56393       |
|    total_timesteps      | 202752      |
| train/                  |             |
|    approx_kl            | 0.018875774 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.61       |
|    explained_variance   | 0.000205    |
|    learning_rate        | 0.0003      |
|    loss                 | 926         |
|    n_updates            | 980         |
|    policy_gradient_loss | 0.00176     |
|    std                  | 0.807       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 100         |
|    time_elapsed         | 56598       |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.023092816 |
|    clip_fraction        | 0.267       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.59       |
|    explained_variance   | -0.00963    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.764       |
|    n_updates            | 990         |
|    policy_gradient_loss | 0.00169     |
|    std                  | 0.805       |
|    value_loss           | 1.42        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 101         |
|    time_elapsed         | 56803       |
|    total_timesteps      | 206848      |
| train/                  |             |
|    approx_kl            | 0.011286572 |
|    clip_fraction        | 0.135       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.58       |
|    explained_variance   | 0.927       |
|    learning_rate        | 0.0003      |
|    loss                 | 18.5        |
|    n_updates            | 1000        |
|    policy_gradient_loss | -8.52e-05   |
|    std                  | 0.805       |
|    value_loss           | 16.3        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.05e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 102         |
|    time_elapsed         | 57009       |
|    total_timesteps      | 208896      |
| train/                  |             |
|    approx_kl            | 0.027985431 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.55       |
|    explained_variance   | 0.044       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.764       |
|    n_updates            | 1010        |
|    policy_gradient_loss | 0.00192     |
|    std                  | 0.798       |
|    value_loss           | 1.47        |
-----------------------------------------
Eval num_timesteps=210000, episode_reward=-99.85 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 210000      |
| train/                  |             |
|    approx_kl            | 0.027767267 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.51       |
|    explained_variance   | 0.0421      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.704       |
|    n_updates            | 1020        |
|    policy_gradient_loss | -0.00739    |
|    std                  | 0.797       |
|    value_loss           | 1.34        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.04e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 103      |
|    time_elapsed    | 59015    |
|    total_timesteps | 210944   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.04e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 104         |
|    time_elapsed         | 59221       |
|    total_timesteps      | 212992      |
| train/                  |             |
|    approx_kl            | 0.020270854 |
|    clip_fraction        | 0.219       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.5        |
|    explained_variance   | 0.00029     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.55        |
|    n_updates            | 1030        |
|    policy_gradient_loss | -0.00531    |
|    std                  | 0.796       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.05e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 105         |
|    time_elapsed         | 59426       |
|    total_timesteps      | 215040      |
| train/                  |             |
|    approx_kl            | 0.023867622 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.46       |
|    explained_variance   | 0.00258     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.563       |
|    n_updates            | 1040        |
|    policy_gradient_loss | 7.73e-05    |
|    std                  | 0.791       |
|    value_loss           | 1.12        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.05e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 106         |
|    time_elapsed         | 59632       |
|    total_timesteps      | 217088      |
| train/                  |             |
|    approx_kl            | 0.025888147 |
|    clip_fraction        | 0.252       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.4        |
|    explained_variance   | 0.059       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.683       |
|    n_updates            | 1050        |
|    policy_gradient_loss | -0.00634    |
|    std                  | 0.785       |
|    value_loss           | 1.13        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.06e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 107         |
|    time_elapsed         | 59837       |
|    total_timesteps      | 219136      |
| train/                  |             |
|    approx_kl            | 0.025847102 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.37       |
|    explained_variance   | 0.0559      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.477       |
|    n_updates            | 1060        |
|    policy_gradient_loss | -0.00758    |
|    std                  | 0.784       |
|    value_loss           | 1.38        |
-----------------------------------------
Eval num_timesteps=220000, episode_reward=-99.87 +/- 0.06
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 220000      |
| train/                  |             |
|    approx_kl            | 0.028874287 |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.37       |
|    explained_variance   | 0.0269      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.827       |
|    n_updates            | 1070        |
|    policy_gradient_loss | -0.00324    |
|    std                  | 0.784       |
|    value_loss           | 1.34        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.06e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 108      |
|    time_elapsed    | 61845    |
|    total_timesteps | 221184   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.06e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 109         |
|    time_elapsed         | 62051       |
|    total_timesteps      | 223232      |
| train/                  |             |
|    approx_kl            | 0.017580312 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.37       |
|    explained_variance   | 0.0443      |
|    learning_rate        | 0.0003      |
|    loss                 | 937         |
|    n_updates            | 1080        |
|    policy_gradient_loss | 0.00313     |
|    std                  | 0.784       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.07e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 110         |
|    time_elapsed         | 62256       |
|    total_timesteps      | 225280      |
| train/                  |             |
|    approx_kl            | 0.021412874 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.37       |
|    explained_variance   | -1.19       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.619       |
|    n_updates            | 1090        |
|    policy_gradient_loss | -0.00101    |
|    std                  | 0.783       |
|    value_loss           | 1.64        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.08e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 111         |
|    time_elapsed         | 62462       |
|    total_timesteps      | 227328      |
| train/                  |             |
|    approx_kl            | 0.028435862 |
|    clip_fraction        | 0.296       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.32       |
|    explained_variance   | -0.105      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.512       |
|    n_updates            | 1100        |
|    policy_gradient_loss | -0.00752    |
|    std                  | 0.777       |
|    value_loss           | 1.05        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.08e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 112         |
|    time_elapsed         | 62667       |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.011484931 |
|    clip_fraction        | 0.122       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.3        |
|    explained_variance   | 0.916       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.47        |
|    n_updates            | 1110        |
|    policy_gradient_loss | -0.00255    |
|    std                  | 0.778       |
|    value_loss           | 4.89        |
-----------------------------------------
Eval num_timesteps=230000, episode_reward=-99.85 +/- 0.09
Episode length: 3599.60 +/- 2.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 230000      |
| train/                  |             |
|    approx_kl            | 0.014249054 |
|    clip_fraction        | 0.0931      |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.3        |
|    explained_variance   | 0.973       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.85        |
|    n_updates            | 1120        |
|    policy_gradient_loss | -0.011      |
|    std                  | 0.777       |
|    value_loss           | 8.2         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.07e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 113      |
|    time_elapsed    | 64673    |
|    total_timesteps | 231424   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.07e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 114         |
|    time_elapsed         | 64878       |
|    total_timesteps      | 233472      |
| train/                  |             |
|    approx_kl            | 0.014937529 |
|    clip_fraction        | 0.0281      |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.3        |
|    explained_variance   | 0.000237    |
|    learning_rate        | 0.0003      |
|    loss                 | 4.58        |
|    n_updates            | 1130        |
|    policy_gradient_loss | -0.000441   |
|    std                  | 0.777       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.08e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 115         |
|    time_elapsed         | 65084       |
|    total_timesteps      | 235520      |
| train/                  |             |
|    approx_kl            | 0.025346298 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.3        |
|    explained_variance   | -0.0293     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.61        |
|    n_updates            | 1140        |
|    policy_gradient_loss | 0.0111      |
|    std                  | 0.777       |
|    value_loss           | 1.35        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.09e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 116         |
|    time_elapsed         | 65289       |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.029714327 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.28       |
|    explained_variance   | 0.0428      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.436       |
|    n_updates            | 1150        |
|    policy_gradient_loss | 0.00764     |
|    std                  | 0.775       |
|    value_loss           | 0.956       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.09e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 117        |
|    time_elapsed         | 65495      |
|    total_timesteps      | 239616     |
| train/                  |            |
|    approx_kl            | 0.04154158 |
|    clip_fraction        | 0.254      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.27      |
|    explained_variance   | 0.859      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.652      |
|    n_updates            | 1160       |
|    policy_gradient_loss | 0.00163    |
|    std                  | 0.774      |
|    value_loss           | 6.99       |
----------------------------------------
Eval num_timesteps=240000, episode_reward=-99.80 +/- 0.07
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 240000      |
| train/                  |             |
|    approx_kl            | 0.044235554 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.22       |
|    explained_variance   | 0.00479     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.495       |
|    n_updates            | 1170        |
|    policy_gradient_loss | 0.00278     |
|    std                  | 0.769       |
|    value_loss           | 1.2         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.09e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 118      |
|    time_elapsed    | 67502    |
|    total_timesteps | 241664   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.1e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 119         |
|    time_elapsed         | 67707       |
|    total_timesteps      | 243712      |
| train/                  |             |
|    approx_kl            | 0.022419617 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.2        |
|    explained_variance   | -0.000195   |
|    learning_rate        | 0.0003      |
|    loss                 | 498         |
|    n_updates            | 1180        |
|    policy_gradient_loss | -0.00252    |
|    std                  | 0.769       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.1e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 120         |
|    time_elapsed         | 67913       |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.036004517 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.2        |
|    explained_variance   | 0.943       |
|    learning_rate        | 0.0003      |
|    loss                 | 11.5        |
|    n_updates            | 1190        |
|    policy_gradient_loss | 0.00405     |
|    std                  | 0.768       |
|    value_loss           | 20.8        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.11e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 121        |
|    time_elapsed         | 68118      |
|    total_timesteps      | 247808     |
| train/                  |            |
|    approx_kl            | 0.06835287 |
|    clip_fraction        | 0.247      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.19      |
|    explained_variance   | 0.897      |
|    learning_rate        | 0.0003     |
|    loss                 | 10.9       |
|    n_updates            | 1200       |
|    policy_gradient_loss | 0.00982    |
|    std                  | 0.767      |
|    value_loss           | 28.7       |
----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.34e+03     |
|    ep_rew_mean          | 2.11e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 122          |
|    time_elapsed         | 68323        |
|    total_timesteps      | 249856       |
| train/                  |              |
|    approx_kl            | 0.0022768881 |
|    clip_fraction        | 0.00942      |
|    clip_range           | 0.2          |
|    entropy_loss         | -9.18        |
|    explained_variance   | 0.97         |
|    learning_rate        | 0.0003       |
|    loss                 | 6.9          |
|    n_updates            | 1210         |
|    policy_gradient_loss | -0.00272     |
|    std                  | 0.767        |
|    value_loss           | 15.3         |
------------------------------------------
Eval num_timesteps=250000, episode_reward=-99.77 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 250000      |
| train/                  |             |
|    approx_kl            | 0.008893276 |
|    clip_fraction        | 0.0653      |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.18       |
|    explained_variance   | 0.976       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.53        |
|    n_updates            | 1220        |
|    policy_gradient_loss | -0.00703    |
|    std                  | 0.766       |
|    value_loss           | 30          |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.09e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 123      |
|    time_elapsed    | 70331    |
|    total_timesteps | 251904   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.34e+03     |
|    ep_rew_mean          | 2.09e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 124          |
|    time_elapsed         | 70537        |
|    total_timesteps      | 253952       |
| train/                  |              |
|    approx_kl            | 0.0022295518 |
|    clip_fraction        | 0.0249       |
|    clip_range           | 0.2          |
|    entropy_loss         | -9.18        |
|    explained_variance   | 0.57         |
|    learning_rate        | 0.0003       |
|    loss                 | 38.4         |
|    n_updates            | 1230         |
|    policy_gradient_loss | -0.000692    |
|    std                  | 0.766        |
|    value_loss           | 1.06e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.09e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 125         |
|    time_elapsed         | 70742       |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.017776659 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.17       |
|    explained_variance   | 0.966       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.44        |
|    n_updates            | 1240        |
|    policy_gradient_loss | -0.006      |
|    std                  | 0.765       |
|    value_loss           | 15.1        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.1e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 126         |
|    time_elapsed         | 70948       |
|    total_timesteps      | 258048      |
| train/                  |             |
|    approx_kl            | 0.035766266 |
|    clip_fraction        | 0.393       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.14       |
|    explained_variance   | -0.112      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.523       |
|    n_updates            | 1250        |
|    policy_gradient_loss | 0.0122      |
|    std                  | 0.761       |
|    value_loss           | 1.06        |
-----------------------------------------
Eval num_timesteps=260000, episode_reward=-99.83 +/- 0.06
Episode length: 3597.40 +/- 7.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 260000     |
| train/                  |            |
|    approx_kl            | 0.04221205 |
|    clip_fraction        | 0.371      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.12      |
|    explained_variance   | 0.0014     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.542      |
|    n_updates            | 1260       |
|    policy_gradient_loss | 0.0139     |
|    std                  | 0.762      |
|    value_loss           | 1.06       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.09e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 127      |
|    time_elapsed    | 72954    |
|    total_timesteps | 260096   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.09e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 128         |
|    time_elapsed         | 73159       |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.022323115 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.13       |
|    explained_variance   | 0.0413      |
|    learning_rate        | 0.0003      |
|    loss                 | 35          |
|    n_updates            | 1270        |
|    policy_gradient_loss | 0.00456     |
|    std                  | 0.762       |
|    value_loss           | 1.07e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.1e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 129        |
|    time_elapsed         | 73364      |
|    total_timesteps      | 264192     |
| train/                  |            |
|    approx_kl            | 0.02727941 |
|    clip_fraction        | 0.305      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.1       |
|    explained_variance   | 0.0251     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.446      |
|    n_updates            | 1280       |
|    policy_gradient_loss | 0.0073     |
|    std                  | 0.758      |
|    value_loss           | 0.95       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.1e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 130         |
|    time_elapsed         | 73570       |
|    total_timesteps      | 266240      |
| train/                  |             |
|    approx_kl            | 0.027430985 |
|    clip_fraction        | 0.267       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.11       |
|    explained_variance   | -0.834      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.477       |
|    n_updates            | 1290        |
|    policy_gradient_loss | 0.00515     |
|    std                  | 0.761       |
|    value_loss           | 0.874       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.11e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 131         |
|    time_elapsed         | 73775       |
|    total_timesteps      | 268288      |
| train/                  |             |
|    approx_kl            | 0.024508573 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.1        |
|    explained_variance   | 0.0145      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.435       |
|    n_updates            | 1300        |
|    policy_gradient_loss | 0.00477     |
|    std                  | 0.758       |
|    value_loss           | 1.04        |
-----------------------------------------
Eval num_timesteps=270000, episode_reward=-99.83 +/- 0.06
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 270000      |
| train/                  |             |
|    approx_kl            | 0.024580417 |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.07       |
|    explained_variance   | 0.0123      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.331       |
|    n_updates            | 1310        |
|    policy_gradient_loss | 0.000956    |
|    std                  | 0.756       |
|    value_loss           | 0.912       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.11e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 132      |
|    time_elapsed    | 75782    |
|    total_timesteps | 270336   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.11e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 133        |
|    time_elapsed         | 75988      |
|    total_timesteps      | 272384     |
| train/                  |            |
|    approx_kl            | 0.01487945 |
|    clip_fraction        | 0.172      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.06      |
|    explained_variance   | 0.459      |
|    learning_rate        | 0.0003     |
|    loss                 | 9.82       |
|    n_updates            | 1320       |
|    policy_gradient_loss | 0.00247    |
|    std                  | 0.756      |
|    value_loss           | 1.12e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.12e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 134         |
|    time_elapsed         | 76193       |
|    total_timesteps      | 274432      |
| train/                  |             |
|    approx_kl            | 0.027291859 |
|    clip_fraction        | 0.216       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.05       |
|    explained_variance   | -0.628      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.467       |
|    n_updates            | 1330        |
|    policy_gradient_loss | -0.00322    |
|    std                  | 0.753       |
|    value_loss           | 1.1         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.12e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 135         |
|    time_elapsed         | 76399       |
|    total_timesteps      | 276480      |
| train/                  |             |
|    approx_kl            | 0.017884329 |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.03       |
|    explained_variance   | 0.843       |
|    learning_rate        | 0.0003      |
|    loss                 | 45.6        |
|    n_updates            | 1340        |
|    policy_gradient_loss | 0.00538     |
|    std                  | 0.753       |
|    value_loss           | 36.7        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.13e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 136        |
|    time_elapsed         | 76604      |
|    total_timesteps      | 278528     |
| train/                  |            |
|    approx_kl            | 0.03534793 |
|    clip_fraction        | 0.296      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.03      |
|    explained_variance   | 0.0167     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.492      |
|    n_updates            | 1350       |
|    policy_gradient_loss | 0.00703    |
|    std                  | 0.754      |
|    value_loss           | 1.11       |
----------------------------------------
Eval num_timesteps=280000, episode_reward=-99.84 +/- 0.06
Episode length: 3599.60 +/- 2.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 280000      |
| train/                  |             |
|    approx_kl            | 0.025480814 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.02       |
|    explained_variance   | -7.59       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.506       |
|    n_updates            | 1360        |
|    policy_gradient_loss | 0.000217    |
|    std                  | 0.751       |
|    value_loss           | 2.21        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.12e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 137      |
|    time_elapsed    | 78613    |
|    total_timesteps | 280576   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.12e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 138         |
|    time_elapsed         | 78818       |
|    total_timesteps      | 282624      |
| train/                  |             |
|    approx_kl            | 0.016740449 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.01       |
|    explained_variance   | 0.692       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.78e+03    |
|    n_updates            | 1370        |
|    policy_gradient_loss | -0.00247    |
|    std                  | 0.752       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.34e+03     |
|    ep_rew_mean          | 2.12e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 139          |
|    time_elapsed         | 79024        |
|    total_timesteps      | 284672       |
| train/                  |              |
|    approx_kl            | 0.0075496687 |
|    clip_fraction        | 0.0606       |
|    clip_range           | 0.2          |
|    entropy_loss         | -9.01        |
|    explained_variance   | 0.924        |
|    learning_rate        | 0.0003       |
|    loss                 | 49.2         |
|    n_updates            | 1380         |
|    policy_gradient_loss | -0.00234     |
|    std                  | 0.752        |
|    value_loss           | 29.8         |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.12e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 140        |
|    time_elapsed         | 79229      |
|    total_timesteps      | 286720     |
| train/                  |            |
|    approx_kl            | 0.00871747 |
|    clip_fraction        | 0.0425     |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.01      |
|    explained_variance   | 0.941      |
|    learning_rate        | 0.0003     |
|    loss                 | 3.87       |
|    n_updates            | 1390       |
|    policy_gradient_loss | -0.00867   |
|    std                  | 0.752      |
|    value_loss           | 19.9       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.13e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 141         |
|    time_elapsed         | 79434       |
|    total_timesteps      | 288768      |
| train/                  |             |
|    approx_kl            | 0.038060054 |
|    clip_fraction        | 0.33        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.97       |
|    explained_variance   | 0.00458     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.403       |
|    n_updates            | 1400        |
|    policy_gradient_loss | 0.0101      |
|    std                  | 0.746       |
|    value_loss           | 1.06        |
-----------------------------------------
Eval num_timesteps=290000, episode_reward=-99.74 +/- 0.04
Episode length: 3597.20 +/- 7.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 290000      |
| train/                  |             |
|    approx_kl            | 0.020491298 |
|    clip_fraction        | 0.223       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.95       |
|    explained_variance   | 0.947       |
|    learning_rate        | 0.0003      |
|    loss                 | 22.8        |
|    n_updates            | 1410        |
|    policy_gradient_loss | 0.0021      |
|    std                  | 0.746       |
|    value_loss           | 44.1        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.13e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 142      |
|    time_elapsed    | 81441    |
|    total_timesteps | 290816   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.13e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 143        |
|    time_elapsed         | 81646      |
|    total_timesteps      | 292864     |
| train/                  |            |
|    approx_kl            | 0.03312609 |
|    clip_fraction        | 0.241      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.95      |
|    explained_variance   | -0.000278  |
|    learning_rate        | 0.0003     |
|    loss                 | 860        |
|    n_updates            | 1420       |
|    policy_gradient_loss | 0.00118    |
|    std                  | 0.746      |
|    value_loss           | 1.05e+03   |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 2.13e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 144      |
|    time_elapsed         | 81851    |
|    total_timesteps      | 294912   |
| train/                  |          |
|    approx_kl            | 0.047148 |
|    clip_fraction        | 0.319    |
|    clip_range           | 0.2      |
|    entropy_loss         | -8.94    |
|    explained_variance   | 0.0149   |
|    learning_rate        | 0.0003   |
|    loss                 | 0.28     |
|    n_updates            | 1430     |
|    policy_gradient_loss | 0.0091   |
|    std                  | 0.743    |
|    value_loss           | 0.846    |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.13e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 145       |
|    time_elapsed         | 82057     |
|    total_timesteps      | 296960    |
| train/                  |           |
|    approx_kl            | 0.0351158 |
|    clip_fraction        | 0.255     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.91     |
|    explained_variance   | 0.869     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.552     |
|    n_updates            | 1440      |
|    policy_gradient_loss | 0.00735   |
|    std                  | 0.742     |
|    value_loss           | 25.6      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.14e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 146        |
|    time_elapsed         | 82262      |
|    total_timesteps      | 299008     |
| train/                  |            |
|    approx_kl            | 0.03518472 |
|    clip_fraction        | 0.323      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.9       |
|    explained_variance   | 0.0156     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.367      |
|    n_updates            | 1450       |
|    policy_gradient_loss | 0.00267    |
|    std                  | 0.739      |
|    value_loss           | 0.798      |
----------------------------------------
Eval num_timesteps=300000, episode_reward=-99.72 +/- 0.10
Episode length: 3597.40 +/- 7.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 300000      |
| train/                  |             |
|    approx_kl            | 0.016626552 |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.88       |
|    explained_variance   | 0.867       |
|    learning_rate        | 0.0003      |
|    loss                 | 18.2        |
|    n_updates            | 1460        |
|    policy_gradient_loss | -0.00143    |
|    std                  | 0.739       |
|    value_loss           | 60.2        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.14e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 147      |
|    time_elapsed    | 84270    |
|    total_timesteps | 301056   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.14e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 148         |
|    time_elapsed         | 84477       |
|    total_timesteps      | 303104      |
| train/                  |             |
|    approx_kl            | 0.004959196 |
|    clip_fraction        | 0.0474      |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.88       |
|    explained_variance   | 0.000171    |
|    learning_rate        | 0.0003      |
|    loss                 | 6.57        |
|    n_updates            | 1470        |
|    policy_gradient_loss | -0.00149    |
|    std                  | 0.739       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.15e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 149         |
|    time_elapsed         | 84683       |
|    total_timesteps      | 305152      |
| train/                  |             |
|    approx_kl            | 0.045051176 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.87       |
|    explained_variance   | -0.633      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.459       |
|    n_updates            | 1480        |
|    policy_gradient_loss | 0.00158     |
|    std                  | 0.738       |
|    value_loss           | 1.04        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.15e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 150         |
|    time_elapsed         | 84888       |
|    total_timesteps      | 307200      |
| train/                  |             |
|    approx_kl            | 0.030869164 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.86       |
|    explained_variance   | 0.0348      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.546       |
|    n_updates            | 1490        |
|    policy_gradient_loss | 0.00365     |
|    std                  | 0.738       |
|    value_loss           | 1.23        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.15e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 151        |
|    time_elapsed         | 85093      |
|    total_timesteps      | 309248     |
| train/                  |            |
|    approx_kl            | 0.04658957 |
|    clip_fraction        | 0.3        |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.86      |
|    explained_variance   | 0.96       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.437      |
|    n_updates            | 1500       |
|    policy_gradient_loss | 0.00569    |
|    std                  | 0.735      |
|    value_loss           | 2.32       |
----------------------------------------
Eval num_timesteps=310000, episode_reward=-99.88 +/- 0.05
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 310000      |
| train/                  |             |
|    approx_kl            | 0.015125046 |
|    clip_fraction        | 0.255       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.84       |
|    explained_variance   | 0.964       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.26        |
|    n_updates            | 1510        |
|    policy_gradient_loss | -0.00109    |
|    std                  | 0.736       |
|    value_loss           | 33          |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.15e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 152      |
|    time_elapsed    | 87101    |
|    total_timesteps | 311296   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.15e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 153         |
|    time_elapsed         | 87307       |
|    total_timesteps      | 313344      |
| train/                  |             |
|    approx_kl            | 0.042742066 |
|    clip_fraction        | 0.122       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.84       |
|    explained_variance   | 3.8e-05     |
|    learning_rate        | 0.0003      |
|    loss                 | 929         |
|    n_updates            | 1520        |
|    policy_gradient_loss | -0.00253    |
|    std                  | 0.735       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.16e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 154         |
|    time_elapsed         | 87512       |
|    total_timesteps      | 315392      |
| train/                  |             |
|    approx_kl            | 0.033303488 |
|    clip_fraction        | 0.361       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.79       |
|    explained_variance   | -0.0103     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.5         |
|    n_updates            | 1530        |
|    policy_gradient_loss | 0.0157      |
|    std                  | 0.728       |
|    value_loss           | 1.07        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.16e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 155        |
|    time_elapsed         | 87717      |
|    total_timesteps      | 317440     |
| train/                  |            |
|    approx_kl            | 0.03376478 |
|    clip_fraction        | 0.301      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.76      |
|    explained_variance   | -0.00587   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.393      |
|    n_updates            | 1540       |
|    policy_gradient_loss | 0.0102     |
|    std                  | 0.727      |
|    value_loss           | 0.896      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.16e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 156         |
|    time_elapsed         | 87923       |
|    total_timesteps      | 319488      |
| train/                  |             |
|    approx_kl            | 0.033868574 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.78       |
|    explained_variance   | 0.00636     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.394       |
|    n_updates            | 1550        |
|    policy_gradient_loss | 0.00254     |
|    std                  | 0.731       |
|    value_loss           | 0.843       |
-----------------------------------------
Eval num_timesteps=320000, episode_reward=-99.82 +/- 0.05
Episode length: 3599.40 +/- 2.06
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 320000      |
| train/                  |             |
|    approx_kl            | 0.034252483 |
|    clip_fraction        | 0.248       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.78       |
|    explained_variance   | 0.0245      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.46        |
|    n_updates            | 1560        |
|    policy_gradient_loss | 0.00271     |
|    std                  | 0.727       |
|    value_loss           | 1.04        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.16e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 157      |
|    time_elapsed    | 89929    |
|    total_timesteps | 321536   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.16e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 158         |
|    time_elapsed         | 90135       |
|    total_timesteps      | 323584      |
| train/                  |             |
|    approx_kl            | 0.024662575 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.76       |
|    explained_variance   | -0.000525   |
|    learning_rate        | 0.0003      |
|    loss                 | 18.4        |
|    n_updates            | 1570        |
|    policy_gradient_loss | -0.000501   |
|    std                  | 0.727       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.17e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 159         |
|    time_elapsed         | 90340       |
|    total_timesteps      | 325632      |
| train/                  |             |
|    approx_kl            | 0.042882375 |
|    clip_fraction        | 0.298       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.75       |
|    explained_variance   | -0.126      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.512       |
|    n_updates            | 1580        |
|    policy_gradient_loss | -0.000778   |
|    std                  | 0.726       |
|    value_loss           | 1.24        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.18e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 160        |
|    time_elapsed         | 90546      |
|    total_timesteps      | 327680     |
| train/                  |            |
|    approx_kl            | 0.03078774 |
|    clip_fraction        | 0.254      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.73      |
|    explained_variance   | 0.052      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.443      |
|    n_updates            | 1590       |
|    policy_gradient_loss | -0.000124  |
|    std                  | 0.723      |
|    value_loss           | 0.921      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.18e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 161         |
|    time_elapsed         | 90751       |
|    total_timesteps      | 329728      |
| train/                  |             |
|    approx_kl            | 0.026983196 |
|    clip_fraction        | 0.264       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.69       |
|    explained_variance   | 0.054       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.419       |
|    n_updates            | 1600        |
|    policy_gradient_loss | -0.00114    |
|    std                  | 0.72        |
|    value_loss           | 1.01        |
-----------------------------------------
Eval num_timesteps=330000, episode_reward=-99.86 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 330000      |
| train/                  |             |
|    approx_kl            | 0.030761156 |
|    clip_fraction        | 0.255       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.66       |
|    explained_variance   | 0.0384      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.48        |
|    n_updates            | 1610        |
|    policy_gradient_loss | 0.00333     |
|    std                  | 0.716       |
|    value_loss           | 1.04        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.17e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 162      |
|    time_elapsed    | 92758    |
|    total_timesteps | 331776   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.18e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 163         |
|    time_elapsed         | 92965       |
|    total_timesteps      | 333824      |
| train/                  |             |
|    approx_kl            | 0.028874457 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.64       |
|    explained_variance   | 0.548       |
|    learning_rate        | 0.0003      |
|    loss                 | 317         |
|    n_updates            | 1620        |
|    policy_gradient_loss | 0.00128     |
|    std                  | 0.716       |
|    value_loss           | 1.12e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.18e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 164         |
|    time_elapsed         | 93170       |
|    total_timesteps      | 335872      |
| train/                  |             |
|    approx_kl            | 0.027027499 |
|    clip_fraction        | 0.296       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.64       |
|    explained_variance   | -0.937      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.432       |
|    n_updates            | 1630        |
|    policy_gradient_loss | 0.00207     |
|    std                  | 0.716       |
|    value_loss           | 1.01        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.19e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 165         |
|    time_elapsed         | 93376       |
|    total_timesteps      | 337920      |
| train/                  |             |
|    approx_kl            | 0.041597866 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.63       |
|    explained_variance   | 0.027       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.599       |
|    n_updates            | 1640        |
|    policy_gradient_loss | 0.00372     |
|    std                  | 0.715       |
|    value_loss           | 1.05        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.19e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 166         |
|    time_elapsed         | 93581       |
|    total_timesteps      | 339968      |
| train/                  |             |
|    approx_kl            | 0.024189288 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.64       |
|    explained_variance   | -0.0407     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.537       |
|    n_updates            | 1650        |
|    policy_gradient_loss | 0.000605    |
|    std                  | 0.717       |
|    value_loss           | 1.06        |
-----------------------------------------
Eval num_timesteps=340000, episode_reward=-99.84 +/- 0.03
Episode length: 3600.20 +/- 1.17
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 340000      |
| train/                  |             |
|    approx_kl            | 0.021146573 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.62       |
|    explained_variance   | 0.0244      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.392       |
|    n_updates            | 1660        |
|    policy_gradient_loss | 0.0012      |
|    std                  | 0.714       |
|    value_loss           | 0.763       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.2e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 167      |
|    time_elapsed    | 95589    |
|    total_timesteps | 342016   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.22e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 168         |
|    time_elapsed         | 95795       |
|    total_timesteps      | 344064      |
| train/                  |             |
|    approx_kl            | 0.030319303 |
|    clip_fraction        | 0.242       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.6        |
|    explained_variance   | 0.000172    |
|    learning_rate        | 0.0003      |
|    loss                 | 3.43        |
|    n_updates            | 1670        |
|    policy_gradient_loss | 0.00227     |
|    std                  | 0.713       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.22e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 169        |
|    time_elapsed         | 96001      |
|    total_timesteps      | 346112     |
| train/                  |            |
|    approx_kl            | 0.05045532 |
|    clip_fraction        | 0.267      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.61      |
|    explained_variance   | 0.017      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.381      |
|    n_updates            | 1680       |
|    policy_gradient_loss | 0.00754    |
|    std                  | 0.714      |
|    value_loss           | 0.979      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.23e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 170        |
|    time_elapsed         | 96206      |
|    total_timesteps      | 348160     |
| train/                  |            |
|    approx_kl            | 0.03019746 |
|    clip_fraction        | 0.282      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.6       |
|    explained_variance   | 0.0165     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.459      |
|    n_updates            | 1690       |
|    policy_gradient_loss | 0.000872   |
|    std                  | 0.712      |
|    value_loss           | 0.997      |
----------------------------------------
Eval num_timesteps=350000, episode_reward=-99.75 +/- 0.08
Episode length: 3597.60 +/- 6.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 350000     |
| train/                  |            |
|    approx_kl            | 0.00936405 |
|    clip_fraction        | 0.179      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.6       |
|    explained_variance   | 0.933      |
|    learning_rate        | 0.0003     |
|    loss                 | 6.36       |
|    n_updates            | 1700       |
|    policy_gradient_loss | 0.0016     |
|    std                  | 0.712      |
|    value_loss           | 40.5       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.23e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 171      |
|    time_elapsed    | 98213    |
|    total_timesteps | 350208   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.23e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 172         |
|    time_elapsed         | 98418       |
|    total_timesteps      | 352256      |
| train/                  |             |
|    approx_kl            | 0.017699791 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.6        |
|    explained_variance   | -0.00829    |
|    learning_rate        | 0.0003      |
|    loss                 | 201         |
|    n_updates            | 1710        |
|    policy_gradient_loss | 0.00175     |
|    std                  | 0.712       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.25e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 173         |
|    time_elapsed         | 98623       |
|    total_timesteps      | 354304      |
| train/                  |             |
|    approx_kl            | 0.037619546 |
|    clip_fraction        | 0.323       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.57       |
|    explained_variance   | 0.0187      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.579       |
|    n_updates            | 1720        |
|    policy_gradient_loss | 0.00579     |
|    std                  | 0.707       |
|    value_loss           | 1.1         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.25e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 174         |
|    time_elapsed         | 98829       |
|    total_timesteps      | 356352      |
| train/                  |             |
|    approx_kl            | 0.036731154 |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.54       |
|    explained_variance   | 0.854       |
|    learning_rate        | 0.0003      |
|    loss                 | 9.78        |
|    n_updates            | 1730        |
|    policy_gradient_loss | 0.00178     |
|    std                  | 0.706       |
|    value_loss           | 7.08        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.26e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 175         |
|    time_elapsed         | 99034       |
|    total_timesteps      | 358400      |
| train/                  |             |
|    approx_kl            | 0.034857906 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.51       |
|    explained_variance   | 0.0137      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.613       |
|    n_updates            | 1740        |
|    policy_gradient_loss | 0.00725     |
|    std                  | 0.704       |
|    value_loss           | 0.834       |
-----------------------------------------
Eval num_timesteps=360000, episode_reward=-99.68 +/- 0.14
Episode length: 3596.60 +/- 8.31
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 360000      |
| train/                  |             |
|    approx_kl            | 0.013516311 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.5        |
|    explained_variance   | 0.889       |
|    learning_rate        | 0.0003      |
|    loss                 | 12.1        |
|    n_updates            | 1750        |
|    policy_gradient_loss | -0.00598    |
|    std                  | 0.704       |
|    value_loss           | 15.1        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.26e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 176      |
|    time_elapsed    | 101043   |
|    total_timesteps | 360448   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.26e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 177         |
|    time_elapsed         | 101250      |
|    total_timesteps      | 362496      |
| train/                  |             |
|    approx_kl            | 0.038647454 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.51       |
|    explained_variance   | -0.000545   |
|    learning_rate        | 0.0003      |
|    loss                 | 7.5         |
|    n_updates            | 1760        |
|    policy_gradient_loss | 0.00532     |
|    std                  | 0.704       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.27e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 178         |
|    time_elapsed         | 101455      |
|    total_timesteps      | 364544      |
| train/                  |             |
|    approx_kl            | 0.038018584 |
|    clip_fraction        | 0.339       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.51       |
|    explained_variance   | -0.157      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.526       |
|    n_updates            | 1770        |
|    policy_gradient_loss | 0.00666     |
|    std                  | 0.703       |
|    value_loss           | 1.08        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.27e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 179        |
|    time_elapsed         | 101661     |
|    total_timesteps      | 366592     |
| train/                  |            |
|    approx_kl            | 0.02906071 |
|    clip_fraction        | 0.275      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.49      |
|    explained_variance   | 0.215      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.66       |
|    n_updates            | 1780       |
|    policy_gradient_loss | 0.00907    |
|    std                  | 0.701      |
|    value_loss           | 2.25       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.28e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 180        |
|    time_elapsed         | 101866     |
|    total_timesteps      | 368640     |
| train/                  |            |
|    approx_kl            | 0.03853946 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.48      |
|    explained_variance   | 0.0174     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.469      |
|    n_updates            | 1790       |
|    policy_gradient_loss | 0.0145     |
|    std                  | 0.701      |
|    value_loss           | 0.891      |
----------------------------------------
Eval num_timesteps=370000, episode_reward=-99.83 +/- 0.03
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 370000      |
| train/                  |             |
|    approx_kl            | 0.026138803 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.47       |
|    explained_variance   | 0.747       |
|    learning_rate        | 0.0003      |
|    loss                 | 8.51        |
|    n_updates            | 1800        |
|    policy_gradient_loss | 0.0108      |
|    std                  | 0.701       |
|    value_loss           | 40.3        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.28e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 181      |
|    time_elapsed    | 103874   |
|    total_timesteps | 370688   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 2.28e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 182          |
|    time_elapsed         | 104079       |
|    total_timesteps      | 372736       |
| train/                  |              |
|    approx_kl            | 0.0025116182 |
|    clip_fraction        | 0.0137       |
|    clip_range           | 0.2          |
|    entropy_loss         | -8.48        |
|    explained_variance   | 0.213        |
|    learning_rate        | 0.0003       |
|    loss                 | 725          |
|    n_updates            | 1810         |
|    policy_gradient_loss | -0.00444     |
|    std                  | 0.701        |
|    value_loss           | 1.07e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.29e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 183         |
|    time_elapsed         | 104285      |
|    total_timesteps      | 374784      |
| train/                  |             |
|    approx_kl            | 0.052785568 |
|    clip_fraction        | 0.348       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.5        |
|    explained_variance   | -0.204      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.434       |
|    n_updates            | 1820        |
|    policy_gradient_loss | 0.0148      |
|    std                  | 0.705       |
|    value_loss           | 0.787       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.29e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 184         |
|    time_elapsed         | 104493      |
|    total_timesteps      | 376832      |
| train/                  |             |
|    approx_kl            | 0.013549714 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.52       |
|    explained_variance   | 0.963       |
|    learning_rate        | 0.0003      |
|    loss                 | 16.2        |
|    n_updates            | 1830        |
|    policy_gradient_loss | 0.00187     |
|    std                  | 0.705       |
|    value_loss           | 10.4        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.3e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 185         |
|    time_elapsed         | 104700      |
|    total_timesteps      | 378880      |
| train/                  |             |
|    approx_kl            | 0.035338096 |
|    clip_fraction        | 0.346       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.53       |
|    explained_variance   | 0.0082      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.758       |
|    n_updates            | 1840        |
|    policy_gradient_loss | 0.0129      |
|    std                  | 0.708       |
|    value_loss           | 1.22        |
-----------------------------------------
Eval num_timesteps=380000, episode_reward=-99.82 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 380000      |
| train/                  |             |
|    approx_kl            | 0.040839985 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.57       |
|    explained_variance   | 0.0123      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.368       |
|    n_updates            | 1850        |
|    policy_gradient_loss | 0.00508     |
|    std                  | 0.71        |
|    value_loss           | 1.07        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.3e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 186      |
|    time_elapsed    | 106706   |
|    total_timesteps | 380928   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.3e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 187         |
|    time_elapsed         | 106911      |
|    total_timesteps      | 382976      |
| train/                  |             |
|    approx_kl            | 0.051031828 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.58       |
|    explained_variance   | 0.000268    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.05e+03    |
|    n_updates            | 1860        |
|    policy_gradient_loss | 0.000603    |
|    std                  | 0.711       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.32e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 188        |
|    time_elapsed         | 107116     |
|    total_timesteps      | 385024     |
| train/                  |            |
|    approx_kl            | 0.04786352 |
|    clip_fraction        | 0.316      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.59      |
|    explained_variance   | 0.00605    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.448      |
|    n_updates            | 1870       |
|    policy_gradient_loss | 0.00501    |
|    std                  | 0.711      |
|    value_loss           | 0.758      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.32e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 189         |
|    time_elapsed         | 107322      |
|    total_timesteps      | 387072      |
| train/                  |             |
|    approx_kl            | 0.041421134 |
|    clip_fraction        | 0.358       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.59       |
|    explained_variance   | 0.91        |
|    learning_rate        | 0.0003      |
|    loss                 | 16.2        |
|    n_updates            | 1880        |
|    policy_gradient_loss | 0.0128      |
|    std                  | 0.712       |
|    value_loss           | 37.8        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.32e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 190        |
|    time_elapsed         | 107527     |
|    total_timesteps      | 389120     |
| train/                  |            |
|    approx_kl            | 0.03456752 |
|    clip_fraction        | 0.298      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.59      |
|    explained_variance   | 0.00473    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.493      |
|    n_updates            | 1890       |
|    policy_gradient_loss | 0.00616    |
|    std                  | 0.712      |
|    value_loss           | 0.912      |
----------------------------------------
Eval num_timesteps=390000, episode_reward=-99.86 +/- 0.03
Episode length: 3597.80 +/- 1.94
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 390000      |
| train/                  |             |
|    approx_kl            | 0.022808492 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.58       |
|    explained_variance   | 0.905       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.55        |
|    n_updates            | 1900        |
|    policy_gradient_loss | -0.00285    |
|    std                  | 0.712       |
|    value_loss           | 33.2        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.32e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 191      |
|    time_elapsed    | 109534   |
|    total_timesteps | 391168   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.32e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 192         |
|    time_elapsed         | 109740      |
|    total_timesteps      | 393216      |
| train/                  |             |
|    approx_kl            | 0.003381623 |
|    clip_fraction        | 0.0192      |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.58       |
|    explained_variance   | 0.333       |
|    learning_rate        | 0.0003      |
|    loss                 | 586         |
|    n_updates            | 1910        |
|    policy_gradient_loss | -0.00415    |
|    std                  | 0.712       |
|    value_loss           | 1.07e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.33e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 193         |
|    time_elapsed         | 109945      |
|    total_timesteps      | 395264      |
| train/                  |             |
|    approx_kl            | 0.024504224 |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.58       |
|    explained_variance   | -1.06       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.461       |
|    n_updates            | 1920        |
|    policy_gradient_loss | -0.00545    |
|    std                  | 0.711       |
|    value_loss           | 1.3         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.34e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 194         |
|    time_elapsed         | 110151      |
|    total_timesteps      | 397312      |
| train/                  |             |
|    approx_kl            | 0.034397442 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.58       |
|    explained_variance   | 0.768       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.75        |
|    n_updates            | 1930        |
|    policy_gradient_loss | 0.00956     |
|    std                  | 0.711       |
|    value_loss           | 9.6         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.34e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 195         |
|    time_elapsed         | 110356      |
|    total_timesteps      | 399360      |
| train/                  |             |
|    approx_kl            | 0.026868738 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.58       |
|    explained_variance   | 0.941       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.866       |
|    n_updates            | 1940        |
|    policy_gradient_loss | -0.00272    |
|    std                  | 0.712       |
|    value_loss           | 3.44        |
-----------------------------------------
Eval num_timesteps=400000, episode_reward=-99.83 +/- 0.06
Episode length: 3597.20 +/- 7.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 400000      |
| train/                  |             |
|    approx_kl            | 0.058720365 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.58       |
|    explained_variance   | 0.896       |
|    learning_rate        | 0.0003      |
|    loss                 | 6.32        |
|    n_updates            | 1950        |
|    policy_gradient_loss | 0.0134      |
|    std                  | 0.711       |
|    value_loss           | 12.8        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.33e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 196      |
|    time_elapsed    | 112366   |
|    total_timesteps | 401408   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.33e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 197         |
|    time_elapsed         | 112574      |
|    total_timesteps      | 403456      |
| train/                  |             |
|    approx_kl            | 0.022405315 |
|    clip_fraction        | 0.305       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.58       |
|    explained_variance   | -0.000148   |
|    learning_rate        | 0.0003      |
|    loss                 | 939         |
|    n_updates            | 1960        |
|    policy_gradient_loss | 0.00615     |
|    std                  | 0.711       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.35e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 198         |
|    time_elapsed         | 112779      |
|    total_timesteps      | 405504      |
| train/                  |             |
|    approx_kl            | 0.060297772 |
|    clip_fraction        | 0.421       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.56       |
|    explained_variance   | 0.00558     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.425       |
|    n_updates            | 1970        |
|    policy_gradient_loss | 0.0308      |
|    std                  | 0.709       |
|    value_loss           | 0.98        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.35e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 199         |
|    time_elapsed         | 112985      |
|    total_timesteps      | 407552      |
| train/                  |             |
|    approx_kl            | 0.024372948 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.55       |
|    explained_variance   | 0.895       |
|    learning_rate        | 0.0003      |
|    loss                 | 13.1        |
|    n_updates            | 1980        |
|    policy_gradient_loss | 0.00577     |
|    std                  | 0.709       |
|    value_loss           | 38.3        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.34e+03     |
|    ep_rew_mean          | 2.35e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 200          |
|    time_elapsed         | 113190       |
|    total_timesteps      | 409600       |
| train/                  |              |
|    approx_kl            | 0.0069737006 |
|    clip_fraction        | 0.0502       |
|    clip_range           | 0.2          |
|    entropy_loss         | -8.55        |
|    explained_variance   | 0.948        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.74         |
|    n_updates            | 1990         |
|    policy_gradient_loss | -0.0086      |
|    std                  | 0.708        |
|    value_loss           | 21.3         |
------------------------------------------
Eval num_timesteps=410000, episode_reward=-99.79 +/- 0.04
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 410000     |
| train/                  |            |
|    approx_kl            | 0.05410353 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.56      |
|    explained_variance   | 0.00938    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.555      |
|    n_updates            | 2000       |
|    policy_gradient_loss | 0.0217     |
|    std                  | 0.711      |
|    value_loss           | 1.14       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.34e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 201      |
|    time_elapsed    | 115196   |
|    total_timesteps | 411648   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.36e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 202         |
|    time_elapsed         | 115402      |
|    total_timesteps      | 413696      |
| train/                  |             |
|    approx_kl            | 0.046694726 |
|    clip_fraction        | 0.414       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.58       |
|    explained_variance   | 0.169       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.25e+03    |
|    n_updates            | 2010        |
|    policy_gradient_loss | 0.00716     |
|    std                  | 0.711       |
|    value_loss           | 1.07e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.36e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 203       |
|    time_elapsed         | 115608    |
|    total_timesteps      | 415744    |
| train/                  |           |
|    approx_kl            | 0.0984669 |
|    clip_fraction        | 0.377     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.58     |
|    explained_variance   | -1.13     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.382     |
|    n_updates            | 2020      |
|    policy_gradient_loss | 0.0054    |
|    std                  | 0.71      |
|    value_loss           | 1.03      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.37e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 204        |
|    time_elapsed         | 115813     |
|    total_timesteps      | 417792     |
| train/                  |            |
|    approx_kl            | 0.03258407 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.53      |
|    explained_variance   | 0.034      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.59       |
|    n_updates            | 2030       |
|    policy_gradient_loss | 0.0106     |
|    std                  | 0.704      |
|    value_loss           | 1.13       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.37e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 205         |
|    time_elapsed         | 116019      |
|    total_timesteps      | 419840      |
| train/                  |             |
|    approx_kl            | 0.036109228 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.49       |
|    explained_variance   | 0.0282      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.38        |
|    n_updates            | 2040        |
|    policy_gradient_loss | -0.00237    |
|    std                  | 0.701       |
|    value_loss           | 0.899       |
-----------------------------------------
Eval num_timesteps=420000, episode_reward=-99.84 +/- 0.04
Episode length: 3598.00 +/- 6.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 420000      |
| train/                  |             |
|    approx_kl            | 0.030306432 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.45       |
|    explained_variance   | 0.0316      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.415       |
|    n_updates            | 2050        |
|    policy_gradient_loss | 0.00397     |
|    std                  | 0.698       |
|    value_loss           | 0.793       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.36e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 206      |
|    time_elapsed    | 118025   |
|    total_timesteps | 421888   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.38e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 207         |
|    time_elapsed         | 118230      |
|    total_timesteps      | 423936      |
| train/                  |             |
|    approx_kl            | 0.037212793 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.43       |
|    explained_variance   | -5.96e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 460         |
|    n_updates            | 2060        |
|    policy_gradient_loss | 0.00264     |
|    std                  | 0.697       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.38e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 208        |
|    time_elapsed         | 118435     |
|    total_timesteps      | 425984     |
| train/                  |            |
|    approx_kl            | 0.03627044 |
|    clip_fraction        | 0.305      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.4       |
|    explained_variance   | -0.00292   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.501      |
|    n_updates            | 2070       |
|    policy_gradient_loss | 0.0116     |
|    std                  | 0.695      |
|    value_loss           | 0.903      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.39e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 209         |
|    time_elapsed         | 118641      |
|    total_timesteps      | 428032      |
| train/                  |             |
|    approx_kl            | 0.035328157 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.37       |
|    explained_variance   | 0.0101      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.373       |
|    n_updates            | 2080        |
|    policy_gradient_loss | 0.00753     |
|    std                  | 0.691       |
|    value_loss           | 0.805       |
-----------------------------------------
Eval num_timesteps=430000, episode_reward=-99.83 +/- 0.04
Episode length: 3597.80 +/- 5.46
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 430000     |
| train/                  |            |
|    approx_kl            | 0.03524903 |
|    clip_fraction        | 0.299      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.32      |
|    explained_variance   | 0.0202     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.541      |
|    n_updates            | 2090       |
|    policy_gradient_loss | 0.00495    |
|    std                  | 0.687      |
|    value_loss           | 1.14       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.38e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 210      |
|    time_elapsed    | 120651   |
|    total_timesteps | 430080   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.38e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 211        |
|    time_elapsed         | 120857     |
|    total_timesteps      | 432128     |
| train/                  |            |
|    approx_kl            | 0.02946988 |
|    clip_fraction        | 0.319      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.3       |
|    explained_variance   | -0.00018   |
|    learning_rate        | 0.0003     |
|    loss                 | 73.3       |
|    n_updates            | 2100       |
|    policy_gradient_loss | -0.00259   |
|    std                  | 0.686      |
|    value_loss           | 1.06e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.4e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 212         |
|    time_elapsed         | 121063      |
|    total_timesteps      | 434176      |
| train/                  |             |
|    approx_kl            | 0.041207198 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.28       |
|    explained_variance   | -0.022      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.4         |
|    n_updates            | 2110        |
|    policy_gradient_loss | 0.0072      |
|    std                  | 0.684       |
|    value_loss           | 0.932       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.4e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 213         |
|    time_elapsed         | 121268      |
|    total_timesteps      | 436224      |
| train/                  |             |
|    approx_kl            | 0.026159143 |
|    clip_fraction        | 0.332       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.28       |
|    explained_variance   | 0.937       |
|    learning_rate        | 0.0003      |
|    loss                 | 26.1        |
|    n_updates            | 2120        |
|    policy_gradient_loss | 0.0137      |
|    std                  | 0.684       |
|    value_loss           | 67.6        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.4e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 214         |
|    time_elapsed         | 121474      |
|    total_timesteps      | 438272      |
| train/                  |             |
|    approx_kl            | 0.040859737 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.29       |
|    explained_variance   | 0.00398     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.345       |
|    n_updates            | 2130        |
|    policy_gradient_loss | 0.00368     |
|    std                  | 0.686       |
|    value_loss           | 1.02        |
-----------------------------------------
Eval num_timesteps=440000, episode_reward=-99.81 +/- 0.04
Episode length: 3599.60 +/- 1.74
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 440000      |
| train/                  |             |
|    approx_kl            | 0.048816364 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.3        |
|    explained_variance   | -0.179      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.448       |
|    n_updates            | 2140        |
|    policy_gradient_loss | 0.00529     |
|    std                  | 0.687       |
|    value_loss           | 10          |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.39e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 215      |
|    time_elapsed    | 123481   |
|    total_timesteps | 440320   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.39e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 216         |
|    time_elapsed         | 123686      |
|    total_timesteps      | 442368      |
| train/                  |             |
|    approx_kl            | 0.050116666 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.3        |
|    explained_variance   | -0.000218   |
|    learning_rate        | 0.0003      |
|    loss                 | 91.4        |
|    n_updates            | 2150        |
|    policy_gradient_loss | -0.002      |
|    std                  | 0.686       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.41e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 217         |
|    time_elapsed         | 123892      |
|    total_timesteps      | 444416      |
| train/                  |             |
|    approx_kl            | 0.059350707 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.26       |
|    explained_variance   | -0.00118    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.401       |
|    n_updates            | 2160        |
|    policy_gradient_loss | 0.0112      |
|    std                  | 0.681       |
|    value_loss           | 0.947       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.41e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 218         |
|    time_elapsed         | 124097      |
|    total_timesteps      | 446464      |
| train/                  |             |
|    approx_kl            | 0.037213884 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.21       |
|    explained_variance   | 0.00307     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.398       |
|    n_updates            | 2170        |
|    policy_gradient_loss | 0.00926     |
|    std                  | 0.677       |
|    value_loss           | 0.907       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.42e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 219         |
|    time_elapsed         | 124302      |
|    total_timesteps      | 448512      |
| train/                  |             |
|    approx_kl            | 0.027632805 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.17       |
|    explained_variance   | -0.00253    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.318       |
|    n_updates            | 2180        |
|    policy_gradient_loss | 0.00639     |
|    std                  | 0.675       |
|    value_loss           | 0.691       |
-----------------------------------------
Eval num_timesteps=450000, episode_reward=-99.78 +/- 0.06
Episode length: 3596.60 +/- 8.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 450000     |
| train/                  |            |
|    approx_kl            | 0.04605497 |
|    clip_fraction        | 0.291      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.17      |
|    explained_variance   | 0.00295    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.387      |
|    n_updates            | 2190       |
|    policy_gradient_loss | 1.4e-05    |
|    std                  | 0.678      |
|    value_loss           | 0.719      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.41e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 220      |
|    time_elapsed    | 126308   |
|    total_timesteps | 450560   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.41e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 221        |
|    time_elapsed         | 126514     |
|    total_timesteps      | 452608     |
| train/                  |            |
|    approx_kl            | 0.05003586 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.19      |
|    explained_variance   | -0.000185  |
|    learning_rate        | 0.0003     |
|    loss                 | 150        |
|    n_updates            | 2200       |
|    policy_gradient_loss | -0.00264   |
|    std                  | 0.678      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.43e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 222         |
|    time_elapsed         | 126719      |
|    total_timesteps      | 454656      |
| train/                  |             |
|    approx_kl            | 0.028352875 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.2        |
|    explained_variance   | 0.00291     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.283       |
|    n_updates            | 2210        |
|    policy_gradient_loss | 0.0027      |
|    std                  | 0.679       |
|    value_loss           | 0.855       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.43e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 223         |
|    time_elapsed         | 126924      |
|    total_timesteps      | 456704      |
| train/                  |             |
|    approx_kl            | 0.027792677 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.2        |
|    explained_variance   | 0.903       |
|    learning_rate        | 0.0003      |
|    loss                 | 38.8        |
|    n_updates            | 2220        |
|    policy_gradient_loss | 0.00446     |
|    std                  | 0.679       |
|    value_loss           | 117         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.43e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 224         |
|    time_elapsed         | 127130      |
|    total_timesteps      | 458752      |
| train/                  |             |
|    approx_kl            | 0.044598002 |
|    clip_fraction        | 0.348       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.18       |
|    explained_variance   | 0.00657     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.404       |
|    n_updates            | 2230        |
|    policy_gradient_loss | 0.00335     |
|    std                  | 0.676       |
|    value_loss           | 0.754       |
-----------------------------------------
Eval num_timesteps=460000, episode_reward=-99.84 +/- 0.04
Episode length: 3596.00 +/- 10.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 460000      |
| train/                  |             |
|    approx_kl            | 0.050636232 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.14       |
|    explained_variance   | 0.00275     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.401       |
|    n_updates            | 2240        |
|    policy_gradient_loss | 0.00844     |
|    std                  | 0.672       |
|    value_loss           | 0.797       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.42e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 225      |
|    time_elapsed    | 129142   |
|    total_timesteps | 460800   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.42e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 226         |
|    time_elapsed         | 129349      |
|    total_timesteps      | 462848      |
| train/                  |             |
|    approx_kl            | 0.026086766 |
|    clip_fraction        | 0.384       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.12       |
|    explained_variance   | 0.0555      |
|    learning_rate        | 0.0003      |
|    loss                 | 834         |
|    n_updates            | 2250        |
|    policy_gradient_loss | 0.0144      |
|    std                  | 0.672       |
|    value_loss           | 1.08e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.44e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 227         |
|    time_elapsed         | 129554      |
|    total_timesteps      | 464896      |
| train/                  |             |
|    approx_kl            | 0.033317007 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.12       |
|    explained_variance   | -0.025      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.463       |
|    n_updates            | 2260        |
|    policy_gradient_loss | 0.00457     |
|    std                  | 0.672       |
|    value_loss           | 0.807       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.44e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 228         |
|    time_elapsed         | 129759      |
|    total_timesteps      | 466944      |
| train/                  |             |
|    approx_kl            | 0.044828597 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.11       |
|    explained_variance   | 0.358       |
|    learning_rate        | 0.0003      |
|    loss                 | 22          |
|    n_updates            | 2270        |
|    policy_gradient_loss | 0.00383     |
|    std                  | 0.671       |
|    value_loss           | 9.04        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.44e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 229        |
|    time_elapsed         | 129965     |
|    total_timesteps      | 468992     |
| train/                  |            |
|    approx_kl            | 0.03801144 |
|    clip_fraction        | 0.31       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.08      |
|    explained_variance   | 0.0186     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.577      |
|    n_updates            | 2280       |
|    policy_gradient_loss | 0.00731    |
|    std                  | 0.668      |
|    value_loss           | 0.87       |
----------------------------------------
Eval num_timesteps=470000, episode_reward=-99.84 +/- 0.04
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 470000     |
| train/                  |            |
|    approx_kl            | 0.04356389 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.04      |
|    explained_variance   | 0.0183     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.344      |
|    n_updates            | 2290       |
|    policy_gradient_loss | 0.00165    |
|    std                  | 0.664      |
|    value_loss           | 0.651      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.43e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 230      |
|    time_elapsed    | 131971   |
|    total_timesteps | 471040   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.43e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 231         |
|    time_elapsed         | 132176      |
|    total_timesteps      | 473088      |
| train/                  |             |
|    approx_kl            | 0.018704634 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.02       |
|    explained_variance   | 0.0815      |
|    learning_rate        | 0.0003      |
|    loss                 | 934         |
|    n_updates            | 2300        |
|    policy_gradient_loss | -0.000874   |
|    std                  | 0.664       |
|    value_loss           | 1.07e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.45e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 232         |
|    time_elapsed         | 132385      |
|    total_timesteps      | 475136      |
| train/                  |             |
|    approx_kl            | 0.046581227 |
|    clip_fraction        | 0.334       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.99       |
|    explained_variance   | -0.221      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.563       |
|    n_updates            | 2310        |
|    policy_gradient_loss | 0.00151     |
|    std                  | 0.659       |
|    value_loss           | 1.01        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.45e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 233         |
|    time_elapsed         | 132591      |
|    total_timesteps      | 477184      |
| train/                  |             |
|    approx_kl            | 0.012269519 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.96       |
|    explained_variance   | 0.877       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.14        |
|    n_updates            | 2320        |
|    policy_gradient_loss | -0.0065     |
|    std                  | 0.658       |
|    value_loss           | 14.8        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.45e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 234        |
|    time_elapsed         | 132797     |
|    total_timesteps      | 479232     |
| train/                  |            |
|    approx_kl            | 0.03706731 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.96      |
|    explained_variance   | -0.035     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.512      |
|    n_updates            | 2330       |
|    policy_gradient_loss | 0.0116     |
|    std                  | 0.66       |
|    value_loss           | 0.868      |
----------------------------------------
Eval num_timesteps=480000, episode_reward=-99.82 +/- 0.06
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 480000    |
| train/                  |           |
|    approx_kl            | 0.0407629 |
|    clip_fraction        | 0.353     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.95     |
|    explained_variance   | 0.00701   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.3       |
|    n_updates            | 2340      |
|    policy_gradient_loss | 0.00142   |
|    std                  | 0.657     |
|    value_loss           | 0.762     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.44e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 235      |
|    time_elapsed    | 134803   |
|    total_timesteps | 481280   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.44e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 236         |
|    time_elapsed         | 135009      |
|    total_timesteps      | 483328      |
| train/                  |             |
|    approx_kl            | 0.035562925 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.93       |
|    explained_variance   | -9.14e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 2.52e+03    |
|    n_updates            | 2350        |
|    policy_gradient_loss | -0.00183    |
|    std                  | 0.656       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.46e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 237         |
|    time_elapsed         | 135214      |
|    total_timesteps      | 485376      |
| train/                  |             |
|    approx_kl            | 0.053543396 |
|    clip_fraction        | 0.34        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.92       |
|    explained_variance   | -0.00509    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.194       |
|    n_updates            | 2360        |
|    policy_gradient_loss | 0.0113      |
|    std                  | 0.655       |
|    value_loss           | 0.78        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.46e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 238         |
|    time_elapsed         | 135420      |
|    total_timesteps      | 487424      |
| train/                  |             |
|    approx_kl            | 0.054326326 |
|    clip_fraction        | 0.268       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.91       |
|    explained_variance   | 0.852       |
|    learning_rate        | 0.0003      |
|    loss                 | 29.9        |
|    n_updates            | 2370        |
|    policy_gradient_loss | 0.00821     |
|    std                  | 0.655       |
|    value_loss           | 40.4        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.46e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 239        |
|    time_elapsed         | 135625     |
|    total_timesteps      | 489472     |
| train/                  |            |
|    approx_kl            | 0.04689157 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.88      |
|    explained_variance   | -0.00408   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.495      |
|    n_updates            | 2380       |
|    policy_gradient_loss | 0.0115     |
|    std                  | 0.652      |
|    value_loss           | 0.881      |
----------------------------------------
Eval num_timesteps=490000, episode_reward=-99.94 +/- 0.04
Episode length: 3598.20 +/- 4.26
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 490000      |
| train/                  |             |
|    approx_kl            | 0.032278977 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.89       |
|    explained_variance   | 0.031       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.478       |
|    n_updates            | 2390        |
|    policy_gradient_loss | 0.00895     |
|    std                  | 0.655       |
|    value_loss           | 0.848       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.46e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 240      |
|    time_elapsed    | 137633   |
|    total_timesteps | 491520   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.46e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 241         |
|    time_elapsed         | 137839      |
|    total_timesteps      | 493568      |
| train/                  |             |
|    approx_kl            | 0.026173472 |
|    clip_fraction        | 0.323       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.89       |
|    explained_variance   | -0.000195   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.16e+03    |
|    n_updates            | 2400        |
|    policy_gradient_loss | -0.00197    |
|    std                  | 0.654       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.47e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 242         |
|    time_elapsed         | 138045      |
|    total_timesteps      | 495616      |
| train/                  |             |
|    approx_kl            | 0.038174838 |
|    clip_fraction        | 0.331       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.87       |
|    explained_variance   | 0.00337     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.359       |
|    n_updates            | 2410        |
|    policy_gradient_loss | 0.00721     |
|    std                  | 0.653       |
|    value_loss           | 0.755       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.47e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 243         |
|    time_elapsed         | 138250      |
|    total_timesteps      | 497664      |
| train/                  |             |
|    approx_kl            | 0.031697292 |
|    clip_fraction        | 0.329       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.87       |
|    explained_variance   | 0.079       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.41        |
|    n_updates            | 2420        |
|    policy_gradient_loss | 0.00597     |
|    std                  | 0.652       |
|    value_loss           | 0.951       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.47e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 244        |
|    time_elapsed         | 138455     |
|    total_timesteps      | 499712     |
| train/                  |            |
|    approx_kl            | 0.03860144 |
|    clip_fraction        | 0.313      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.84      |
|    explained_variance   | 0.00226    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.39       |
|    n_updates            | 2430       |
|    policy_gradient_loss | 0.00364    |
|    std                  | 0.649      |
|    value_loss           | 0.742      |
----------------------------------------
Eval num_timesteps=500000, episode_reward=-99.86 +/- 0.05
Episode length: 3596.60 +/- 8.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 500000    |
| train/                  |           |
|    approx_kl            | 0.0366185 |
|    clip_fraction        | 0.304     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.8      |
|    explained_variance   | 0.00619   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.399     |
|    n_updates            | 2440      |
|    policy_gradient_loss | 0.00465   |
|    std                  | 0.647     |
|    value_loss           | 1         |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.47e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 245      |
|    time_elapsed    | 140463   |
|    total_timesteps | 501760   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.48e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 246        |
|    time_elapsed         | 140670     |
|    total_timesteps      | 503808     |
| train/                  |            |
|    approx_kl            | 0.05778386 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.8       |
|    explained_variance   | -8.3e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 15.4       |
|    n_updates            | 2450       |
|    policy_gradient_loss | -0.00188   |
|    std                  | 0.649      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.48e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 247         |
|    time_elapsed         | 140876      |
|    total_timesteps      | 505856      |
| train/                  |             |
|    approx_kl            | 0.032891244 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.78       |
|    explained_variance   | 0.0199      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.392       |
|    n_updates            | 2460        |
|    policy_gradient_loss | 0.0104      |
|    std                  | 0.645       |
|    value_loss           | 0.673       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.49e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 248         |
|    time_elapsed         | 141081      |
|    total_timesteps      | 507904      |
| train/                  |             |
|    approx_kl            | 0.045835886 |
|    clip_fraction        | 0.296       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.78       |
|    explained_variance   | 0.00187     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.473       |
|    n_updates            | 2470        |
|    policy_gradient_loss | 0.0104      |
|    std                  | 0.648       |
|    value_loss           | 0.935       |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.49e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 249       |
|    time_elapsed         | 141286    |
|    total_timesteps      | 509952    |
| train/                  |           |
|    approx_kl            | 0.0346975 |
|    clip_fraction        | 0.302     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.78     |
|    explained_variance   | 0.0141    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.384     |
|    n_updates            | 2480      |
|    policy_gradient_loss | 0.00987   |
|    std                  | 0.646     |
|    value_loss           | 0.721     |
---------------------------------------
Eval num_timesteps=510000, episode_reward=-99.80 +/- 0.08
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 510000      |
| train/                  |             |
|    approx_kl            | 0.042634014 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.76       |
|    explained_variance   | 0.000618    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.277       |
|    n_updates            | 2490        |
|    policy_gradient_loss | 0.00642     |
|    std                  | 0.644       |
|    value_loss           | 0.872       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.48e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 250      |
|    time_elapsed    | 143293   |
|    total_timesteps | 512000   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.49e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 251        |
|    time_elapsed         | 143498     |
|    total_timesteps      | 514048     |
| train/                  |            |
|    approx_kl            | 0.03532319 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.76      |
|    explained_variance   | -6.51e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 2.67e+03   |
|    n_updates            | 2500       |
|    policy_gradient_loss | 0.0026     |
|    std                  | 0.645      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.49e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 252         |
|    time_elapsed         | 143704      |
|    total_timesteps      | 516096      |
| train/                  |             |
|    approx_kl            | 0.043300707 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.79       |
|    explained_variance   | -0.000667   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.404       |
|    n_updates            | 2510        |
|    policy_gradient_loss | 0.0108      |
|    std                  | 0.649       |
|    value_loss           | 0.684       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.5e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 253        |
|    time_elapsed         | 143909     |
|    total_timesteps      | 518144     |
| train/                  |            |
|    approx_kl            | 0.03249211 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.79      |
|    explained_variance   | -0.000972  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.279      |
|    n_updates            | 2520       |
|    policy_gradient_loss | 0.000925   |
|    std                  | 0.646      |
|    value_loss           | 0.753      |
----------------------------------------
Eval num_timesteps=520000, episode_reward=-99.81 +/- 0.08
Episode length: 3596.00 +/- 10.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 520000      |
| train/                  |             |
|    approx_kl            | 0.026431043 |
|    clip_fraction        | 0.224       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.78       |
|    explained_variance   | 0.843       |
|    learning_rate        | 0.0003      |
|    loss                 | 17.2        |
|    n_updates            | 2530        |
|    policy_gradient_loss | 0.0026      |
|    std                  | 0.645       |
|    value_loss           | 48.2        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.49e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 254      |
|    time_elapsed    | 145920   |
|    total_timesteps | 520192   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.49e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 255         |
|    time_elapsed         | 146126      |
|    total_timesteps      | 522240      |
| train/                  |             |
|    approx_kl            | 0.041305132 |
|    clip_fraction        | 0.396       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.79       |
|    explained_variance   | 1.61e-06    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.79e+03    |
|    n_updates            | 2540        |
|    policy_gradient_loss | -0.00421    |
|    std                  | 0.647       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.51e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 256         |
|    time_elapsed         | 146332      |
|    total_timesteps      | 524288      |
| train/                  |             |
|    approx_kl            | 0.044399306 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.82       |
|    explained_variance   | 0.00144     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.353       |
|    n_updates            | 2550        |
|    policy_gradient_loss | 0.00592     |
|    std                  | 0.65        |
|    value_loss           | 0.738       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.51e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 257         |
|    time_elapsed         | 146537      |
|    total_timesteps      | 526336      |
| train/                  |             |
|    approx_kl            | 0.046562612 |
|    clip_fraction        | 0.304       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.83       |
|    explained_variance   | -0.000363   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.298       |
|    n_updates            | 2560        |
|    policy_gradient_loss | 0.0133      |
|    std                  | 0.653       |
|    value_loss           | 0.917       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.51e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 258         |
|    time_elapsed         | 146743      |
|    total_timesteps      | 528384      |
| train/                  |             |
|    approx_kl            | 0.044181857 |
|    clip_fraction        | 0.348       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.86       |
|    explained_variance   | -0.000351   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.368       |
|    n_updates            | 2570        |
|    policy_gradient_loss | 0.00537     |
|    std                  | 0.653       |
|    value_loss           | 0.582       |
-----------------------------------------
Eval num_timesteps=530000, episode_reward=-99.89 +/- 0.05
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 530000     |
| train/                  |            |
|    approx_kl            | 0.03818295 |
|    clip_fraction        | 0.288      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.85      |
|    explained_variance   | 0.00201    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.365      |
|    n_updates            | 2580       |
|    policy_gradient_loss | 0.00516    |
|    std                  | 0.652      |
|    value_loss           | 0.81       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.51e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 259      |
|    time_elapsed    | 148749   |
|    total_timesteps | 530432   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.51e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 260        |
|    time_elapsed         | 148955     |
|    total_timesteps      | 532480     |
| train/                  |            |
|    approx_kl            | 0.04311625 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.85      |
|    explained_variance   | -0.000155  |
|    learning_rate        | 0.0003     |
|    loss                 | 60.7       |
|    n_updates            | 2590       |
|    policy_gradient_loss | 0.00106    |
|    std                  | 0.653      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.52e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 261        |
|    time_elapsed         | 149160     |
|    total_timesteps      | 534528     |
| train/                  |            |
|    approx_kl            | 0.05420642 |
|    clip_fraction        | 0.331      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.86      |
|    explained_variance   | 0.00235    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.275      |
|    n_updates            | 2600       |
|    policy_gradient_loss | 0.00201    |
|    std                  | 0.653      |
|    value_loss           | 0.655      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.52e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 262         |
|    time_elapsed         | 149368      |
|    total_timesteps      | 536576      |
| train/                  |             |
|    approx_kl            | 0.037684686 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.86       |
|    explained_variance   | 0.022       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.312       |
|    n_updates            | 2610        |
|    policy_gradient_loss | -0.000456   |
|    std                  | 0.654       |
|    value_loss           | 0.911       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.53e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 263         |
|    time_elapsed         | 149575      |
|    total_timesteps      | 538624      |
| train/                  |             |
|    approx_kl            | 0.030260947 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.84       |
|    explained_variance   | 0.00656     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.244       |
|    n_updates            | 2620        |
|    policy_gradient_loss | 0.00365     |
|    std                  | 0.651       |
|    value_loss           | 0.639       |
-----------------------------------------
Eval num_timesteps=540000, episode_reward=-99.86 +/- 0.07
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 540000      |
| train/                  |             |
|    approx_kl            | 0.047382034 |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.83       |
|    explained_variance   | 0.649       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.1         |
|    n_updates            | 2630        |
|    policy_gradient_loss | 0.00373     |
|    std                  | 0.651       |
|    value_loss           | 27.2        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.52e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 264      |
|    time_elapsed    | 151581   |
|    total_timesteps | 540672   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 2.52e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 265          |
|    time_elapsed         | 151786       |
|    total_timesteps      | 542720       |
| train/                  |              |
|    approx_kl            | 0.0073125022 |
|    clip_fraction        | 0.0735       |
|    clip_range           | 0.2          |
|    entropy_loss         | -7.83        |
|    explained_variance   | 0.0333       |
|    learning_rate        | 0.0003       |
|    loss                 | 993          |
|    n_updates            | 2640         |
|    policy_gradient_loss | -0.00443     |
|    std                  | 0.651        |
|    value_loss           | 1.06e+03     |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.53e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 266        |
|    time_elapsed         | 151992     |
|    total_timesteps      | 544768     |
| train/                  |            |
|    approx_kl            | 0.08332075 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.81      |
|    explained_variance   | -0.492     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.371      |
|    n_updates            | 2650       |
|    policy_gradient_loss | 0.0138     |
|    std                  | 0.649      |
|    value_loss           | 0.789      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.53e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 267        |
|    time_elapsed         | 152197     |
|    total_timesteps      | 546816     |
| train/                  |            |
|    approx_kl            | 0.03612978 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.8       |
|    explained_variance   | 0.863      |
|    learning_rate        | 0.0003     |
|    loss                 | 4.79       |
|    n_updates            | 2660       |
|    policy_gradient_loss | 0.00857    |
|    std                  | 0.649      |
|    value_loss           | 46.3       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.54e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 268         |
|    time_elapsed         | 152403      |
|    total_timesteps      | 548864      |
| train/                  |             |
|    approx_kl            | 0.115012944 |
|    clip_fraction        | 0.38        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.78       |
|    explained_variance   | -0.0227     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.357       |
|    n_updates            | 2670        |
|    policy_gradient_loss | 0.0186      |
|    std                  | 0.646       |
|    value_loss           | 0.656       |
-----------------------------------------
Eval num_timesteps=550000, episode_reward=-99.85 +/- 0.07
Episode length: 3598.20 +/- 3.92
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 550000      |
| train/                  |             |
|    approx_kl            | 0.035345465 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.76       |
|    explained_variance   | 0.835       |
|    learning_rate        | 0.0003      |
|    loss                 | 21.2        |
|    n_updates            | 2680        |
|    policy_gradient_loss | 0.00288     |
|    std                  | 0.646       |
|    value_loss           | 32.7        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.53e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 269      |
|    time_elapsed    | 154409   |
|    total_timesteps | 550912   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.53e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 270         |
|    time_elapsed         | 154615      |
|    total_timesteps      | 552960      |
| train/                  |             |
|    approx_kl            | 0.047998913 |
|    clip_fraction        | 0.342       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.78       |
|    explained_variance   | -0.000529   |
|    learning_rate        | 0.0003      |
|    loss                 | 63          |
|    n_updates            | 2690        |
|    policy_gradient_loss | 0.00593     |
|    std                  | 0.649       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.54e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 271        |
|    time_elapsed         | 154821     |
|    total_timesteps      | 555008     |
| train/                  |            |
|    approx_kl            | 0.06759915 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.81      |
|    explained_variance   | 0.000917   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.35       |
|    n_updates            | 2700       |
|    policy_gradient_loss | 0.0152     |
|    std                  | 0.652      |
|    value_loss           | 0.697      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.54e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 272         |
|    time_elapsed         | 155026      |
|    total_timesteps      | 557056      |
| train/                  |             |
|    approx_kl            | 0.042687513 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.82       |
|    explained_variance   | 0.00561     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.318       |
|    n_updates            | 2710        |
|    policy_gradient_loss | 0.011       |
|    std                  | 0.649       |
|    value_loss           | 0.598       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.55e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 273         |
|    time_elapsed         | 155231      |
|    total_timesteps      | 559104      |
| train/                  |             |
|    approx_kl            | 0.044816133 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.8        |
|    explained_variance   | 0.00759     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.337       |
|    n_updates            | 2720        |
|    policy_gradient_loss | 0.006       |
|    std                  | 0.649       |
|    value_loss           | 0.821       |
-----------------------------------------
Eval num_timesteps=560000, episode_reward=-99.87 +/- 0.07
Episode length: 3597.00 +/- 6.60
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 560000    |
| train/                  |           |
|    approx_kl            | 0.0212592 |
|    clip_fraction        | 0.214     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.8      |
|    explained_variance   | 0.909     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.487     |
|    n_updates            | 2730      |
|    policy_gradient_loss | -0.00357  |
|    std                  | 0.649     |
|    value_loss           | 28.2      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.54e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 274      |
|    time_elapsed    | 157239   |
|    total_timesteps | 561152   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.54e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 275         |
|    time_elapsed         | 157447      |
|    total_timesteps      | 563200      |
| train/                  |             |
|    approx_kl            | 0.023373842 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.8        |
|    explained_variance   | -0.02       |
|    learning_rate        | 0.0003      |
|    loss                 | 92.6        |
|    n_updates            | 2740        |
|    policy_gradient_loss | -0.00152    |
|    std                  | 0.648       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.55e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 276         |
|    time_elapsed         | 157652      |
|    total_timesteps      | 565248      |
| train/                  |             |
|    approx_kl            | 0.054898992 |
|    clip_fraction        | 0.342       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.76       |
|    explained_variance   | 0.00655     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.289       |
|    n_updates            | 2750        |
|    policy_gradient_loss | 0.0136      |
|    std                  | 0.645       |
|    value_loss           | 0.637       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.56e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 277        |
|    time_elapsed         | 157857     |
|    total_timesteps      | 567296     |
| train/                  |            |
|    approx_kl            | 0.03711903 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.74      |
|    explained_variance   | 0.0131     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.384      |
|    n_updates            | 2760       |
|    policy_gradient_loss | 0.00853    |
|    std                  | 0.644      |
|    value_loss           | 0.723      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.56e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 278         |
|    time_elapsed         | 158063      |
|    total_timesteps      | 569344      |
| train/                  |             |
|    approx_kl            | 0.030120395 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.73       |
|    explained_variance   | 0.881       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.762       |
|    n_updates            | 2770        |
|    policy_gradient_loss | -0.003      |
|    std                  | 0.644       |
|    value_loss           | 14.6        |
-----------------------------------------
Eval num_timesteps=570000, episode_reward=-99.80 +/- 0.03
Episode length: 3600.40 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 570000      |
| train/                  |             |
|    approx_kl            | 0.027023291 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.73       |
|    explained_variance   | 0.931       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.16        |
|    n_updates            | 2780        |
|    policy_gradient_loss | 0.000984    |
|    std                  | 0.644       |
|    value_loss           | 11.3        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.55e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 279      |
|    time_elapsed    | 160069   |
|    total_timesteps | 571392   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 2.55e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 280          |
|    time_elapsed         | 160275       |
|    total_timesteps      | 573440       |
| train/                  |              |
|    approx_kl            | 0.0049424823 |
|    clip_fraction        | 0.0379       |
|    clip_range           | 0.2          |
|    entropy_loss         | -7.72        |
|    explained_variance   | -0.000415    |
|    learning_rate        | 0.0003       |
|    loss                 | 12           |
|    n_updates            | 2790         |
|    policy_gradient_loss | -0.00149     |
|    std                  | 0.643        |
|    value_loss           | 1.05e+03     |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.56e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 281       |
|    time_elapsed         | 160480    |
|    total_timesteps      | 575488    |
| train/                  |           |
|    approx_kl            | 0.0601619 |
|    clip_fraction        | 0.409     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.72     |
|    explained_variance   | -0.01     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.322     |
|    n_updates            | 2800      |
|    policy_gradient_loss | 0.0161    |
|    std                  | 0.643     |
|    value_loss           | 0.641     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.57e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 282         |
|    time_elapsed         | 160685      |
|    total_timesteps      | 577536      |
| train/                  |             |
|    approx_kl            | 0.061567664 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.71       |
|    explained_variance   | 0.342       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.205       |
|    n_updates            | 2810        |
|    policy_gradient_loss | 0.00346     |
|    std                  | 0.642       |
|    value_loss           | 7.67        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.57e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 283         |
|    time_elapsed         | 160891      |
|    total_timesteps      | 579584      |
| train/                  |             |
|    approx_kl            | 0.045186073 |
|    clip_fraction        | 0.34        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.68       |
|    explained_variance   | 0.0784      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.356       |
|    n_updates            | 2820        |
|    policy_gradient_loss | 0.0117      |
|    std                  | 0.638       |
|    value_loss           | 0.773       |
-----------------------------------------
Eval num_timesteps=580000, episode_reward=-99.83 +/- 0.05
Episode length: 3597.40 +/- 7.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 580000     |
| train/                  |            |
|    approx_kl            | 0.07385153 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.65      |
|    explained_variance   | -0.0021    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.428      |
|    n_updates            | 2830       |
|    policy_gradient_loss | 0.00906    |
|    std                  | 0.637      |
|    value_loss           | 0.717      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.56e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 284      |
|    time_elapsed    | 162897   |
|    total_timesteps | 581632   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.58e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 285         |
|    time_elapsed         | 163102      |
|    total_timesteps      | 583680      |
| train/                  |             |
|    approx_kl            | 0.039671227 |
|    clip_fraction        | 0.348       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.65       |
|    explained_variance   | -7.96e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 5.96        |
|    n_updates            | 2840        |
|    policy_gradient_loss | 0.00163     |
|    std                  | 0.638       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.58e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 286        |
|    time_elapsed         | 163308     |
|    total_timesteps      | 585728     |
| train/                  |            |
|    approx_kl            | 0.04499203 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.64      |
|    explained_variance   | -8.95e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.446      |
|    n_updates            | 2850       |
|    policy_gradient_loss | 0.00914    |
|    std                  | 0.636      |
|    value_loss           | 0.64       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.59e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 287         |
|    time_elapsed         | 163513      |
|    total_timesteps      | 587776      |
| train/                  |             |
|    approx_kl            | 0.059582386 |
|    clip_fraction        | 0.348       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.59       |
|    explained_variance   | 0.00171     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.429       |
|    n_updates            | 2860        |
|    policy_gradient_loss | 0.00737     |
|    std                  | 0.632       |
|    value_loss           | 0.7         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.59e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 288        |
|    time_elapsed         | 163719     |
|    total_timesteps      | 589824     |
| train/                  |            |
|    approx_kl            | 0.04659734 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.56      |
|    explained_variance   | 0.00424    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.283      |
|    n_updates            | 2870       |
|    policy_gradient_loss | 0.0109     |
|    std                  | 0.631      |
|    value_loss           | 0.718      |
----------------------------------------
Eval num_timesteps=590000, episode_reward=-99.88 +/- 0.08
Episode length: 3597.80 +/- 6.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 590000      |
| train/                  |             |
|    approx_kl            | 0.036533065 |
|    clip_fraction        | 0.322       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.55       |
|    explained_variance   | 0.00906     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.383       |
|    n_updates            | 2880        |
|    policy_gradient_loss | 0.00561     |
|    std                  | 0.63        |
|    value_loss           | 0.704       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.59e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 289      |
|    time_elapsed    | 165728   |
|    total_timesteps | 591872   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.6e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 290         |
|    time_elapsed         | 165934      |
|    total_timesteps      | 593920      |
| train/                  |             |
|    approx_kl            | 0.100111976 |
|    clip_fraction        | 0.247       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.54       |
|    explained_variance   | 0.557       |
|    learning_rate        | 0.0003      |
|    loss                 | 686         |
|    n_updates            | 2890        |
|    policy_gradient_loss | 0.00526     |
|    std                  | 0.63        |
|    value_loss           | 1.19e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.6e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 291         |
|    time_elapsed         | 166140      |
|    total_timesteps      | 595968      |
| train/                  |             |
|    approx_kl            | 0.052752532 |
|    clip_fraction        | 0.368       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.53       |
|    explained_variance   | 0.0141      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.25        |
|    n_updates            | 2900        |
|    policy_gradient_loss | 0.0133      |
|    std                  | 0.628       |
|    value_loss           | 0.67        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.6e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 292        |
|    time_elapsed         | 166346     |
|    total_timesteps      | 598016     |
| train/                  |            |
|    approx_kl            | 0.12953939 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.51      |
|    explained_variance   | -0.000791  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.411      |
|    n_updates            | 2910       |
|    policy_gradient_loss | 0.0128     |
|    std                  | 0.626      |
|    value_loss           | 0.693      |
----------------------------------------
Eval num_timesteps=600000, episode_reward=-99.88 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 600000      |
| train/                  |             |
|    approx_kl            | 0.032557324 |
|    clip_fraction        | 0.319       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.47       |
|    explained_variance   | 0.0529      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.328       |
|    n_updates            | 2920        |
|    policy_gradient_loss | 0.00263     |
|    std                  | 0.624       |
|    value_loss           | 0.599       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.59e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 293      |
|    time_elapsed    | 168351   |
|    total_timesteps | 600064   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.59e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 294         |
|    time_elapsed         | 168557      |
|    total_timesteps      | 602112      |
| train/                  |             |
|    approx_kl            | 0.048021972 |
|    clip_fraction        | 0.396       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.46       |
|    explained_variance   | -5.41e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 343         |
|    n_updates            | 2930        |
|    policy_gradient_loss | 0.000877    |
|    std                  | 0.625       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.61e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 295         |
|    time_elapsed         | 168762      |
|    total_timesteps      | 604160      |
| train/                  |             |
|    approx_kl            | 0.056323655 |
|    clip_fraction        | 0.349       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.43       |
|    explained_variance   | 6.74e-06    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.238       |
|    n_updates            | 2940        |
|    policy_gradient_loss | -1.84e-05   |
|    std                  | 0.619       |
|    value_loss           | 0.582       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.61e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 296        |
|    time_elapsed         | 168968     |
|    total_timesteps      | 606208     |
| train/                  |            |
|    approx_kl            | 0.04493831 |
|    clip_fraction        | 0.313      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.38      |
|    explained_variance   | 0.708      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.37       |
|    n_updates            | 2950       |
|    policy_gradient_loss | 0.00902    |
|    std                  | 0.618      |
|    value_loss           | 24.7       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.61e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 297         |
|    time_elapsed         | 169173      |
|    total_timesteps      | 608256      |
| train/                  |             |
|    approx_kl            | 0.052996013 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.37       |
|    explained_variance   | 0.000371    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.139       |
|    n_updates            | 2960        |
|    policy_gradient_loss | 0.00617     |
|    std                  | 0.618       |
|    value_loss           | 0.44        |
-----------------------------------------
Eval num_timesteps=610000, episode_reward=-99.81 +/- 0.06
Episode length: 3599.40 +/- 2.06
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 610000      |
| train/                  |             |
|    approx_kl            | 0.029403964 |
|    clip_fraction        | 0.221       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.37       |
|    explained_variance   | 0.83        |
|    learning_rate        | 0.0003      |
|    loss                 | 32.6        |
|    n_updates            | 2970        |
|    policy_gradient_loss | 0.00211     |
|    std                  | 0.618       |
|    value_loss           | 104         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.6e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 298      |
|    time_elapsed    | 171180   |
|    total_timesteps | 610304   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.6e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 299         |
|    time_elapsed         | 171385      |
|    total_timesteps      | 612352      |
| train/                  |             |
|    approx_kl            | 0.017722543 |
|    clip_fraction        | 0.0803      |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.37       |
|    explained_variance   | -0.00703    |
|    learning_rate        | 0.0003      |
|    loss                 | 452         |
|    n_updates            | 2980        |
|    policy_gradient_loss | -0.00121    |
|    std                  | 0.618       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.61e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 300        |
|    time_elapsed         | 171591     |
|    total_timesteps      | 614400     |
| train/                  |            |
|    approx_kl            | 0.07042776 |
|    clip_fraction        | 0.281      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.36      |
|    explained_variance   | -0.316     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.227      |
|    n_updates            | 2990       |
|    policy_gradient_loss | 0.00533    |
|    std                  | 0.618      |
|    value_loss           | 0.596      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.61e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 301         |
|    time_elapsed         | 171796      |
|    total_timesteps      | 616448      |
| train/                  |             |
|    approx_kl            | 0.021667726 |
|    clip_fraction        | 0.304       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.36       |
|    explained_variance   | 0.951       |
|    learning_rate        | 0.0003      |
|    loss                 | 18.1        |
|    n_updates            | 3000        |
|    policy_gradient_loss | 0.00304     |
|    std                  | 0.618       |
|    value_loss           | 30.2        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.62e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 302        |
|    time_elapsed         | 172001     |
|    total_timesteps      | 618496     |
| train/                  |            |
|    approx_kl            | 0.10620855 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.36      |
|    explained_variance   | 2.33e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.303      |
|    n_updates            | 3010       |
|    policy_gradient_loss | 0.0281     |
|    std                  | 0.619      |
|    value_loss           | 0.367      |
----------------------------------------
Eval num_timesteps=620000, episode_reward=-99.87 +/- 0.07
Episode length: 3597.60 +/- 6.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 620000     |
| train/                  |            |
|    approx_kl            | 0.03565121 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.37      |
|    explained_variance   | 0.943      |
|    learning_rate        | 0.0003     |
|    loss                 | 7.42       |
|    n_updates            | 3020       |
|    policy_gradient_loss | 0.0141     |
|    std                  | 0.619      |
|    value_loss           | 52.5       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.61e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 303      |
|    time_elapsed    | 174012   |
|    total_timesteps | 620544   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.61e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 304        |
|    time_elapsed         | 174218     |
|    total_timesteps      | 622592     |
| train/                  |            |
|    approx_kl            | 0.10072579 |
|    clip_fraction        | 0.347      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.38      |
|    explained_variance   | 0.149      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.43e+03   |
|    n_updates            | 3030       |
|    policy_gradient_loss | 0.000626   |
|    std                  | 0.62       |
|    value_loss           | 1.07e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.63e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 305        |
|    time_elapsed         | 174424     |
|    total_timesteps      | 624640     |
| train/                  |            |
|    approx_kl            | 0.07104042 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.36      |
|    explained_variance   | -0.00125   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.279      |
|    n_updates            | 3040       |
|    policy_gradient_loss | 0.0297     |
|    std                  | 0.617      |
|    value_loss           | 0.43       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.63e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 306         |
|    time_elapsed         | 174629      |
|    total_timesteps      | 626688      |
| train/                  |             |
|    approx_kl            | 0.039442234 |
|    clip_fraction        | 0.358       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.34       |
|    explained_variance   | 0.418       |
|    learning_rate        | 0.0003      |
|    loss                 | 13.7        |
|    n_updates            | 3050        |
|    policy_gradient_loss | 0.00287     |
|    std                  | 0.614       |
|    value_loss           | 6.99        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.63e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 307         |
|    time_elapsed         | 174834      |
|    total_timesteps      | 628736      |
| train/                  |             |
|    approx_kl            | 0.043644805 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.26       |
|    explained_variance   | 0.0153      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.182       |
|    n_updates            | 3060        |
|    policy_gradient_loss | 0.0133      |
|    std                  | 0.607       |
|    value_loss           | 0.476       |
-----------------------------------------
Eval num_timesteps=630000, episode_reward=-99.85 +/- 0.02
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 630000     |
| train/                  |            |
|    approx_kl            | 0.06398557 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.21      |
|    explained_variance   | 0.532      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.266      |
|    n_updates            | 3070       |
|    policy_gradient_loss | 0.00338    |
|    std                  | 0.607      |
|    value_loss           | 2.64       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.62e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 308      |
|    time_elapsed    | 176840   |
|    total_timesteps | 630784   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.62e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 309         |
|    time_elapsed         | 177046      |
|    total_timesteps      | 632832      |
| train/                  |             |
|    approx_kl            | 0.048834927 |
|    clip_fraction        | 0.334       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.2        |
|    explained_variance   | -2.36e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 5.82        |
|    n_updates            | 3080        |
|    policy_gradient_loss | 0.00654     |
|    std                  | 0.605       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.64e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 310         |
|    time_elapsed         | 177251      |
|    total_timesteps      | 634880      |
| train/                  |             |
|    approx_kl            | 0.059574816 |
|    clip_fraction        | 0.362       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.16       |
|    explained_variance   | 0.00088     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.149       |
|    n_updates            | 3090        |
|    policy_gradient_loss | 0.0104      |
|    std                  | 0.6         |
|    value_loss           | 0.447       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.64e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 311         |
|    time_elapsed         | 177456      |
|    total_timesteps      | 636928      |
| train/                  |             |
|    approx_kl            | 0.058410205 |
|    clip_fraction        | 0.319       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.13       |
|    explained_variance   | 0.033       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.194       |
|    n_updates            | 3100        |
|    policy_gradient_loss | 0.00537     |
|    std                  | 0.6         |
|    value_loss           | 0.431       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.64e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 312         |
|    time_elapsed         | 177662      |
|    total_timesteps      | 638976      |
| train/                  |             |
|    approx_kl            | 0.041078262 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.14       |
|    explained_variance   | 0.000206    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.136       |
|    n_updates            | 3110        |
|    policy_gradient_loss | 0.00778     |
|    std                  | 0.601       |
|    value_loss           | 0.435       |
-----------------------------------------
Eval num_timesteps=640000, episode_reward=-99.83 +/- 0.05
Episode length: 3597.80 +/- 5.04
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 640000      |
| train/                  |             |
|    approx_kl            | 0.103818186 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.13       |
|    explained_variance   | 0.25        |
|    learning_rate        | 0.0003      |
|    loss                 | 7.9         |
|    n_updates            | 3120        |
|    policy_gradient_loss | 0.00529     |
|    std                  | 0.599       |
|    value_loss           | 5.29        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.63e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 313      |
|    time_elapsed    | 179668   |
|    total_timesteps | 641024   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.63e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 314         |
|    time_elapsed         | 179873      |
|    total_timesteps      | 643072      |
| train/                  |             |
|    approx_kl            | 0.025690537 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.12       |
|    explained_variance   | -0.00143    |
|    learning_rate        | 0.0003      |
|    loss                 | 304         |
|    n_updates            | 3130        |
|    policy_gradient_loss | 0.00344     |
|    std                  | 0.599       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.65e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 315         |
|    time_elapsed         | 180079      |
|    total_timesteps      | 645120      |
| train/                  |             |
|    approx_kl            | 0.027863733 |
|    clip_fraction        | 0.0651      |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.12       |
|    explained_variance   | -10.7       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.3         |
|    n_updates            | 3140        |
|    policy_gradient_loss | -0.000999   |
|    std                  | 0.599       |
|    value_loss           | 1.03        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.65e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 316         |
|    time_elapsed         | 180284      |
|    total_timesteps      | 647168      |
| train/                  |             |
|    approx_kl            | 0.043615516 |
|    clip_fraction        | 0.239       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.12       |
|    explained_variance   | 0.782       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.12        |
|    n_updates            | 3150        |
|    policy_gradient_loss | 6.38e-05    |
|    std                  | 0.599       |
|    value_loss           | 1.68        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.65e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 317        |
|    time_elapsed         | 180490     |
|    total_timesteps      | 649216     |
| train/                  |            |
|    approx_kl            | 0.07935171 |
|    clip_fraction        | 0.437      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.1       |
|    explained_variance   | 0.00168    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.279      |
|    n_updates            | 3160       |
|    policy_gradient_loss | 0.0294     |
|    std                  | 0.599      |
|    value_loss           | 0.621      |
----------------------------------------
Eval num_timesteps=650000, episode_reward=-99.82 +/- 0.03
Episode length: 3596.80 +/- 8.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 650000      |
| train/                  |             |
|    approx_kl            | 0.027057886 |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.1        |
|    explained_variance   | 0.915       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.64        |
|    n_updates            | 3170        |
|    policy_gradient_loss | 0.00245     |
|    std                  | 0.599       |
|    value_loss           | 4.59        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.64e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 318      |
|    time_elapsed    | 182500   |
|    total_timesteps | 651264   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.64e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 319         |
|    time_elapsed         | 182706      |
|    total_timesteps      | 653312      |
| train/                  |             |
|    approx_kl            | 0.039405413 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.1        |
|    explained_variance   | -0.00357    |
|    learning_rate        | 0.0003      |
|    loss                 | 2.37e+03    |
|    n_updates            | 3180        |
|    policy_gradient_loss | -0.000291   |
|    std                  | 0.598       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.66e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 320         |
|    time_elapsed         | 182912      |
|    total_timesteps      | 655360      |
| train/                  |             |
|    approx_kl            | 0.066439345 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.1        |
|    explained_variance   | -0.00123    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.157       |
|    n_updates            | 3190        |
|    policy_gradient_loss | 0.0235      |
|    std                  | 0.597       |
|    value_loss           | 0.342       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.66e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 321        |
|    time_elapsed         | 183117     |
|    total_timesteps      | 657408     |
| train/                  |            |
|    approx_kl            | 0.07178864 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.08      |
|    explained_variance   | 0.00166    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.311      |
|    n_updates            | 3200       |
|    policy_gradient_loss | 0.0126     |
|    std                  | 0.598      |
|    value_loss           | 0.555      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.66e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 322        |
|    time_elapsed         | 183323     |
|    total_timesteps      | 659456     |
| train/                  |            |
|    approx_kl            | 0.29937592 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.07      |
|    explained_variance   | -1.12      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.18       |
|    n_updates            | 3210       |
|    policy_gradient_loss | 0.0178     |
|    std                  | 0.596      |
|    value_loss           | 2.95       |
----------------------------------------
Eval num_timesteps=660000, episode_reward=-99.81 +/- 0.02
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 660000      |
| train/                  |             |
|    approx_kl            | 0.046363965 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.03       |
|    explained_variance   | -0.00312    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.186       |
|    n_updates            | 3220        |
|    policy_gradient_loss | 0.00839     |
|    std                  | 0.593       |
|    value_loss           | 0.447       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.65e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 323      |
|    time_elapsed    | 185328   |
|    total_timesteps | 661504   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.65e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 324         |
|    time_elapsed         | 185534      |
|    total_timesteps      | 663552      |
| train/                  |             |
|    approx_kl            | 0.028049955 |
|    clip_fraction        | 0.31        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.03       |
|    explained_variance   | -2.91e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 150         |
|    n_updates            | 3230        |
|    policy_gradient_loss | -0.00123    |
|    std                  | 0.594       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.67e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 325         |
|    time_elapsed         | 185742      |
|    total_timesteps      | 665600      |
| train/                  |             |
|    approx_kl            | 0.046671808 |
|    clip_fraction        | 0.339       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.05       |
|    explained_variance   | -0.00243    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.449       |
|    n_updates            | 3240        |
|    policy_gradient_loss | 0.00949     |
|    std                  | 0.595       |
|    value_loss           | 0.598       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.68e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 326        |
|    time_elapsed         | 185948     |
|    total_timesteps      | 667648     |
| train/                  |            |
|    approx_kl            | 0.13511942 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.05      |
|    explained_variance   | 0.54       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.161      |
|    n_updates            | 3250       |
|    policy_gradient_loss | 0.00524    |
|    std                  | 0.594      |
|    value_loss           | 18.5       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.68e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 327         |
|    time_elapsed         | 186154      |
|    total_timesteps      | 669696      |
| train/                  |             |
|    approx_kl            | 0.048855737 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.03       |
|    explained_variance   | 0.358       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.06        |
|    n_updates            | 3260        |
|    policy_gradient_loss | 0.00433     |
|    std                  | 0.593       |
|    value_loss           | 7.52        |
-----------------------------------------
Eval num_timesteps=670000, episode_reward=-99.80 +/- 0.03
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 670000     |
| train/                  |            |
|    approx_kl            | 0.08881327 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.98      |
|    explained_variance   | -0.0887    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.261      |
|    n_updates            | 3270       |
|    policy_gradient_loss | 0.0128     |
|    std                  | 0.587      |
|    value_loss           | 0.425      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.67e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 328      |
|    time_elapsed    | 188160   |
|    total_timesteps | 671744   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.68e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 329         |
|    time_elapsed         | 188365      |
|    total_timesteps      | 673792      |
| train/                  |             |
|    approx_kl            | 0.029659634 |
|    clip_fraction        | 0.264       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.95       |
|    explained_variance   | -8.23e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 212         |
|    n_updates            | 3280        |
|    policy_gradient_loss | 0.00143     |
|    std                  | 0.587       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.68e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 330        |
|    time_elapsed         | 188570     |
|    total_timesteps      | 675840     |
| train/                  |            |
|    approx_kl            | 0.07868295 |
|    clip_fraction        | 0.257      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.95      |
|    explained_variance   | 0.886      |
|    learning_rate        | 0.0003     |
|    loss                 | 4.25       |
|    n_updates            | 3290       |
|    policy_gradient_loss | 0.00123    |
|    std                  | 0.586      |
|    value_loss           | 3.99       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.68e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 331        |
|    time_elapsed         | 188776     |
|    total_timesteps      | 677888     |
| train/                  |            |
|    approx_kl            | 0.04822038 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.9       |
|    explained_variance   | 0.00865    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.262      |
|    n_updates            | 3300       |
|    policy_gradient_loss | 0.00963    |
|    std                  | 0.582      |
|    value_loss           | 0.451      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.68e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 332         |
|    time_elapsed         | 188981      |
|    total_timesteps      | 679936      |
| train/                  |             |
|    approx_kl            | 0.039389856 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.87       |
|    explained_variance   | 0.0157      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.298       |
|    n_updates            | 3310        |
|    policy_gradient_loss | 0.00901     |
|    std                  | 0.581       |
|    value_loss           | 0.371       |
-----------------------------------------
Eval num_timesteps=680000, episode_reward=-99.84 +/- 0.05
Episode length: 3600.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 680000      |
| train/                  |             |
|    approx_kl            | 0.050322905 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.87       |
|    explained_variance   | 0.0138      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.259       |
|    n_updates            | 3320        |
|    policy_gradient_loss | 0.0049      |
|    std                  | 0.582       |
|    value_loss           | 0.407       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.68e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 333      |
|    time_elapsed    | 190989   |
|    total_timesteps | 681984   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.69e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 334         |
|    time_elapsed         | 191195      |
|    total_timesteps      | 684032      |
| train/                  |             |
|    approx_kl            | 0.026798267 |
|    clip_fraction        | 0.326       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.88       |
|    explained_variance   | -0.00304    |
|    learning_rate        | 0.0003      |
|    loss                 | 3.88        |
|    n_updates            | 3330        |
|    policy_gradient_loss | 0.000464    |
|    std                  | 0.583       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.69e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 335        |
|    time_elapsed         | 191400     |
|    total_timesteps      | 686080     |
| train/                  |            |
|    approx_kl            | 0.20695701 |
|    clip_fraction        | 0.317      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.85      |
|    explained_variance   | -0.0102    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.184      |
|    n_updates            | 3340       |
|    policy_gradient_loss | 0.00591    |
|    std                  | 0.579      |
|    value_loss           | 0.448      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.7e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 336        |
|    time_elapsed         | 191606     |
|    total_timesteps      | 688128     |
| train/                  |            |
|    approx_kl            | 0.08055034 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.84      |
|    explained_variance   | 0.000852   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.227      |
|    n_updates            | 3350       |
|    policy_gradient_loss | 0.00937    |
|    std                  | 0.58       |
|    value_loss           | 0.363      |
----------------------------------------
Eval num_timesteps=690000, episode_reward=-99.83 +/- 0.04
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 690000      |
| train/                  |             |
|    approx_kl            | 0.042273343 |
|    clip_fraction        | 0.305       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.83       |
|    explained_variance   | 0.118       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.194       |
|    n_updates            | 3360        |
|    policy_gradient_loss | 0.000824    |
|    std                  | 0.579       |
|    value_loss           | 0.329       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.69e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 337      |
|    time_elapsed    | 193614   |
|    total_timesteps | 690176   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.69e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 338        |
|    time_elapsed         | 193820     |
|    total_timesteps      | 692224     |
| train/                  |            |
|    approx_kl            | 0.02142145 |
|    clip_fraction        | 0.287      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.83      |
|    explained_variance   | 0.0335     |
|    learning_rate        | 0.0003     |
|    loss                 | 63.9       |
|    n_updates            | 3370       |
|    policy_gradient_loss | 0.00567    |
|    std                  | 0.58       |
|    value_loss           | 1.08e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 339         |
|    time_elapsed         | 194025      |
|    total_timesteps      | 694272      |
| train/                  |             |
|    approx_kl            | 0.032536454 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.8        |
|    explained_variance   | 0.000371    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.228       |
|    n_updates            | 3380        |
|    policy_gradient_loss | 0.00404     |
|    std                  | 0.576       |
|    value_loss           | 0.357       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 340         |
|    time_elapsed         | 194231      |
|    total_timesteps      | 696320      |
| train/                  |             |
|    approx_kl            | 0.062449895 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.76       |
|    explained_variance   | 0.053       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.147       |
|    n_updates            | 3390        |
|    policy_gradient_loss | 0.00535     |
|    std                  | 0.574       |
|    value_loss           | 0.406       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 341         |
|    time_elapsed         | 194436      |
|    total_timesteps      | 698368      |
| train/                  |             |
|    approx_kl            | 0.046001114 |
|    clip_fraction        | 0.319       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.71       |
|    explained_variance   | -0.00915    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.269       |
|    n_updates            | 3400        |
|    policy_gradient_loss | 0.00753     |
|    std                  | 0.568       |
|    value_loss           | 0.57        |
-----------------------------------------
Eval num_timesteps=700000, episode_reward=-99.85 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 700000      |
| train/                  |             |
|    approx_kl            | 0.047847763 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.68       |
|    explained_variance   | 0.674       |
|    learning_rate        | 0.0003      |
|    loss                 | 14          |
|    n_updates            | 3410        |
|    policy_gradient_loss | 0.0111      |
|    std                  | 0.568       |
|    value_loss           | 66.6        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.7e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 342      |
|    time_elapsed    | 196442   |
|    total_timesteps | 700416   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.7e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 343         |
|    time_elapsed         | 196647      |
|    total_timesteps      | 702464      |
| train/                  |             |
|    approx_kl            | 0.023064986 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.68       |
|    explained_variance   | 0.132       |
|    learning_rate        | 0.0003      |
|    loss                 | 12.3        |
|    n_updates            | 3420        |
|    policy_gradient_loss | -0.00482    |
|    std                  | 0.568       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.72e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 344        |
|    time_elapsed         | 196853     |
|    total_timesteps      | 704512     |
| train/                  |            |
|    approx_kl            | 0.06809442 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.66      |
|    explained_variance   | -0.0022    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.399      |
|    n_updates            | 3430       |
|    policy_gradient_loss | 0.0187     |
|    std                  | 0.567      |
|    value_loss           | 0.575      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.72e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 345        |
|    time_elapsed         | 197058     |
|    total_timesteps      | 706560     |
| train/                  |            |
|    approx_kl            | 0.05745153 |
|    clip_fraction        | 0.316      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.66      |
|    explained_variance   | 0.875      |
|    learning_rate        | 0.0003     |
|    loss                 | 6.2        |
|    n_updates            | 3440       |
|    policy_gradient_loss | 0.00756    |
|    std                  | 0.566      |
|    value_loss           | 9.75       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.72e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 346        |
|    time_elapsed         | 197263     |
|    total_timesteps      | 708608     |
| train/                  |            |
|    approx_kl            | 0.05233212 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.63      |
|    explained_variance   | 0.0112     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.334      |
|    n_updates            | 3450       |
|    policy_gradient_loss | 0.0225     |
|    std                  | 0.563      |
|    value_loss           | 0.659      |
----------------------------------------
Eval num_timesteps=710000, episode_reward=-99.84 +/- 0.05
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 710000      |
| train/                  |             |
|    approx_kl            | 0.057431694 |
|    clip_fraction        | 0.35        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.6        |
|    explained_variance   | -0.0132     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.343       |
|    n_updates            | 3460        |
|    policy_gradient_loss | 0.00892     |
|    std                  | 0.562       |
|    value_loss           | 0.74        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.71e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 347      |
|    time_elapsed    | 199273   |
|    total_timesteps | 710656   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 348         |
|    time_elapsed         | 199479      |
|    total_timesteps      | 712704      |
| train/                  |             |
|    approx_kl            | 0.030007187 |
|    clip_fraction        | 0.359       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.6        |
|    explained_variance   | 0.101       |
|    learning_rate        | 0.0003      |
|    loss                 | 27.8        |
|    n_updates            | 3470        |
|    policy_gradient_loss | 0.00601     |
|    std                  | 0.562       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.73e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 349        |
|    time_elapsed         | 199684     |
|    total_timesteps      | 714752     |
| train/                  |            |
|    approx_kl            | 0.11612241 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.59      |
|    explained_variance   | -0.006     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.174      |
|    n_updates            | 3480       |
|    policy_gradient_loss | 0.021      |
|    std                  | 0.561      |
|    value_loss           | 0.408      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.73e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 350        |
|    time_elapsed         | 199889     |
|    total_timesteps      | 716800     |
| train/                  |            |
|    approx_kl            | 0.07051526 |
|    clip_fraction        | 0.319      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.57      |
|    explained_variance   | 0.867      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.1        |
|    n_updates            | 3490       |
|    policy_gradient_loss | -0.00222   |
|    std                  | 0.56       |
|    value_loss           | 2.01       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.73e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 351        |
|    time_elapsed         | 200095     |
|    total_timesteps      | 718848     |
| train/                  |            |
|    approx_kl            | 0.04568235 |
|    clip_fraction        | 0.325      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.56      |
|    explained_variance   | 0.0075     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.191      |
|    n_updates            | 3500       |
|    policy_gradient_loss | 0.0132     |
|    std                  | 0.56       |
|    value_loss           | 0.345      |
----------------------------------------
Eval num_timesteps=720000, episode_reward=-99.83 +/- 0.06
Episode length: 3598.80 +/- 4.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 720000      |
| train/                  |             |
|    approx_kl            | 0.051820423 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.54       |
|    explained_variance   | -0.044      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.24        |
|    n_updates            | 3510        |
|    policy_gradient_loss | 0.00268     |
|    std                  | 0.559       |
|    value_loss           | 3.39        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.72e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 352      |
|    time_elapsed    | 202101   |
|    total_timesteps | 720896   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.72e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 353         |
|    time_elapsed         | 202309      |
|    total_timesteps      | 722944      |
| train/                  |             |
|    approx_kl            | 0.030544467 |
|    clip_fraction        | 0.355       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.53       |
|    explained_variance   | -2.8e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 443         |
|    n_updates            | 3520        |
|    policy_gradient_loss | -0.00465    |
|    std                  | 0.558       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.74e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 354        |
|    time_elapsed         | 202514     |
|    total_timesteps      | 724992     |
| train/                  |            |
|    approx_kl            | 0.09981762 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.54      |
|    explained_variance   | 0.00961    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.21       |
|    n_updates            | 3530       |
|    policy_gradient_loss | 0.00927    |
|    std                  | 0.558      |
|    value_loss           | 0.452      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.74e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 355         |
|    time_elapsed         | 202720      |
|    total_timesteps      | 727040      |
| train/                  |             |
|    approx_kl            | 0.044886574 |
|    clip_fraction        | 0.326       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.48       |
|    explained_variance   | -0.000583   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.196       |
|    n_updates            | 3540        |
|    policy_gradient_loss | 0.00825     |
|    std                  | 0.553       |
|    value_loss           | 0.387       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.75e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 356         |
|    time_elapsed         | 202925      |
|    total_timesteps      | 729088      |
| train/                  |             |
|    approx_kl            | 0.038010858 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.45       |
|    explained_variance   | 0.0202      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.158       |
|    n_updates            | 3550        |
|    policy_gradient_loss | 0.00654     |
|    std                  | 0.552       |
|    value_loss           | 0.266       |
-----------------------------------------
Eval num_timesteps=730000, episode_reward=-99.81 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 730000      |
| train/                  |             |
|    approx_kl            | 0.029976621 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.44       |
|    explained_variance   | 0.0269      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0854      |
|    n_updates            | 3560        |
|    policy_gradient_loss | 0.00349     |
|    std                  | 0.554       |
|    value_loss           | 0.363       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.74e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 357      |
|    time_elapsed    | 204931   |
|    total_timesteps | 731136   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.74e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 358         |
|    time_elapsed         | 205137      |
|    total_timesteps      | 733184      |
| train/                  |             |
|    approx_kl            | 0.053762656 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.45       |
|    explained_variance   | -0.00636    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.53e+03    |
|    n_updates            | 3570        |
|    policy_gradient_loss | 0.000251    |
|    std                  | 0.554       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.75e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 359         |
|    time_elapsed         | 205346      |
|    total_timesteps      | 735232      |
| train/                  |             |
|    approx_kl            | 0.039175354 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.47       |
|    explained_variance   | 0.00603     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.217       |
|    n_updates            | 3580        |
|    policy_gradient_loss | 0.00484     |
|    std                  | 0.556       |
|    value_loss           | 0.399       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.76e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 360         |
|    time_elapsed         | 205553      |
|    total_timesteps      | 737280      |
| train/                  |             |
|    approx_kl            | 0.050995447 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.48       |
|    explained_variance   | 0.84        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.124       |
|    n_updates            | 3590        |
|    policy_gradient_loss | 0.00329     |
|    std                  | 0.556       |
|    value_loss           | 4.78        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.76e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 361         |
|    time_elapsed         | 205759      |
|    total_timesteps      | 739328      |
| train/                  |             |
|    approx_kl            | 0.110711396 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.46       |
|    explained_variance   | -1.24       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0918      |
|    n_updates            | 3600        |
|    policy_gradient_loss | 0.00759     |
|    std                  | 0.554       |
|    value_loss           | 0.457       |
-----------------------------------------
Eval num_timesteps=740000, episode_reward=-99.78 +/- 0.03
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 740000     |
| train/                  |            |
|    approx_kl            | 0.05472604 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.42      |
|    explained_variance   | 0.00502    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.227      |
|    n_updates            | 3610       |
|    policy_gradient_loss | 0.00665    |
|    std                  | 0.552      |
|    value_loss           | 0.382      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.75e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 362      |
|    time_elapsed    | 207765   |
|    total_timesteps | 741376   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.75e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 363        |
|    time_elapsed         | 207970     |
|    total_timesteps      | 743424     |
| train/                  |            |
|    approx_kl            | 0.03219723 |
|    clip_fraction        | 0.247      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.4       |
|    explained_variance   | -0.0222    |
|    learning_rate        | 0.0003     |
|    loss                 | 3.98       |
|    n_updates            | 3620       |
|    policy_gradient_loss | -0.00305   |
|    std                  | 0.552      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.77e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 364        |
|    time_elapsed         | 208176     |
|    total_timesteps      | 745472     |
| train/                  |            |
|    approx_kl            | 0.07762858 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.39      |
|    explained_variance   | -0.0408    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.189      |
|    n_updates            | 3630       |
|    policy_gradient_loss | 0.0309     |
|    std                  | 0.549      |
|    value_loss           | 0.342      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.77e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 365        |
|    time_elapsed         | 208381     |
|    total_timesteps      | 747520     |
| train/                  |            |
|    approx_kl            | 0.08069268 |
|    clip_fraction        | 0.313      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.33      |
|    explained_variance   | 0.115      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.247      |
|    n_updates            | 3640       |
|    policy_gradient_loss | 0.00603    |
|    std                  | 0.545      |
|    value_loss           | 0.448      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.77e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 366        |
|    time_elapsed         | 208587     |
|    total_timesteps      | 749568     |
| train/                  |            |
|    approx_kl            | 0.03428803 |
|    clip_fraction        | 0.187      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.31      |
|    explained_variance   | 0.781      |
|    learning_rate        | 0.0003     |
|    loss                 | 7.56       |
|    n_updates            | 3650       |
|    policy_gradient_loss | 0.00187    |
|    std                  | 0.545      |
|    value_loss           | 21.2       |
----------------------------------------
Eval num_timesteps=750000, episode_reward=-99.81 +/- 0.04
Episode length: 3599.00 +/- 4.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 750000     |
| train/                  |            |
|    approx_kl            | 0.18221942 |
|    clip_fraction        | 0.29       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.31      |
|    explained_variance   | -0.00987   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.232      |
|    n_updates            | 3660       |
|    policy_gradient_loss | 0.0162     |
|    std                  | 0.545      |
|    value_loss           | 0.351      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.76e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 367      |
|    time_elapsed    | 210593   |
|    total_timesteps | 751616   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.78e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 368        |
|    time_elapsed         | 210798     |
|    total_timesteps      | 753664     |
| train/                  |            |
|    approx_kl            | 0.01880055 |
|    clip_fraction        | 0.184      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.31      |
|    explained_variance   | 0.0654     |
|    learning_rate        | 0.0003     |
|    loss                 | 389        |
|    n_updates            | 3670       |
|    policy_gradient_loss | -0.000896  |
|    std                  | 0.545      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.78e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 369        |
|    time_elapsed         | 211003     |
|    total_timesteps      | 755712     |
| train/                  |            |
|    approx_kl            | 0.04189618 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.29      |
|    explained_variance   | -0.0112    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.142      |
|    n_updates            | 3680       |
|    policy_gradient_loss | 0.0107     |
|    std                  | 0.543      |
|    value_loss           | 0.448      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.78e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 370         |
|    time_elapsed         | 211209      |
|    total_timesteps      | 757760      |
| train/                  |             |
|    approx_kl            | 0.043959722 |
|    clip_fraction        | 0.322       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.25       |
|    explained_variance   | -0.00294    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.13        |
|    n_updates            | 3690        |
|    policy_gradient_loss | 0.00258     |
|    std                  | 0.54        |
|    value_loss           | 0.407       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.78e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 371         |
|    time_elapsed         | 211414      |
|    total_timesteps      | 759808      |
| train/                  |             |
|    approx_kl            | 0.029759008 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.21       |
|    explained_variance   | 0.3         |
|    learning_rate        | 0.0003      |
|    loss                 | 0.183       |
|    n_updates            | 3700        |
|    policy_gradient_loss | -0.00221    |
|    std                  | 0.537       |
|    value_loss           | 0.337       |
-----------------------------------------
Eval num_timesteps=760000, episode_reward=-99.83 +/- 0.05
Episode length: 3598.20 +/- 5.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 760000     |
| train/                  |            |
|    approx_kl            | 0.04015663 |
|    clip_fraction        | 0.277      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.19      |
|    explained_variance   | 0.00727    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0695     |
|    n_updates            | 3710       |
|    policy_gradient_loss | 0.00195    |
|    std                  | 0.536      |
|    value_loss           | 0.208      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.77e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 372      |
|    time_elapsed    | 213424   |
|    total_timesteps | 761856   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.79e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 373         |
|    time_elapsed         | 213631      |
|    total_timesteps      | 763904      |
| train/                  |             |
|    approx_kl            | 0.021789012 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.18       |
|    explained_variance   | 0.0639      |
|    learning_rate        | 0.0003      |
|    loss                 | 29.2        |
|    n_updates            | 3720        |
|    policy_gradient_loss | -0.00366    |
|    std                  | 0.536       |
|    value_loss           | 1.07e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.79e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 374        |
|    time_elapsed         | 213836     |
|    total_timesteps      | 765952     |
| train/                  |            |
|    approx_kl            | 0.04642316 |
|    clip_fraction        | 0.307      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.17      |
|    explained_variance   | -0.38      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0855     |
|    n_updates            | 3730       |
|    policy_gradient_loss | 0.00537    |
|    std                  | 0.535      |
|    value_loss           | 0.245      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.79e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 375        |
|    time_elapsed         | 214041     |
|    total_timesteps      | 768000     |
| train/                  |            |
|    approx_kl            | 0.03587714 |
|    clip_fraction        | 0.292      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.18      |
|    explained_variance   | -0.00126   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.153      |
|    n_updates            | 3740       |
|    policy_gradient_loss | 0.00328    |
|    std                  | 0.536      |
|    value_loss           | 0.27       |
----------------------------------------
Eval num_timesteps=770000, episode_reward=-99.86 +/- 0.06
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 770000      |
| train/                  |             |
|    approx_kl            | 0.061592795 |
|    clip_fraction        | 0.266       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.19       |
|    explained_variance   | 0.00186     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.147       |
|    n_updates            | 3750        |
|    policy_gradient_loss | 0.00611     |
|    std                  | 0.537       |
|    value_loss           | 0.259       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.79e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 376      |
|    time_elapsed    | 216047   |
|    total_timesteps | 770048   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.79e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 377         |
|    time_elapsed         | 216253      |
|    total_timesteps      | 772096      |
| train/                  |             |
|    approx_kl            | 0.031174574 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.21       |
|    explained_variance   | -0.0464     |
|    learning_rate        | 0.0003      |
|    loss                 | 219         |
|    n_updates            | 3760        |
|    policy_gradient_loss | 0.00203     |
|    std                  | 0.537       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.8e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 378         |
|    time_elapsed         | 216458      |
|    total_timesteps      | 774144      |
| train/                  |             |
|    approx_kl            | 0.037824668 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.2        |
|    explained_variance   | -0.0166     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.163       |
|    n_updates            | 3770        |
|    policy_gradient_loss | 0.0011      |
|    std                  | 0.536       |
|    value_loss           | 0.315       |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.8e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 379       |
|    time_elapsed         | 216664    |
|    total_timesteps      | 776192    |
| train/                  |           |
|    approx_kl            | 0.0372726 |
|    clip_fraction        | 0.278     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.16     |
|    explained_variance   | -0.00153  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.168     |
|    n_updates            | 3780      |
|    policy_gradient_loss | 0.0025    |
|    std                  | 0.533     |
|    value_loss           | 0.322     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.8e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 380         |
|    time_elapsed         | 216869      |
|    total_timesteps      | 778240      |
| train/                  |             |
|    approx_kl            | 0.060323827 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.13       |
|    explained_variance   | 0.00696     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.229       |
|    n_updates            | 3790        |
|    policy_gradient_loss | 0.00913     |
|    std                  | 0.532       |
|    value_loss           | 0.31        |
-----------------------------------------
Eval num_timesteps=780000, episode_reward=-99.86 +/- 0.05
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 780000     |
| train/                  |            |
|    approx_kl            | 0.03531186 |
|    clip_fraction        | 0.246      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.11      |
|    explained_variance   | -3.73      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.203      |
|    n_updates            | 3800       |
|    policy_gradient_loss | 0.00752    |
|    std                  | 0.531      |
|    value_loss           | 0.42       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.79e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 381      |
|    time_elapsed    | 218876   |
|    total_timesteps | 780288   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.79e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 382         |
|    time_elapsed         | 219081      |
|    total_timesteps      | 782336      |
| train/                  |             |
|    approx_kl            | 0.017085055 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.1        |
|    explained_variance   | -0.0321     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.12e+03    |
|    n_updates            | 3810        |
|    policy_gradient_loss | 0.00232     |
|    std                  | 0.531       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.81e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 383         |
|    time_elapsed         | 219286      |
|    total_timesteps      | 784384      |
| train/                  |             |
|    approx_kl            | 0.027779466 |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.1        |
|    explained_variance   | -0.00452    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0942      |
|    n_updates            | 3820        |
|    policy_gradient_loss | 0.00307     |
|    std                  | 0.532       |
|    value_loss           | 0.275       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.81e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 384         |
|    time_elapsed         | 219492      |
|    total_timesteps      | 786432      |
| train/                  |             |
|    approx_kl            | 0.020508327 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.1        |
|    explained_variance   | 0.832       |
|    learning_rate        | 0.0003      |
|    loss                 | 16.1        |
|    n_updates            | 3830        |
|    policy_gradient_loss | 0.00624     |
|    std                  | 0.532       |
|    value_loss           | 22.6        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.81e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 385        |
|    time_elapsed         | 219697     |
|    total_timesteps      | 788480     |
| train/                  |            |
|    approx_kl            | 0.03137127 |
|    clip_fraction        | 0.28       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.06      |
|    explained_variance   | 0.000233   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.158      |
|    n_updates            | 3840       |
|    policy_gradient_loss | 0.00624    |
|    std                  | 0.527      |
|    value_loss           | 0.282      |
----------------------------------------
Eval num_timesteps=790000, episode_reward=-99.83 +/- 0.06
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 790000      |
| train/                  |             |
|    approx_kl            | 0.062077783 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.02       |
|    explained_variance   | 0.666       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.331       |
|    n_updates            | 3850        |
|    policy_gradient_loss | -0.000851   |
|    std                  | 0.526       |
|    value_loss           | 3.26        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.8e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 386      |
|    time_elapsed    | 221705   |
|    total_timesteps | 790528   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.8e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 387         |
|    time_elapsed         | 221910      |
|    total_timesteps      | 792576      |
| train/                  |             |
|    approx_kl            | 0.013088914 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.01       |
|    explained_variance   | 0.0226      |
|    learning_rate        | 0.0003      |
|    loss                 | 472         |
|    n_updates            | 3860        |
|    policy_gradient_loss | 0.00444     |
|    std                  | 0.525       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.82e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 388        |
|    time_elapsed         | 222116     |
|    total_timesteps      | 794624     |
| train/                  |            |
|    approx_kl            | 0.09786695 |
|    clip_fraction        | 0.309      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6         |
|    explained_variance   | -0.618     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.18       |
|    n_updates            | 3870       |
|    policy_gradient_loss | 0.0146     |
|    std                  | 0.524      |
|    value_loss           | 0.34       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.82e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 389        |
|    time_elapsed         | 222321     |
|    total_timesteps      | 796672     |
| train/                  |            |
|    approx_kl            | 0.07109529 |
|    clip_fraction        | 0.321      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.99      |
|    explained_variance   | -7.83      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.126      |
|    n_updates            | 3880       |
|    policy_gradient_loss | 0.00799    |
|    std                  | 0.525      |
|    value_loss           | 0.33       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.82e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 390       |
|    time_elapsed         | 222526    |
|    total_timesteps      | 798720    |
| train/                  |           |
|    approx_kl            | 0.0443781 |
|    clip_fraction        | 0.299     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.99     |
|    explained_variance   | 0.00133   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.161     |
|    n_updates            | 3890      |
|    policy_gradient_loss | 0.00478   |
|    std                  | 0.525     |
|    value_loss           | 0.295     |
---------------------------------------
Eval num_timesteps=800000, episode_reward=-99.87 +/- 0.05
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 800000     |
| train/                  |            |
|    approx_kl            | 0.20451568 |
|    clip_fraction        | 0.279      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.98      |
|    explained_variance   | 0.00766    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0778     |
|    n_updates            | 3900       |
|    policy_gradient_loss | 0.00629    |
|    std                  | 0.523      |
|    value_loss           | 0.264      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.81e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 391      |
|    time_elapsed    | 224532   |
|    total_timesteps | 800768   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.81e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 392        |
|    time_elapsed         | 224738     |
|    total_timesteps      | 802816     |
| train/                  |            |
|    approx_kl            | 0.04175347 |
|    clip_fraction        | 0.308      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.97      |
|    explained_variance   | -1.05e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 446        |
|    n_updates            | 3910       |
|    policy_gradient_loss | -0.0027    |
|    std                  | 0.523      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.83e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 393         |
|    time_elapsed         | 224943      |
|    total_timesteps      | 804864      |
| train/                  |             |
|    approx_kl            | 0.046150796 |
|    clip_fraction        | 0.266       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.95       |
|    explained_variance   | 0.00598     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.104       |
|    n_updates            | 3920        |
|    policy_gradient_loss | 0.00427     |
|    std                  | 0.52        |
|    value_loss           | 0.296       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.83e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 394         |
|    time_elapsed         | 225154      |
|    total_timesteps      | 806912      |
| train/                  |             |
|    approx_kl            | 0.036352105 |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.93       |
|    explained_variance   | 0.122       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.259       |
|    n_updates            | 3930        |
|    policy_gradient_loss | -0.00218    |
|    std                  | 0.52        |
|    value_loss           | 0.346       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.83e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 395         |
|    time_elapsed         | 225360      |
|    total_timesteps      | 808960      |
| train/                  |             |
|    approx_kl            | 0.032919727 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.9        |
|    explained_variance   | -0.000348   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0383      |
|    n_updates            | 3940        |
|    policy_gradient_loss | 0.00562     |
|    std                  | 0.517       |
|    value_loss           | 0.237       |
-----------------------------------------
Eval num_timesteps=810000, episode_reward=-99.84 +/- 0.04
Episode length: 3600.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 810000      |
| train/                  |             |
|    approx_kl            | 0.047856957 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.88       |
|    explained_variance   | 0.786       |
|    learning_rate        | 0.0003      |
|    loss                 | 10.7        |
|    n_updates            | 3950        |
|    policy_gradient_loss | 0.0083      |
|    std                  | 0.517       |
|    value_loss           | 34.3        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.82e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 396      |
|    time_elapsed    | 227366   |
|    total_timesteps | 811008   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.82e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 397         |
|    time_elapsed         | 227571      |
|    total_timesteps      | 813056      |
| train/                  |             |
|    approx_kl            | 0.032744292 |
|    clip_fraction        | 0.31        |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.88       |
|    explained_variance   | 7.1e-05     |
|    learning_rate        | 0.0003      |
|    loss                 | 944         |
|    n_updates            | 3960        |
|    policy_gradient_loss | -0.00319    |
|    std                  | 0.517       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.84e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 398        |
|    time_elapsed         | 227777     |
|    total_timesteps      | 815104     |
| train/                  |            |
|    approx_kl            | 0.09615082 |
|    clip_fraction        | 0.299      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.87      |
|    explained_variance   | -0.012     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.145      |
|    n_updates            | 3970       |
|    policy_gradient_loss | 0.00284    |
|    std                  | 0.514      |
|    value_loss           | 0.311      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.84e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 399        |
|    time_elapsed         | 227982     |
|    total_timesteps      | 817152     |
| train/                  |            |
|    approx_kl            | 0.03921225 |
|    clip_fraction        | 0.28       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.89      |
|    explained_variance   | -0.000567  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.165      |
|    n_updates            | 3980       |
|    policy_gradient_loss | 0.00597    |
|    std                  | 0.517      |
|    value_loss           | 0.28       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.84e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 400         |
|    time_elapsed         | 228187      |
|    total_timesteps      | 819200      |
| train/                  |             |
|    approx_kl            | 0.040113732 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.9        |
|    explained_variance   | 0.00354     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.131       |
|    n_updates            | 3990        |
|    policy_gradient_loss | 0.00464     |
|    std                  | 0.515       |
|    value_loss           | 0.292       |
-----------------------------------------
Eval num_timesteps=820000, episode_reward=-99.83 +/- 0.05
Episode length: 3597.40 +/- 5.82
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 820000      |
| train/                  |             |
|    approx_kl            | 0.118595526 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.88       |
|    explained_variance   | -0.0224     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.122       |
|    n_updates            | 4000        |
|    policy_gradient_loss | 6.01e-05    |
|    std                  | 0.515       |
|    value_loss           | 0.384       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.83e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 401      |
|    time_elapsed    | 230194   |
|    total_timesteps | 821248   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.83e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 402         |
|    time_elapsed         | 230399      |
|    total_timesteps      | 823296      |
| train/                  |             |
|    approx_kl            | 0.040521324 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.89       |
|    explained_variance   | -5.09e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 79.8        |
|    n_updates            | 4010        |
|    policy_gradient_loss | -0.00194    |
|    std                  | 0.516       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.84e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 403        |
|    time_elapsed         | 230605     |
|    total_timesteps      | 825344     |
| train/                  |            |
|    approx_kl            | 0.05459719 |
|    clip_fraction        | 0.286      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.86      |
|    explained_variance   | -0.00483   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.18       |
|    n_updates            | 4020       |
|    policy_gradient_loss | 0.0103     |
|    std                  | 0.513      |
|    value_loss           | 0.263      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.85e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 404         |
|    time_elapsed         | 230810      |
|    total_timesteps      | 827392      |
| train/                  |             |
|    approx_kl            | 0.079628535 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.82       |
|    explained_variance   | 0.059       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.153       |
|    n_updates            | 4030        |
|    policy_gradient_loss | -0.00103    |
|    std                  | 0.512       |
|    value_loss           | 0.323       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.85e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 405        |
|    time_elapsed         | 231015     |
|    total_timesteps      | 829440     |
| train/                  |            |
|    approx_kl            | 0.22210684 |
|    clip_fraction        | 0.273      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.81      |
|    explained_variance   | -0.564     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.204      |
|    n_updates            | 4040       |
|    policy_gradient_loss | 0.00497    |
|    std                  | 0.511      |
|    value_loss           | 3.76       |
----------------------------------------
Eval num_timesteps=830000, episode_reward=-99.81 +/- 0.06
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 830000     |
| train/                  |            |
|    approx_kl            | 0.08120261 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.77      |
|    explained_variance   | 0.00638    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.182      |
|    n_updates            | 4050       |
|    policy_gradient_loss | 0.0122     |
|    std                  | 0.507      |
|    value_loss           | 0.368      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.84e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 406      |
|    time_elapsed    | 233027   |
|    total_timesteps | 831488   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.84e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 407         |
|    time_elapsed         | 233233      |
|    total_timesteps      | 833536      |
| train/                  |             |
|    approx_kl            | 0.054198995 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.74       |
|    explained_variance   | 0.0382      |
|    learning_rate        | 0.0003      |
|    loss                 | 6.9         |
|    n_updates            | 4060        |
|    policy_gradient_loss | -0.0015     |
|    std                  | 0.507       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.85e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 408        |
|    time_elapsed         | 233438     |
|    total_timesteps      | 835584     |
| train/                  |            |
|    approx_kl            | 0.19137505 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.76      |
|    explained_variance   | 0.00215    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.138      |
|    n_updates            | 4070       |
|    policy_gradient_loss | 0.00519    |
|    std                  | 0.508      |
|    value_loss           | 0.357      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.85e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 409         |
|    time_elapsed         | 233643      |
|    total_timesteps      | 837632      |
| train/                  |             |
|    approx_kl            | 0.042768106 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.77       |
|    explained_variance   | -0.018      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.166       |
|    n_updates            | 4080        |
|    policy_gradient_loss | 0.00201     |
|    std                  | 0.509       |
|    value_loss           | 0.31        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.85e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 410        |
|    time_elapsed         | 233849     |
|    total_timesteps      | 839680     |
| train/                  |            |
|    approx_kl            | 0.05734725 |
|    clip_fraction        | 0.263      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.79      |
|    explained_variance   | -0.000432  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.136      |
|    n_updates            | 4090       |
|    policy_gradient_loss | -3.35e-05  |
|    std                  | 0.51       |
|    value_loss           | 0.203      |
----------------------------------------
Eval num_timesteps=840000, episode_reward=-99.80 +/- 0.07
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 840000      |
| train/                  |             |
|    approx_kl            | 0.033837706 |
|    clip_fraction        | 0.264       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.79       |
|    explained_variance   | 2.95e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.161       |
|    n_updates            | 4100        |
|    policy_gradient_loss | 0.00547     |
|    std                  | 0.51        |
|    value_loss           | 0.282       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.84e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 411      |
|    time_elapsed    | 235855   |
|    total_timesteps | 841728   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.86e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 412         |
|    time_elapsed         | 236060      |
|    total_timesteps      | 843776      |
| train/                  |             |
|    approx_kl            | 0.012695556 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.8        |
|    explained_variance   | 0.101       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.34e+03    |
|    n_updates            | 4110        |
|    policy_gradient_loss | -0.00132    |
|    std                  | 0.51        |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.86e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 413         |
|    time_elapsed         | 236265      |
|    total_timesteps      | 845824      |
| train/                  |             |
|    approx_kl            | 0.019221397 |
|    clip_fraction        | 0.0527      |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.8        |
|    explained_variance   | 0.945       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.41        |
|    n_updates            | 4120        |
|    policy_gradient_loss | 0.000581    |
|    std                  | 0.51        |
|    value_loss           | 11.1        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.86e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 414         |
|    time_elapsed         | 236471      |
|    total_timesteps      | 847872      |
| train/                  |             |
|    approx_kl            | 0.033570245 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.75       |
|    explained_variance   | 0.118       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.133       |
|    n_updates            | 4130        |
|    policy_gradient_loss | 0.00215     |
|    std                  | 0.505       |
|    value_loss           | 0.285       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.86e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 415         |
|    time_elapsed         | 236676      |
|    total_timesteps      | 849920      |
| train/                  |             |
|    approx_kl            | 0.041606557 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.74       |
|    explained_variance   | 0.575       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.14        |
|    n_updates            | 4140        |
|    policy_gradient_loss | 0.000694    |
|    std                  | 0.506       |
|    value_loss           | 5.24        |
-----------------------------------------
Eval num_timesteps=850000, episode_reward=-99.84 +/- 0.05
Episode length: 3599.40 +/- 3.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 850000      |
| train/                  |             |
|    approx_kl            | 0.046895713 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.74       |
|    explained_variance   | 0.00336     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.126       |
|    n_updates            | 4150        |
|    policy_gradient_loss | 0.00236     |
|    std                  | 0.506       |
|    value_loss           | 0.282       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.85e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 416      |
|    time_elapsed    | 238683   |
|    total_timesteps | 851968   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.86e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 417         |
|    time_elapsed         | 238890      |
|    total_timesteps      | 854016      |
| train/                  |             |
|    approx_kl            | 0.024766741 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.74       |
|    explained_variance   | -0.000165   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.94e+03    |
|    n_updates            | 4160        |
|    policy_gradient_loss | -0.00493    |
|    std                  | 0.506       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.86e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 418       |
|    time_elapsed         | 239095    |
|    total_timesteps      | 856064    |
| train/                  |           |
|    approx_kl            | 0.1633462 |
|    clip_fraction        | 0.302     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.75     |
|    explained_variance   | 0.0324    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.0955    |
|    n_updates            | 4170      |
|    policy_gradient_loss | 0.0122    |
|    std                  | 0.507     |
|    value_loss           | 0.263     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.86e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 419        |
|    time_elapsed         | 239301     |
|    total_timesteps      | 858112     |
| train/                  |            |
|    approx_kl            | 0.07710514 |
|    clip_fraction        | 0.262      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.72      |
|    explained_variance   | 0.000585   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.173      |
|    n_updates            | 4180       |
|    policy_gradient_loss | 0.00368    |
|    std                  | 0.504      |
|    value_loss           | 0.284      |
----------------------------------------
Eval num_timesteps=860000, episode_reward=-99.80 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 860000      |
| train/                  |             |
|    approx_kl            | 0.031105887 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.69       |
|    explained_variance   | 0.871       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.53        |
|    n_updates            | 4190        |
|    policy_gradient_loss | 0.00133     |
|    std                  | 0.504       |
|    value_loss           | 27.9        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.85e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 420      |
|    time_elapsed    | 241307   |
|    total_timesteps | 860160   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.85e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 421        |
|    time_elapsed         | 241513     |
|    total_timesteps      | 862208     |
| train/                  |            |
|    approx_kl            | 0.08652198 |
|    clip_fraction        | 0.317      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.7       |
|    explained_variance   | -0.000361  |
|    learning_rate        | 0.0003     |
|    loss                 | 1.75e+03   |
|    n_updates            | 4200       |
|    policy_gradient_loss | 0.000279   |
|    std                  | 0.505      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.87e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 422         |
|    time_elapsed         | 241718      |
|    total_timesteps      | 864256      |
| train/                  |             |
|    approx_kl            | 0.103395924 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.69       |
|    explained_variance   | 1.57e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.097       |
|    n_updates            | 4210        |
|    policy_gradient_loss | 0.0101      |
|    std                  | 0.502       |
|    value_loss           | 0.275       |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.87e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 423       |
|    time_elapsed         | 241923    |
|    total_timesteps      | 866304    |
| train/                  |           |
|    approx_kl            | 0.0642263 |
|    clip_fraction        | 0.285     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.68     |
|    explained_variance   | 0.318     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.262     |
|    n_updates            | 4220      |
|    policy_gradient_loss | 0.00216   |
|    std                  | 0.502     |
|    value_loss           | 6.37      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.87e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 424         |
|    time_elapsed         | 242129      |
|    total_timesteps      | 868352      |
| train/                  |             |
|    approx_kl            | 0.035879664 |
|    clip_fraction        | 0.305       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.66       |
|    explained_variance   | 3.49e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.107       |
|    n_updates            | 4230        |
|    policy_gradient_loss | 0.00522     |
|    std                  | 0.501       |
|    value_loss           | 0.182       |
-----------------------------------------
Eval num_timesteps=870000, episode_reward=-99.83 +/- 0.05
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 870000     |
| train/                  |            |
|    approx_kl            | 0.03920825 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.64      |
|    explained_variance   | -0.00049   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.141      |
|    n_updates            | 4240       |
|    policy_gradient_loss | -0.00303   |
|    std                  | 0.5        |
|    value_loss           | 0.266      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.86e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 425      |
|    time_elapsed    | 244135   |
|    total_timesteps | 870400   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.86e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 426        |
|    time_elapsed         | 244340     |
|    total_timesteps      | 872448     |
| train/                  |            |
|    approx_kl            | 0.06516683 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.62      |
|    explained_variance   | -3.58e-07  |
|    learning_rate        | 0.0003     |
|    loss                 | 4.82       |
|    n_updates            | 4250       |
|    policy_gradient_loss | -0.00291   |
|    std                  | 0.499      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.87e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 427        |
|    time_elapsed         | 244546     |
|    total_timesteps      | 874496     |
| train/                  |            |
|    approx_kl            | 0.02910265 |
|    clip_fraction        | 0.247      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.61      |
|    explained_variance   | 0.000238   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0923     |
|    n_updates            | 4260       |
|    policy_gradient_loss | 0.0077     |
|    std                  | 0.499      |
|    value_loss           | 0.207      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.87e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 428         |
|    time_elapsed         | 244751      |
|    total_timesteps      | 876544      |
| train/                  |             |
|    approx_kl            | 0.058587417 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.62       |
|    explained_variance   | 0.00215     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.109       |
|    n_updates            | 4270        |
|    policy_gradient_loss | 0.00685     |
|    std                  | 0.499       |
|    value_loss           | 0.28        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.88e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 429         |
|    time_elapsed         | 244957      |
|    total_timesteps      | 878592      |
| train/                  |             |
|    approx_kl            | 0.041004788 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.62       |
|    explained_variance   | -0.000166   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.133       |
|    n_updates            | 4280        |
|    policy_gradient_loss | 0.00419     |
|    std                  | 0.498       |
|    value_loss           | 0.189       |
-----------------------------------------
Eval num_timesteps=880000, episode_reward=-99.78 +/- 0.12
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 880000      |
| train/                  |             |
|    approx_kl            | 0.018224217 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.61       |
|    explained_variance   | 0.871       |
|    learning_rate        | 0.0003      |
|    loss                 | 16.5        |
|    n_updates            | 4290        |
|    policy_gradient_loss | -0.00699    |
|    std                  | 0.498       |
|    value_loss           | 35.3        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.87e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 430      |
|    time_elapsed    | 246962   |
|    total_timesteps | 880640   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.87e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 431         |
|    time_elapsed         | 247168      |
|    total_timesteps      | 882688      |
| train/                  |             |
|    approx_kl            | 0.018083882 |
|    clip_fraction        | 0.166       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.61       |
|    explained_variance   | -8.34e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 307         |
|    n_updates            | 4300        |
|    policy_gradient_loss | 0.00102     |
|    std                  | 0.498       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 2.88e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 432      |
|    time_elapsed         | 247373   |
|    total_timesteps      | 884736   |
| train/                  |          |
|    approx_kl            | 2.375632 |
|    clip_fraction        | 0.331    |
|    clip_range           | 0.2      |
|    entropy_loss         | -5.62    |
|    explained_variance   | -2.77    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.0592   |
|    n_updates            | 4310     |
|    policy_gradient_loss | -0.00251 |
|    std                  | 0.499    |
|    value_loss           | 0.202    |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.88e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 433        |
|    time_elapsed         | 247581     |
|    total_timesteps      | 886784     |
| train/                  |            |
|    approx_kl            | 0.22267118 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.59      |
|    explained_variance   | 3.18e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.235      |
|    n_updates            | 4320       |
|    policy_gradient_loss | 0.0232     |
|    std                  | 0.495      |
|    value_loss           | 0.585      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.88e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 434       |
|    time_elapsed         | 247786    |
|    total_timesteps      | 888832    |
| train/                  |           |
|    approx_kl            | 0.1905409 |
|    clip_fraction        | 0.298     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.56     |
|    explained_variance   | 0.000685  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.327     |
|    n_updates            | 4330      |
|    policy_gradient_loss | 0.0113    |
|    std                  | 0.496     |
|    value_loss           | 0.488     |
---------------------------------------
Eval num_timesteps=890000, episode_reward=-99.72 +/- 0.09
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 890000     |
| train/                  |            |
|    approx_kl            | 0.11024672 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.57      |
|    explained_variance   | 0.517      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.235      |
|    n_updates            | 4340       |
|    policy_gradient_loss | -0.00236   |
|    std                  | 0.496      |
|    value_loss           | 0.698      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.87e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 435      |
|    time_elapsed    | 249792   |
|    total_timesteps | 890880   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.87e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 436        |
|    time_elapsed         | 249998     |
|    total_timesteps      | 892928     |
| train/                  |            |
|    approx_kl            | 0.10419983 |
|    clip_fraction        | 0.151      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.57      |
|    explained_variance   | 0.22       |
|    learning_rate        | 0.0003     |
|    loss                 | 2.02e+03   |
|    n_updates            | 4350       |
|    policy_gradient_loss | 0.000975   |
|    std                  | 0.496      |
|    value_loss           | 1.06e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.88e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 437        |
|    time_elapsed         | 250203     |
|    total_timesteps      | 894976     |
| train/                  |            |
|    approx_kl            | 0.40567923 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.57      |
|    explained_variance   | -0.632     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.328      |
|    n_updates            | 4360       |
|    policy_gradient_loss | 0.0174     |
|    std                  | 0.496      |
|    value_loss           | 0.634      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.88e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 438       |
|    time_elapsed         | 250409    |
|    total_timesteps      | 897024    |
| train/                  |           |
|    approx_kl            | 0.1948451 |
|    clip_fraction        | 0.304     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.56     |
|    explained_variance   | 0.958     |
|    learning_rate        | 0.0003    |
|    loss                 | 12        |
|    n_updates            | 4370      |
|    policy_gradient_loss | 0.0044    |
|    std                  | 0.495     |
|    value_loss           | 9.75      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.88e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 439        |
|    time_elapsed         | 250615     |
|    total_timesteps      | 899072     |
| train/                  |            |
|    approx_kl            | 0.04010114 |
|    clip_fraction        | 0.317      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.53      |
|    explained_variance   | 0.000211   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.182      |
|    n_updates            | 4380       |
|    policy_gradient_loss | 0.00612    |
|    std                  | 0.494      |
|    value_loss           | 0.252      |
----------------------------------------
Eval num_timesteps=900000, episode_reward=-99.82 +/- 0.07
Episode length: 3600.60 +/- 0.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 900000    |
| train/                  |           |
|    approx_kl            | 0.0576093 |
|    clip_fraction        | 0.296     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.49     |
|    explained_variance   | -9.62     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.149     |
|    n_updates            | 4390      |
|    policy_gradient_loss | 0.00232   |
|    std                  | 0.49      |
|    value_loss           | 0.606     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.87e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 440      |
|    time_elapsed    | 252622   |
|    total_timesteps | 901120   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.87e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 441        |
|    time_elapsed         | 252827     |
|    total_timesteps      | 903168     |
| train/                  |            |
|    approx_kl            | 0.02101388 |
|    clip_fraction        | 0.204      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.46      |
|    explained_variance   | 0.372      |
|    learning_rate        | 0.0003     |
|    loss                 | 48.5       |
|    n_updates            | 4400       |
|    policy_gradient_loss | -0.00442   |
|    std                  | 0.489      |
|    value_loss           | 1.06e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 442         |
|    time_elapsed         | 253032      |
|    total_timesteps      | 905216      |
| train/                  |             |
|    approx_kl            | 0.031766754 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.44       |
|    explained_variance   | -4.77e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.193       |
|    n_updates            | 4410        |
|    policy_gradient_loss | 0.00972     |
|    std                  | 0.487       |
|    value_loss           | 0.284       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 443         |
|    time_elapsed         | 253238      |
|    total_timesteps      | 907264      |
| train/                  |             |
|    approx_kl            | 0.053107083 |
|    clip_fraction        | 0.339       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.43       |
|    explained_variance   | 0.000162    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.216       |
|    n_updates            | 4420        |
|    policy_gradient_loss | -0.00119    |
|    std                  | 0.488       |
|    value_loss           | 0.337       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 444         |
|    time_elapsed         | 253443      |
|    total_timesteps      | 909312      |
| train/                  |             |
|    approx_kl            | 0.028060779 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.47       |
|    explained_variance   | -0.0152     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0743      |
|    n_updates            | 4430        |
|    policy_gradient_loss | -0.00178    |
|    std                  | 0.49        |
|    value_loss           | 0.227       |
-----------------------------------------
Eval num_timesteps=910000, episode_reward=-99.75 +/- 0.11
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 910000      |
| train/                  |             |
|    approx_kl            | 0.055413514 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.49       |
|    explained_variance   | 0.00365     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.119       |
|    n_updates            | 4440        |
|    policy_gradient_loss | 0.00296     |
|    std                  | 0.49        |
|    value_loss           | 0.302       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.88e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 445      |
|    time_elapsed    | 255451   |
|    total_timesteps | 911360   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.88e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 446         |
|    time_elapsed         | 255657      |
|    total_timesteps      | 913408      |
| train/                  |             |
|    approx_kl            | 0.017935555 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.5        |
|    explained_variance   | -0.000107   |
|    learning_rate        | 0.0003      |
|    loss                 | 5.66        |
|    n_updates            | 4450        |
|    policy_gradient_loss | -0.00544    |
|    std                  | 0.49        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 447         |
|    time_elapsed         | 255862      |
|    total_timesteps      | 915456      |
| train/                  |             |
|    approx_kl            | 0.036396585 |
|    clip_fraction        | 0.263       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.5        |
|    explained_variance   | -0.000168   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0883      |
|    n_updates            | 4460        |
|    policy_gradient_loss | 0.00483     |
|    std                  | 0.491       |
|    value_loss           | 0.227       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 448         |
|    time_elapsed         | 256068      |
|    total_timesteps      | 917504      |
| train/                  |             |
|    approx_kl            | 0.021618031 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.47       |
|    explained_variance   | 0.000677    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.158       |
|    n_updates            | 4470        |
|    policy_gradient_loss | 0.00213     |
|    std                  | 0.487       |
|    value_loss           | 0.218       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 449         |
|    time_elapsed         | 256273      |
|    total_timesteps      | 919552      |
| train/                  |             |
|    approx_kl            | 0.026769675 |
|    clip_fraction        | 0.242       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.43       |
|    explained_variance   | 0.988       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.201       |
|    n_updates            | 4480        |
|    policy_gradient_loss | -0.00897    |
|    std                  | 0.486       |
|    value_loss           | 4.05        |
-----------------------------------------
Eval num_timesteps=920000, episode_reward=-99.83 +/- 0.02
Episode length: 3600.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 920000      |
| train/                  |             |
|    approx_kl            | 0.027481724 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.42       |
|    explained_variance   | 0.934       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.38        |
|    n_updates            | 4490        |
|    policy_gradient_loss | -0.00262    |
|    std                  | 0.485       |
|    value_loss           | 25.6        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.88e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 450      |
|    time_elapsed    | 258279   |
|    total_timesteps | 921600   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 451         |
|    time_elapsed         | 258484      |
|    total_timesteps      | 923648      |
| train/                  |             |
|    approx_kl            | 0.018269133 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.41       |
|    explained_variance   | 0.43        |
|    learning_rate        | 0.0003      |
|    loss                 | 137         |
|    n_updates            | 4500        |
|    policy_gradient_loss | -0.0103     |
|    std                  | 0.485       |
|    value_loss           | 1.07e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 452         |
|    time_elapsed         | 258689      |
|    total_timesteps      | 925696      |
| train/                  |             |
|    approx_kl            | 0.036951598 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.4        |
|    explained_variance   | 1.79e-07    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.119       |
|    n_updates            | 4510        |
|    policy_gradient_loss | 0.0106      |
|    std                  | 0.483       |
|    value_loss           | 0.218       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 453         |
|    time_elapsed         | 258895      |
|    total_timesteps      | 927744      |
| train/                  |             |
|    approx_kl            | 0.075862266 |
|    clip_fraction        | 0.296       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.36       |
|    explained_variance   | 1.21e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.56        |
|    n_updates            | 4520        |
|    policy_gradient_loss | 0.00672     |
|    std                  | 0.481       |
|    value_loss           | 0.239       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 454         |
|    time_elapsed         | 259100      |
|    total_timesteps      | 929792      |
| train/                  |             |
|    approx_kl            | 0.026024595 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.36       |
|    explained_variance   | 0.816       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.89        |
|    n_updates            | 4530        |
|    policy_gradient_loss | 6.36e-05    |
|    std                  | 0.482       |
|    value_loss           | 17.8        |
-----------------------------------------
Eval num_timesteps=930000, episode_reward=-99.85 +/- 0.05
Episode length: 3596.80 +/- 6.08
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 930000     |
| train/                  |            |
|    approx_kl            | 0.02710405 |
|    clip_fraction        | 0.265      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.37      |
|    explained_variance   | -0.0122    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.147      |
|    n_updates            | 4540       |
|    policy_gradient_loss | 0.00543    |
|    std                  | 0.482      |
|    value_loss           | 0.239      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.88e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 455      |
|    time_elapsed    | 261111   |
|    total_timesteps | 931840   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 456         |
|    time_elapsed         | 261317      |
|    total_timesteps      | 933888      |
| train/                  |             |
|    approx_kl            | 0.024114009 |
|    clip_fraction        | 0.224       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.38       |
|    explained_variance   | 0.00731     |
|    learning_rate        | 0.0003      |
|    loss                 | 568         |
|    n_updates            | 4550        |
|    policy_gradient_loss | -0.00293    |
|    std                  | 0.483       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.89e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 457        |
|    time_elapsed         | 261522     |
|    total_timesteps      | 935936     |
| train/                  |            |
|    approx_kl            | 0.09143759 |
|    clip_fraction        | 0.283      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.38      |
|    explained_variance   | -6.71      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.313      |
|    n_updates            | 4560       |
|    policy_gradient_loss | 0.000234   |
|    std                  | 0.483      |
|    value_loss           | 0.471      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.9e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 458         |
|    time_elapsed         | 261728      |
|    total_timesteps      | 937984      |
| train/                  |             |
|    approx_kl            | 0.108563736 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.41       |
|    explained_variance   | 9.65e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0916      |
|    n_updates            | 4570        |
|    policy_gradient_loss | 0.00692     |
|    std                  | 0.488       |
|    value_loss           | 0.307       |
-----------------------------------------
Eval num_timesteps=940000, episode_reward=-99.74 +/- 0.10
Episode length: 3600.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 940000      |
| train/                  |             |
|    approx_kl            | 0.039966173 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.46       |
|    explained_variance   | -0.0432     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.075       |
|    n_updates            | 4580        |
|    policy_gradient_loss | 0.00746     |
|    std                  | 0.488       |
|    value_loss           | 0.234       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.89e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 459      |
|    time_elapsed    | 263734   |
|    total_timesteps | 940032   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.89e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 460        |
|    time_elapsed         | 263940     |
|    total_timesteps      | 942080     |
| train/                  |            |
|    approx_kl            | 0.05331152 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.47      |
|    explained_variance   | 0.0753     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.12e+03   |
|    n_updates            | 4590       |
|    policy_gradient_loss | -0.00267   |
|    std                  | 0.489      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.9e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 461         |
|    time_elapsed         | 264145      |
|    total_timesteps      | 944128      |
| train/                  |             |
|    approx_kl            | 0.042861678 |
|    clip_fraction        | 0.235       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.48       |
|    explained_variance   | 0.966       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.1         |
|    n_updates            | 4600        |
|    policy_gradient_loss | -0.00501    |
|    std                  | 0.489       |
|    value_loss           | 17.6        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.9e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 462        |
|    time_elapsed         | 264351     |
|    total_timesteps      | 946176     |
| train/                  |            |
|    approx_kl            | 0.07325087 |
|    clip_fraction        | 0.303      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.48      |
|    explained_variance   | 0.88       |
|    learning_rate        | 0.0003     |
|    loss                 | 4.4        |
|    n_updates            | 4610       |
|    policy_gradient_loss | -0.000559  |
|    std                  | 0.49       |
|    value_loss           | 8.61       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.9e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 463         |
|    time_elapsed         | 264557      |
|    total_timesteps      | 948224      |
| train/                  |             |
|    approx_kl            | 0.066921934 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.49       |
|    explained_variance   | -0.0147     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0979      |
|    n_updates            | 4620        |
|    policy_gradient_loss | 0.00889     |
|    std                  | 0.49        |
|    value_loss           | 0.189       |
-----------------------------------------
Eval num_timesteps=950000, episode_reward=-99.86 +/- 0.07
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 950000     |
| train/                  |            |
|    approx_kl            | 0.08240719 |
|    clip_fraction        | 0.283      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.46      |
|    explained_variance   | 0.0234     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.094      |
|    n_updates            | 4630       |
|    policy_gradient_loss | 0.00338    |
|    std                  | 0.487      |
|    value_loss           | 0.231      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.89e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 464      |
|    time_elapsed    | 266565   |
|    total_timesteps | 950272   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 465         |
|    time_elapsed         | 266770      |
|    total_timesteps      | 952320      |
| train/                  |             |
|    approx_kl            | 0.030845517 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.44       |
|    explained_variance   | 0.0892      |
|    learning_rate        | 0.0003      |
|    loss                 | 162         |
|    n_updates            | 4640        |
|    policy_gradient_loss | -0.00584    |
|    std                  | 0.486       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 466        |
|    time_elapsed         | 266976     |
|    total_timesteps      | 954368     |
| train/                  |            |
|    approx_kl            | 0.03572937 |
|    clip_fraction        | 0.303      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.43      |
|    explained_variance   | -1.19e-07  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.187      |
|    n_updates            | 4650       |
|    policy_gradient_loss | 0.00449    |
|    std                  | 0.485      |
|    value_loss           | 0.308      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 467        |
|    time_elapsed         | 267181     |
|    total_timesteps      | 956416     |
| train/                  |            |
|    approx_kl            | 0.03170043 |
|    clip_fraction        | 0.284      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.4       |
|    explained_variance   | -0.322     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.18       |
|    n_updates            | 4660       |
|    policy_gradient_loss | 0.00282    |
|    std                  | 0.482      |
|    value_loss           | 0.274      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.91e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 468         |
|    time_elapsed         | 267386      |
|    total_timesteps      | 958464      |
| train/                  |             |
|    approx_kl            | 0.027684709 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.38       |
|    explained_variance   | 9e-06       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.196       |
|    n_updates            | 4670        |
|    policy_gradient_loss | 0.00175     |
|    std                  | 0.482       |
|    value_loss           | 0.266       |
-----------------------------------------
Eval num_timesteps=960000, episode_reward=-99.67 +/- 0.08
Episode length: 3599.60 +/- 1.74
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 960000     |
| train/                  |            |
|    approx_kl            | 0.05875066 |
|    clip_fraction        | 0.226      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.36      |
|    explained_variance   | 0.909      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.77       |
|    n_updates            | 4680       |
|    policy_gradient_loss | -0.00285   |
|    std                  | 0.48       |
|    value_loss           | 14.2       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.9e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 469      |
|    time_elapsed    | 269398   |
|    total_timesteps | 960512   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 2.9e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 470       |
|    time_elapsed         | 269605    |
|    total_timesteps      | 962560    |
| train/                  |           |
|    approx_kl            | 0.0384059 |
|    clip_fraction        | 0.271     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.34     |
|    explained_variance   | 0.125     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.06e+03  |
|    n_updates            | 4690      |
|    policy_gradient_loss | -0.00928  |
|    std                  | 0.479     |
|    value_loss           | 1.06e+03  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.91e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 471         |
|    time_elapsed         | 269811      |
|    total_timesteps      | 964608      |
| train/                  |             |
|    approx_kl            | 0.049684677 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.36       |
|    explained_variance   | -1.55e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0864      |
|    n_updates            | 4700        |
|    policy_gradient_loss | 0.00628     |
|    std                  | 0.482       |
|    value_loss           | 0.185       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.91e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 472         |
|    time_elapsed         | 270017      |
|    total_timesteps      | 966656      |
| train/                  |             |
|    approx_kl            | 0.054805458 |
|    clip_fraction        | 0.317       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.39       |
|    explained_variance   | 0.893       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.2         |
|    n_updates            | 4710        |
|    policy_gradient_loss | -0.00832    |
|    std                  | 0.483       |
|    value_loss           | 8.76        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 473        |
|    time_elapsed         | 270222     |
|    total_timesteps      | 968704     |
| train/                  |            |
|    approx_kl            | 0.07813035 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.38      |
|    explained_variance   | 4.17e-07   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.122      |
|    n_updates            | 4720       |
|    policy_gradient_loss | 0.00354    |
|    std                  | 0.482      |
|    value_loss           | 0.24       |
----------------------------------------
Eval num_timesteps=970000, episode_reward=-99.86 +/- 0.06
Episode length: 3600.20 +/- 1.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 970000     |
| train/                  |            |
|    approx_kl            | 0.07847217 |
|    clip_fraction        | 0.273      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.37      |
|    explained_variance   | -17.4      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0799     |
|    n_updates            | 4730       |
|    policy_gradient_loss | 0.00232    |
|    std                  | 0.483      |
|    value_loss           | 0.982      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.9e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 474      |
|    time_elapsed    | 272229   |
|    total_timesteps | 970752   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.9e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 475        |
|    time_elapsed         | 272434     |
|    total_timesteps      | 972800     |
| train/                  |            |
|    approx_kl            | 0.02386235 |
|    clip_fraction        | 0.296      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.37      |
|    explained_variance   | 0.0316     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.06e+03   |
|    n_updates            | 4740       |
|    policy_gradient_loss | -0.00514   |
|    std                  | 0.482      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.91e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 476         |
|    time_elapsed         | 272642      |
|    total_timesteps      | 974848      |
| train/                  |             |
|    approx_kl            | 0.030952435 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.37       |
|    explained_variance   | 5.06e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.132       |
|    n_updates            | 4750        |
|    policy_gradient_loss | 0.0032      |
|    std                  | 0.483       |
|    value_loss           | 0.253       |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.91e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 477       |
|    time_elapsed         | 272847    |
|    total_timesteps      | 976896    |
| train/                  |           |
|    approx_kl            | 0.0430291 |
|    clip_fraction        | 0.274     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.34     |
|    explained_variance   | -0.738    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.102     |
|    n_updates            | 4760      |
|    policy_gradient_loss | 0.00311   |
|    std                  | 0.481     |
|    value_loss           | 0.245     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 478        |
|    time_elapsed         | 273053     |
|    total_timesteps      | 978944     |
| train/                  |            |
|    approx_kl            | 0.24952967 |
|    clip_fraction        | 0.26       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.32      |
|    explained_variance   | 5.96e-07   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.108      |
|    n_updates            | 4770       |
|    policy_gradient_loss | 0.00374    |
|    std                  | 0.48       |
|    value_loss           | 0.214      |
----------------------------------------
Eval num_timesteps=980000, episode_reward=-99.78 +/- 0.03
Episode length: 3597.20 +/- 7.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 980000      |
| train/                  |             |
|    approx_kl            | 0.026201345 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.31       |
|    explained_variance   | 0.905       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.077       |
|    n_updates            | 4780        |
|    policy_gradient_loss | -0.00076    |
|    std                  | 0.479       |
|    value_loss           | 9.76        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.9e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 479      |
|    time_elapsed    | 275060   |
|    total_timesteps | 980992   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.9e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 480        |
|    time_elapsed         | 275266     |
|    total_timesteps      | 983040     |
| train/                  |            |
|    approx_kl            | 0.03145446 |
|    clip_fraction        | 0.137      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.3       |
|    explained_variance   | 0.38       |
|    learning_rate        | 0.0003     |
|    loss                 | 16         |
|    n_updates            | 4790       |
|    policy_gradient_loss | -0.00937   |
|    std                  | 0.479      |
|    value_loss           | 1.07e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 481        |
|    time_elapsed         | 275473     |
|    total_timesteps      | 985088     |
| train/                  |            |
|    approx_kl            | 0.04440756 |
|    clip_fraction        | 0.303      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.34      |
|    explained_variance   | -0.0038    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.111      |
|    n_updates            | 4800       |
|    policy_gradient_loss | -0.000449  |
|    std                  | 0.483      |
|    value_loss           | 0.222      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.91e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 482         |
|    time_elapsed         | 275678      |
|    total_timesteps      | 987136      |
| train/                  |             |
|    approx_kl            | 0.025018476 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.36       |
|    explained_variance   | 0.924       |
|    learning_rate        | 0.0003      |
|    loss                 | 19.3        |
|    n_updates            | 4810        |
|    policy_gradient_loss | -0.00193    |
|    std                  | 0.482       |
|    value_loss           | 10.7        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.91e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 483         |
|    time_elapsed         | 275884      |
|    total_timesteps      | 989184      |
| train/                  |             |
|    approx_kl            | 0.041312825 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.4        |
|    explained_variance   | 0.00992     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.169       |
|    n_updates            | 4820        |
|    policy_gradient_loss | 0.00261     |
|    std                  | 0.487       |
|    value_loss           | 0.232       |
-----------------------------------------
Eval num_timesteps=990000, episode_reward=-99.86 +/- 0.06
Episode length: 3600.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 990000      |
| train/                  |             |
|    approx_kl            | 0.085173346 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.44       |
|    explained_variance   | 0.881       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.114       |
|    n_updates            | 4830        |
|    policy_gradient_loss | 0.00416     |
|    std                  | 0.487       |
|    value_loss           | 4.52        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.9e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 484      |
|    time_elapsed    | 277891   |
|    total_timesteps | 991232   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.9e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 485         |
|    time_elapsed         | 278096      |
|    total_timesteps      | 993280      |
| train/                  |             |
|    approx_kl            | 0.027269814 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.44       |
|    explained_variance   | -7.27e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 45.9        |
|    n_updates            | 4840        |
|    policy_gradient_loss | -0.00357    |
|    std                  | 0.487       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 486        |
|    time_elapsed         | 278302     |
|    total_timesteps      | 995328     |
| train/                  |            |
|    approx_kl            | 0.03486595 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.44      |
|    explained_variance   | -1.12e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.141      |
|    n_updates            | 4850       |
|    policy_gradient_loss | 0.00475    |
|    std                  | 0.487      |
|    value_loss           | 0.26       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 487        |
|    time_elapsed         | 278507     |
|    total_timesteps      | 997376     |
| train/                  |            |
|    approx_kl            | 0.02859047 |
|    clip_fraction        | 0.259      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.44      |
|    explained_variance   | 0.931      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.181      |
|    n_updates            | 4860       |
|    policy_gradient_loss | -0.00288   |
|    std                  | 0.487      |
|    value_loss           | 5.92       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.91e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 488         |
|    time_elapsed         | 278712      |
|    total_timesteps      | 999424      |
| train/                  |             |
|    approx_kl            | 0.028817212 |
|    clip_fraction        | 0.205       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.43       |
|    explained_variance   | 0.909       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.86        |
|    n_updates            | 4870        |
|    policy_gradient_loss | -0.0118     |
|    std                  | 0.486       |
|    value_loss           | 14.1        |
-----------------------------------------
Eval num_timesteps=1000000, episode_reward=-99.87 +/- 0.03
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 1000000     |
| train/                  |             |
|    approx_kl            | 0.036517102 |
|    clip_fraction        | 0.331       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.37       |
|    explained_variance   | -0.0401     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.178       |
|    n_updates            | 4880        |
|    policy_gradient_loss | 0.000997    |
|    std                  | 0.481       |
|    value_loss           | 0.258       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.9e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 489      |
|    time_elapsed    | 280720   |
|    total_timesteps | 1001472  |
---------------------------------
Plot saved as src/FM3_MicRo/control_models/2025-01-22_04-50-18_llm_triton_qwen_7b_binary_rewards_zero_shot_1000000-steps_5-obs_ep-time-360.0/r_ratio_plot.png
 100% ━━━━━━━━━━━━━━━━ 1,001,472/1,000,… [ 3 days, 5:56:05 < 0:00:00 , 10 it/s ]

Detailed evaluation data:
Timesteps (shape=(100,)): [  10000   20000   30000   40000   50000   60000   70000   80000   90000
  100000  110000  120000  130000  140000  150000  160000  170000  180000
  190000  200000  210000  220000  230000  240000  250000  260000  270000
  280000  290000  300000  310000  320000  330000  340000  350000  360000
  370000  380000  390000  400000  410000  420000  430000  440000  450000
  460000  470000  480000  490000  500000  510000  520000  530000  540000
  550000  560000  570000  580000  590000  600000  610000  620000  630000
  640000  650000  660000  670000  680000  690000  700000  710000  720000
  730000  740000  750000  760000  770000  780000  790000  800000  810000
  820000  830000  840000  850000  860000  870000  880000  890000  900000
  910000  920000  930000  940000  950000  960000  970000  980000  990000
 1000000]
Results (shape=(100, 5)):
[[ -99.97698   -99.95418   -99.881697  -99.847066  -99.907188]
 [ -99.979253  -99.872037  -99.893415  -99.998784  -99.857944]
 [-100.047771 -100.005961 -100.020711 -100.010354 -100.007185]
 [-100.071702 -100.077157 -100.031116 -100.002988 -100.029424]
 [-100.017582  -99.979702  -99.934632  -99.922836  -99.930726]
 [ -99.978992  -99.963362  -99.879758 -100.03273   -99.938745]
 [ -99.9066    -99.996379  -99.98131   -99.965903  -99.998479]
 [ -99.89565   -99.981698  -99.925796  -99.969676  -99.964703]
 [ -99.988262 -100.040985  -99.910521  -99.965606 -100.005872]
 [ -99.966504 -100.034084  -99.920594  -99.898956 -100.012382]
 [ -99.950829  -99.887872  -99.948444  -99.877719  -99.945744]
 [ -99.849403  -99.926901  -99.828195  -99.858351  -99.907615]
 [ -99.819092  -99.83648   -99.837378  -99.864811  -99.868087]
 [ -99.820775  -99.975101  -99.860602  -99.934884  -99.926947]
 [ -99.925892  -99.916014  -99.830942  -99.846735  -99.967917]
 [ -99.889346  -99.957116  -99.829452  -99.876404  -99.947296]
 [ -99.923985  -99.909768  -99.869272  -99.935104  -99.863213]
 [ -99.857402  -99.939312  -99.836222  -99.799598  -99.841439]
 [ -99.967123  -99.947292  -99.901529  -99.727236  -99.726572]
 [ -99.948239  -99.746827  -99.650304  -99.633102  -99.65159 ]
 [ -99.805888  -99.852068  -99.880182  -99.873917  -99.860917]
 [ -99.886717  -99.915351  -99.910546  -99.755748  -99.87744 ]
 [ -99.849687  -99.762263  -99.734594  -99.942007  -99.93802 ]
 [ -99.87504   -99.811266  -99.782701  -99.67815   -99.852631]
 [ -99.73717   -99.753159  -99.77798   -99.734249  -99.837407]
 [ -99.78128   -99.810947  -99.938429  -99.775224  -99.835536]
 [ -99.847379  -99.909423  -99.887169  -99.741459  -99.78701 ]
 [ -99.920898  -99.86479   -99.773912  -99.886104  -99.766566]
 [ -99.775615  -99.77041   -99.726496  -99.762047  -99.666188]
 [ -99.794403  -99.826228  -99.642383  -99.561309  -99.772203]
 [ -99.925942  -99.825446  -99.874685  -99.942799  -99.843468]
 [ -99.822574  -99.774038  -99.906986  -99.806753  -99.789401]
 [ -99.835092  -99.935591  -99.902052  -99.795357  -99.814196]
 [ -99.790411  -99.831131  -99.877284  -99.848394  -99.841514]
 [ -99.870156  -99.632655  -99.693993  -99.80003   -99.7698  ]
 [ -99.79281   -99.759743  -99.694803  -99.409622  -99.735661]
 [ -99.811463  -99.841915  -99.7881    -99.853593  -99.862949]
 [ -99.745563  -99.795849  -99.853534  -99.864357  -99.819929]
 [ -99.818041  -99.876081  -99.843747  -99.908253  -99.853704]
 [ -99.767702  -99.903622  -99.798757  -99.885305  -99.777927]
 [ -99.793717  -99.775851  -99.723674  -99.818439  -99.848634]
 [ -99.894409  -99.874485  -99.79556   -99.797598  -99.831554]
 [ -99.788842  -99.862402  -99.856263  -99.775301  -99.850987]
 [ -99.820021  -99.801887  -99.84216   -99.739354  -99.855256]
 [ -99.901324  -99.744052  -99.787488  -99.714346  -99.76876 ]
 [ -99.767731  -99.825964  -99.828651  -99.872735  -99.883571]
 [ -99.771963  -99.871077  -99.850162  -99.886531  -99.798692]
 [ -99.814405  -99.920801  -99.767521  -99.841136  -99.775884]
 [ -99.98253   -99.969935  -99.878955  -99.907337  -99.968662]
 [ -99.817986  -99.940475  -99.82771   -99.829963  -99.874696]
 [ -99.890648  -99.90226   -99.774066  -99.740378  -99.714814]
 [ -99.864643  -99.675106  -99.88294   -99.775436  -99.840096]
 [ -99.801659  -99.952204  -99.898089  -99.886767  -99.901783]
 [ -99.786158  -99.893516  -99.898924  -99.768332  -99.961812]
 [ -99.939502  -99.795342  -99.916273  -99.82663   -99.768601]
 [ -99.899091  -99.885444  -99.774198  -99.965845  -99.816246]
 [ -99.751192  -99.818024  -99.832001  -99.803797  -99.778891]
 [ -99.854839  -99.905867  -99.757455  -99.788612  -99.861253]
 [ -99.808052  -99.832398  -99.972044  -99.974941  -99.807833]
 [ -99.847204  -99.909016  -99.844839  -99.927692  -99.885229]
 [ -99.743644  -99.849852  -99.733801  -99.871196  -99.831828]
 [ -99.798677  -99.99023   -99.881755  -99.82729   -99.834125]
 [ -99.83434   -99.868032  -99.871915  -99.818002  -99.842431]
 [ -99.786867  -99.864819  -99.842993  -99.764019  -99.907215]
 [ -99.870465  -99.810925  -99.794545  -99.807562  -99.811483]
 [ -99.834382  -99.819431  -99.813934  -99.801514  -99.779501]
 [ -99.777192  -99.768179  -99.853658  -99.800097  -99.818925]
 [ -99.796781  -99.923218  -99.862992  -99.809666  -99.814259]
 [ -99.81764   -99.80931   -99.895184  -99.783605  -99.852827]
 [ -99.832811  -99.860471  -99.761645  -99.919866  -99.880339]
 [ -99.867266  -99.851828  -99.74105   -99.906201  -99.847044]
 [ -99.890638  -99.822119  -99.800933  -99.898706  -99.740569]
 [ -99.832371  -99.859396  -99.775427  -99.726271  -99.85863 ]
 [ -99.74594   -99.787677  -99.746162  -99.818918  -99.800739]
 [ -99.803975  -99.803626  -99.819859  -99.863431  -99.741954]
 [ -99.894029  -99.85801   -99.767204  -99.846875  -99.79347 ]
 [ -99.920048  -99.892447  -99.809284  -99.913897  -99.762172]
 [ -99.914133  -99.820243  -99.876949  -99.904803  -99.789083]
 [ -99.800111  -99.767316  -99.799804  -99.931879  -99.858895]
 [ -99.92657   -99.888279  -99.799258  -99.825094  -99.896098]
 [ -99.813061  -99.872852  -99.902855  -99.785886  -99.833516]
 [ -99.781384  -99.870256  -99.750919  -99.862933  -99.873903]
 [ -99.770335  -99.917523  -99.816086  -99.743887  -99.816141]
 [ -99.789357  -99.85818   -99.882769  -99.744455  -99.703392]
 [ -99.879446  -99.825122  -99.825125  -99.768855  -99.896539]
 [ -99.786145  -99.742144  -99.88224   -99.809523  -99.792318]
 [ -99.822084  -99.789476  -99.769515  -99.868227  -99.904792]
 [ -99.788299  -99.712214  -99.889768  -99.598224  -99.91893 ]
 [ -99.830409  -99.787054  -99.731441  -99.664262  -99.591903]
 [ -99.813312  -99.887254  -99.850592  -99.699784  -99.867119]
 [ -99.727815  -99.728956  -99.872165  -99.561917  -99.841977]
 [ -99.82743   -99.808828  -99.859994  -99.834396  -99.838606]
 [ -99.747341  -99.846136  -99.894427  -99.842537  -99.899232]
 [ -99.852718  -99.857345  -99.754515  -99.635141  -99.623961]
 [ -99.878305  -99.902785  -99.838865  -99.730699  -99.924991]
 [ -99.718632  -99.679209  -99.523145  -99.684772  -99.756315]
 [ -99.790738  -99.872653  -99.915509  -99.777749  -99.923941]
 [ -99.742906  -99.814015  -99.810003  -99.795385  -99.759166]
 [ -99.876893  -99.749591  -99.867748  -99.874446  -99.914536]
 [ -99.859525  -99.868666  -99.876268  -99.922695  -99.816774]]
Episode Lengths (shape=(100, 5)):
[[3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3584 3601 3598 3601 3601]
 [3601 3601 3601 3583 3601]
 [3600 3601 3601 3601 3601]
 [3583 3600 3601 3601 3601]
 [3601 3601 3601 3581 3598]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3592 3599 3601 3601]
 [3601 3601 3601 3601 3583]
 [3601 3601 3601 3598 3601]
 [3580 3601 3601 3601 3601]
 [3601 3601 3601 3587 3598]
 [3601 3601 3601 3598 3601]
 [3585 3601 3601 3601 3601]
 [3600 3601 3599 3601 3601]
 [3601 3601 3601 3598 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3594 3601 3601 3601 3601]
 [3601 3601 3600 3601 3601]
 [3601 3601 3601 3601 3601]
 [3583 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3594 3601]
 [3582 3601 3601 3601 3601]
 [3601 3601 3601 3583 3601]
 [3601 3599 3601 3601 3601]
 [3596 3601 3601 3601 3598]
 [3601 3601 3601 3601 3601]
 [3598 3600 3601 3601 3601]
 [3584 3601 3601 3601 3601]
 [3601 3600 3601 3580 3601]
 [3601 3601 3601 3601 3598]
 [3601 3601 3601 3601 3601]
 [3597 3595 3601 3598 3598]
 [3601 3601 3601 3601 3582]
 [3601 3601 3601 3598 3601]
 [3586 3601 3601 3601 3601]
 [3601 3599 3601 3587 3601]
 [3601 3601 3601 3597 3598]
 [3579 3601 3601 3601 3601]
 [3601 3601 3601 3576 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3590 3601 3598 3601]
 [3601 3601 3601 3601 3579]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3576 3601]
 [3601 3601 3599 3601 3601]
 [3601 3601 3599 3601 3601]
 [3601 3591 3601 3597 3601]
 [3601 3598 3601 3601 3584]
 [3600 3601 3601 3601 3599]
 [3583 3601 3601 3601 3601]
 [3601 3601 3601 3585 3601]
 [3601 3601 3601 3601 3601]
 [3596 3601 3601 3598 3601]
 [3601 3601 3601 3584 3601]
 [3601 3601 3601 3601 3601]
 [3588 3598 3601 3601 3601]
 [3601 3601 3601 3580 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3597 3601 3601 3601]
 [3601 3601 3601 3601 3599]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3599 3601]
 [3601 3601 3601 3590 3601]
 [3601 3601 3601 3601 3601]
 [3601 3598 3601 3601 3601]
 [3601 3591 3601 3601 3601]
 [3601 3601 3601 3601 3587]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3597 3601 3601 3601 3601]
 [3601 3601 3586 3598 3601]
 [3601 3601 3601 3601 3601]
 [3601 3600 3601 3601 3601]
 [3601 3601 3601 3593 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3599 3601 3601 3601 3601]
 [3601 3601 3600 3601 3601]
 [3597 3601 3601 3601 3601]
 [3601 3601 3600 3597 3585]
 [3597 3601 3601 3601 3601]
 [3598 3601 3601 3601 3601]
 [3597 3601 3601 3598 3601]
 [3601 3601 3601 3601 3597]
 [3582 3601 3601 3601 3601]
 [3601 3601 3597 3601 3601]
 [3601 3598 3601 3601 3601]]
Time Elapsed: Not available
Plot saved to /scratch/work/sattaru1/FM3-MicRo/src/FM3_MicRo/control_models/2025-01-22_04-50-18_llm_triton_qwen_7b_binary_rewards_zero_shot_1000000-steps_5-obs_ep-time-360.0/rewards_plot.png
Model saved as src/FM3_MicRo/control_models/2025-01-22_04-50-18_llm_triton_qwen_7b_binary_rewards_zero_shot_1000000-steps_5-obs_ep-time-360.0/model
