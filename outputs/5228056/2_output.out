####################
/var/spool/slurmd/job5257061/slurm_script
####################
--batch-size 64 --exc train --goal-reset False --model-id TRITON_QWEN_7B --model-quant fp16 --num-eval 100 --prompt-file llm_prompt_continuous_rewards_1_example_explanation.yaml --reward-type llm --rollout-steps 2048 --text-verbosity True --total-timesteps 1000000 --train-episode-time-limit 360 --train-fps 10 --train-render-fps 120 --train-verbosity True
####################

Metadata saved to src/FM3_MicRo/control_models/2025-01-21_22-07-43_llm_triton_qwen_7b_continuous_rewards_1_example_explanation_1000000-steps_5-obs_ep-time-360.0/metadata.txt
Contextual prompt is:
You are provided description of a 2D workspace where location of each point can be represented as (x, y) where 'x' is the x-axis co-ordinate while 'y' is the y-axis co-ordinate. The center of the workspace is at (0,0) and the top-right corner is at (360,360).
 
 You need to critique the actions of the particle. You will be provided with the goal position, the previous position of the particle and the new position of the particle. You can output a value between -9 and 9 with an accuracy of 1. Actions that are harmful for achievement of the goal position should have a value closer to -9 while actions that are beneficial for the achievement of the goal should have a value closer to +9.
 
 The particle was located at (17.25, -160.50).
 The particle is currently located at (16.50, -159.75).
 The goal is currently located at (5.75, -57.00).
 What is the reward score?
 
 1
 
 Explanation (Do not generate this in your output): The particle started at (17.25, -160.50) and ended at (16.50, -159.75), while the goal was at (5.75, -57.00). The distance to the goal at starting position was 104.13 while the distance at ending position was 103.31. Since, 103.31 < 104.13, the particle moved closer to the goal the score should be positive. But the magnitude of reduction in distance isn't very high so the magnitude should be low. Therfore, a score of 1 seems appropriate.
 
 You must only output a single float value. Do not output any other text in your reponse. Do not output any code or explanation.

Using cpu device
-----------------------------
| time/              |      |
|    fps             | 9    |
|    iterations      | 1    |
|    time_elapsed    | 213  |
|    total_timesteps | 2048 |
-----------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.57e+03    |
|    ep_rew_mean          | -394        |
| time/                   |             |
|    fps                  | 9           |
|    iterations           | 2           |
|    time_elapsed         | 420         |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.012926748 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.408      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.78        |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.0192     |
|    std                  | 0.996       |
|    value_loss           | 4.48        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.57e+03    |
|    ep_rew_mean          | -394        |
| time/                   |             |
|    fps                  | 9           |
|    iterations           | 3           |
|    time_elapsed         | 625         |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.009322471 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.573       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.34        |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0196     |
|    std                  | 1           |
|    value_loss           | 4.43        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.58e+03     |
|    ep_rew_mean          | -351         |
| time/                   |              |
|    fps                  | 9            |
|    iterations           | 4            |
|    time_elapsed         | 831          |
|    total_timesteps      | 8192         |
| train/                  |              |
|    approx_kl            | 0.0080358125 |
|    clip_fraction        | 0.0785       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.4        |
|    explained_variance   | 0.637        |
|    learning_rate        | 0.0003       |
|    loss                 | 3.23         |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.0194      |
|    std                  | 1            |
|    value_loss           | 4.98         |
------------------------------------------
Eval num_timesteps=10000, episode_reward=-99.97 +/- 0.03
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.010261962 |
|    clip_fraction        | 0.0995      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.578       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.3         |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0198     |
|    std                  | 0.997       |
|    value_loss           | 3.06        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -421     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 5        |
|    time_elapsed    | 2837     |
|    total_timesteps | 10240    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | -421         |
| time/                   |              |
|    fps                  | 4            |
|    iterations           | 6            |
|    time_elapsed         | 3043         |
|    total_timesteps      | 12288        |
| train/                  |              |
|    approx_kl            | 0.0062596337 |
|    clip_fraction        | 0.0325       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | -0.00183     |
|    learning_rate        | 0.0003       |
|    loss                 | 2.63e+03     |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.00284     |
|    std                  | 0.996        |
|    value_loss           | 1.04e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.4e+03     |
|    ep_rew_mean          | -329        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 7           |
|    time_elapsed         | 3248        |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.015054778 |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.182       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.5         |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0217     |
|    std                  | 0.994       |
|    value_loss           | 2.29        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.4e+03     |
|    ep_rew_mean          | -329        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 8           |
|    time_elapsed         | 3453        |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.011493074 |
|    clip_fraction        | 0.131       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.334       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.626       |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0185     |
|    std                  | 0.989       |
|    value_loss           | 2.21        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.44e+03    |
|    ep_rew_mean          | -249        |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 9           |
|    time_elapsed         | 3659        |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.015979318 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.29        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.956       |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.02       |
|    std                  | 0.987       |
|    value_loss           | 1.95        |
-----------------------------------------
Eval num_timesteps=20000, episode_reward=-100.03 +/- 0.02
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.013537884 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.282       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.01        |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.0227     |
|    std                  | 0.984       |
|    value_loss           | 2.6         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -271     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 10       |
|    time_elapsed    | 5666     |
|    total_timesteps | 20480    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | -271         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 11           |
|    time_elapsed         | 5871         |
|    total_timesteps      | 22528        |
| train/                  |              |
|    approx_kl            | 0.0057352977 |
|    clip_fraction        | 0.0427       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.2        |
|    explained_variance   | 0.00872      |
|    learning_rate        | 0.0003       |
|    loss                 | 82.9         |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.0053      |
|    std                  | 0.984        |
|    value_loss           | 1.06e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.37e+03    |
|    ep_rew_mean          | -201        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 12          |
|    time_elapsed         | 6076        |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.015957499 |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.277       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.01        |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.0223     |
|    std                  | 0.984       |
|    value_loss           | 2.42        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.37e+03    |
|    ep_rew_mean          | -201        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 13          |
|    time_elapsed         | 6282        |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.017401844 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.33        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.525       |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.016      |
|    std                  | 0.978       |
|    value_loss           | 1.54        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.4e+03     |
|    ep_rew_mean          | -140        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 14          |
|    time_elapsed         | 6488        |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.015606966 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.377       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.02        |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.0199     |
|    std                  | 0.975       |
|    value_loss           | 2.29        |
-----------------------------------------
Eval num_timesteps=30000, episode_reward=-100.01 +/- 0.03
Episode length: 3597.40 +/- 6.71
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 30000       |
| train/                  |             |
|    approx_kl            | 0.013382862 |
|    clip_fraction        | 0.18        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.379       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.02        |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.0148     |
|    std                  | 0.972       |
|    value_loss           | 2.63        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -142     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 15       |
|    time_elapsed    | 8498     |
|    total_timesteps | 30720    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -142        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 16          |
|    time_elapsed         | 8703        |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.010723816 |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.00293    |
|    learning_rate        | 0.0003      |
|    loss                 | 4.88        |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.00648    |
|    std                  | 0.972       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | -78.8       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 17          |
|    time_elapsed         | 8909        |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 0.018412814 |
|    clip_fraction        | 0.226       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.148       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.768       |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.00826    |
|    std                  | 0.975       |
|    value_loss           | 1.76        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.36e+03  |
|    ep_rew_mean          | -78.8     |
| time/                   |           |
|    fps                  | 4         |
|    iterations           | 18        |
|    time_elapsed         | 9116      |
|    total_timesteps      | 36864     |
| train/                  |           |
|    approx_kl            | 0.0149423 |
|    clip_fraction        | 0.175     |
|    clip_range           | 0.2       |
|    entropy_loss         | -11.2     |
|    explained_variance   | 0.355     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.761     |
|    n_updates            | 170       |
|    policy_gradient_loss | -0.011    |
|    std                  | 0.977     |
|    value_loss           | 1.93      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.38e+03    |
|    ep_rew_mean          | -25.2       |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 19          |
|    time_elapsed         | 9321        |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.016471975 |
|    clip_fraction        | 0.228       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.268       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.753       |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.0101     |
|    std                  | 0.968       |
|    value_loss           | 1.43        |
-----------------------------------------
Eval num_timesteps=40000, episode_reward=-100.02 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 40000       |
| train/                  |             |
|    approx_kl            | 0.018854199 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.84        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.992       |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.0179     |
|    std                  | 0.967       |
|    value_loss           | 1.69        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -26.4    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 20       |
|    time_elapsed    | 11330    |
|    total_timesteps | 40960    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -26.4       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 21          |
|    time_elapsed         | 11538       |
|    total_timesteps      | 43008       |
| train/                  |             |
|    approx_kl            | 0.012114491 |
|    clip_fraction        | 0.126       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.00179     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.52e+03    |
|    n_updates            | 200         |
|    policy_gradient_loss | -0.00304    |
|    std                  | 0.967       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 21.9        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 22          |
|    time_elapsed         | 11744       |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.018584605 |
|    clip_fraction        | 0.207       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.144       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.462       |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.000539   |
|    std                  | 0.968       |
|    value_loss           | 1.2         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 21.9        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 23          |
|    time_elapsed         | 11949       |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.017763162 |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.305       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.453       |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.00416    |
|    std                  | 0.97        |
|    value_loss           | 1.17        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.37e+03    |
|    ep_rew_mean          | 69          |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 24          |
|    time_elapsed         | 12157       |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.015836973 |
|    clip_fraction        | 0.207       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.115       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.785       |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.0119     |
|    std                  | 0.967       |
|    value_loss           | 1.51        |
-----------------------------------------
Eval num_timesteps=50000, episode_reward=-99.95 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 50000       |
| train/                  |             |
|    approx_kl            | 0.014824106 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.88        |
|    learning_rate        | 0.0003      |
|    loss                 | 1.6         |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.0118     |
|    std                  | 0.964       |
|    value_loss           | 2.82        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 65.8     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 25       |
|    time_elapsed    | 14166    |
|    total_timesteps | 51200    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 65.8        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 26          |
|    time_elapsed         | 14372       |
|    total_timesteps      | 53248       |
| train/                  |             |
|    approx_kl            | 0.021106899 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.000409    |
|    learning_rate        | 0.0003      |
|    loss                 | 2.05e+03    |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.00798    |
|    std                  | 0.964       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 109         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 27          |
|    time_elapsed         | 14577       |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.026021477 |
|    clip_fraction        | 0.252       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.0868      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.413       |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.00444    |
|    std                  | 0.963       |
|    value_loss           | 1.16        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.36e+03   |
|    ep_rew_mean          | 145        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 28         |
|    time_elapsed         | 14785      |
|    total_timesteps      | 57344      |
| train/                  |            |
|    approx_kl            | 0.02017108 |
|    clip_fraction        | 0.206      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11        |
|    explained_variance   | 0.784      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.91       |
|    n_updates            | 270        |
|    policy_gradient_loss | -0.0122    |
|    std                  | 0.959      |
|    value_loss           | 4.12       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 145         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 29          |
|    time_elapsed         | 14991       |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.025650613 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -0.00712    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.481       |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.00451    |
|    std                  | 0.955       |
|    value_loss           | 1.09        |
-----------------------------------------
Eval num_timesteps=60000, episode_reward=-99.83 +/- 0.14
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 60000      |
| train/                  |            |
|    approx_kl            | 0.02272579 |
|    clip_fraction        | 0.22       |
|    clip_range           | 0.2        |
|    entropy_loss         | -11        |
|    explained_variance   | 0.151      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.626      |
|    n_updates            | 290        |
|    policy_gradient_loss | -0.00415   |
|    std                  | 0.952      |
|    value_loss           | 1.44       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 143      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 30       |
|    time_elapsed    | 16997    |
|    total_timesteps | 61440    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 143         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 31          |
|    time_elapsed         | 17203       |
|    total_timesteps      | 63488       |
| train/                  |             |
|    approx_kl            | 0.022468679 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.000602   |
|    learning_rate        | 0.0003      |
|    loss                 | 809         |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.00518    |
|    std                  | 0.951       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 178         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 32          |
|    time_elapsed         | 17409       |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.021338703 |
|    clip_fraction        | 0.248       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.181      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.448       |
|    n_updates            | 310         |
|    policy_gradient_loss | -0.000247   |
|    std                  | 0.952       |
|    value_loss           | 1.03        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 207         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 33          |
|    time_elapsed         | 17615       |
|    total_timesteps      | 67584       |
| train/                  |             |
|    approx_kl            | 0.026338832 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.925       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.47        |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.00771    |
|    std                  | 0.95        |
|    value_loss           | 5.24        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 207         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 34          |
|    time_elapsed         | 17820       |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.022625186 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.188       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.598       |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.0113     |
|    std                  | 0.949       |
|    value_loss           | 3.77        |
-----------------------------------------
Eval num_timesteps=70000, episode_reward=-99.89 +/- 0.05
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 70000      |
| train/                  |            |
|    approx_kl            | 0.02241403 |
|    clip_fraction        | 0.234      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.9      |
|    explained_variance   | 0.141      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.486      |
|    n_updates            | 340        |
|    policy_gradient_loss | -0.00498   |
|    std                  | 0.948      |
|    value_loss           | 1.3        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 202      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 35       |
|    time_elapsed    | 19828    |
|    total_timesteps | 71680    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.35e+03   |
|    ep_rew_mean          | 228        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 36         |
|    time_elapsed         | 20034      |
|    total_timesteps      | 73728      |
| train/                  |            |
|    approx_kl            | 0.03369472 |
|    clip_fraction        | 0.187      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.9      |
|    explained_variance   | -0.00022   |
|    learning_rate        | 0.0003     |
|    loss                 | 2.33e+03   |
|    n_updates            | 350        |
|    policy_gradient_loss | -0.00527   |
|    std                  | 0.948      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 228         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 37          |
|    time_elapsed         | 20240       |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 0.029016227 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.723       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.6         |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.0104     |
|    std                  | 0.943       |
|    value_loss           | 3.56        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.36e+03   |
|    ep_rew_mean          | 254        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 38         |
|    time_elapsed         | 20446      |
|    total_timesteps      | 77824      |
| train/                  |            |
|    approx_kl            | 0.03944751 |
|    clip_fraction        | 0.302      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | 0.361      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.578      |
|    n_updates            | 370        |
|    policy_gradient_loss | 0.00401    |
|    std                  | 0.935      |
|    value_loss           | 1.02       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 254         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 39          |
|    time_elapsed         | 20652       |
|    total_timesteps      | 79872       |
| train/                  |             |
|    approx_kl            | 0.030302713 |
|    clip_fraction        | 0.266       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.389       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.339       |
|    n_updates            | 380         |
|    policy_gradient_loss | 0.00267     |
|    std                  | 0.937       |
|    value_loss           | 0.855       |
-----------------------------------------
Eval num_timesteps=80000, episode_reward=-99.92 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 80000       |
| train/                  |             |
|    approx_kl            | 0.027851513 |
|    clip_fraction        | 0.264       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.371       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.546       |
|    n_updates            | 390         |
|    policy_gradient_loss | -0.00175    |
|    std                  | 0.934       |
|    value_loss           | 0.886       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 250      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 40       |
|    time_elapsed    | 22658    |
|    total_timesteps | 81920    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 275         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 41          |
|    time_elapsed         | 22864       |
|    total_timesteps      | 83968       |
| train/                  |             |
|    approx_kl            | 0.017628841 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.00281    |
|    learning_rate        | 0.0003      |
|    loss                 | 256         |
|    n_updates            | 400         |
|    policy_gradient_loss | -0.00384    |
|    std                  | 0.933       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 275         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 42          |
|    time_elapsed         | 23069       |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.026221335 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.21        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.612       |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.00339    |
|    std                  | 0.927       |
|    value_loss           | 1.22        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 298         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 43          |
|    time_elapsed         | 23277       |
|    total_timesteps      | 88064       |
| train/                  |             |
|    approx_kl            | 0.029363252 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.375       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.498       |
|    n_updates            | 420         |
|    policy_gradient_loss | 0.003       |
|    std                  | 0.927       |
|    value_loss           | 0.932       |
-----------------------------------------
Eval num_timesteps=90000, episode_reward=-99.91 +/- 0.08
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 90000       |
| train/                  |             |
|    approx_kl            | 0.028621687 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.353       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.572       |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.00107    |
|    std                  | 0.927       |
|    value_loss           | 0.967       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 297      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 44       |
|    time_elapsed    | 25283    |
|    total_timesteps | 90112    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 297         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 45          |
|    time_elapsed         | 25488       |
|    total_timesteps      | 92160       |
| train/                  |             |
|    approx_kl            | 0.021219496 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.000759    |
|    learning_rate        | 0.0003      |
|    loss                 | 5.51        |
|    n_updates            | 440         |
|    policy_gradient_loss | -0.00127    |
|    std                  | 0.927       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 320         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 46          |
|    time_elapsed         | 25693       |
|    total_timesteps      | 94208       |
| train/                  |             |
|    approx_kl            | 0.028747525 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.12        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.491       |
|    n_updates            | 450         |
|    policy_gradient_loss | 0.00175     |
|    std                  | 0.92        |
|    value_loss           | 1.19        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 320         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 47          |
|    time_elapsed         | 25899       |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 0.022304159 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.269       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.624       |
|    n_updates            | 460         |
|    policy_gradient_loss | 0.0013      |
|    std                  | 0.921       |
|    value_loss           | 1.25        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 342         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 48          |
|    time_elapsed         | 26104       |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.031884547 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.387       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.433       |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.00288    |
|    std                  | 0.915       |
|    value_loss           | 0.931       |
-----------------------------------------
Eval num_timesteps=100000, episode_reward=-99.95 +/- 0.05
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 100000      |
| train/                  |             |
|    approx_kl            | 0.022137556 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.809      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.599       |
|    n_updates            | 480         |
|    policy_gradient_loss | 0.00267     |
|    std                  | 0.91        |
|    value_loss           | 1.3         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 341      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 49       |
|    time_elapsed    | 28113    |
|    total_timesteps | 100352   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 341         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 50          |
|    time_elapsed         | 28318       |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 0.023141768 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.00268    |
|    learning_rate        | 0.0003      |
|    loss                 | 133         |
|    n_updates            | 490         |
|    policy_gradient_loss | -0.0039     |
|    std                  | 0.912       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 362         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 51          |
|    time_elapsed         | 28526       |
|    total_timesteps      | 104448      |
| train/                  |             |
|    approx_kl            | 0.029561918 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.0898      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.574       |
|    n_updates            | 500         |
|    policy_gradient_loss | 0.00818     |
|    std                  | 0.906       |
|    value_loss           | 1.13        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 362         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 52          |
|    time_elapsed         | 28731       |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.018299695 |
|    clip_fraction        | 0.229       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.592       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.434       |
|    n_updates            | 510         |
|    policy_gradient_loss | 1.5e-05     |
|    std                  | 0.9         |
|    value_loss           | 1.63        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 383         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 53          |
|    time_elapsed         | 28936       |
|    total_timesteps      | 108544      |
| train/                  |             |
|    approx_kl            | 0.026229328 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.283       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.512       |
|    n_updates            | 520         |
|    policy_gradient_loss | 0.00502     |
|    std                  | 0.896       |
|    value_loss           | 1.02        |
-----------------------------------------
Eval num_timesteps=110000, episode_reward=-99.90 +/- 0.08
Episode length: 3597.60 +/- 6.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 110000      |
| train/                  |             |
|    approx_kl            | 0.031388152 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.227       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.401       |
|    n_updates            | 530         |
|    policy_gradient_loss | 0.00942     |
|    std                  | 0.896       |
|    value_loss           | 0.994       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 380      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 54       |
|    time_elapsed    | 30944    |
|    total_timesteps | 110592   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 380         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 55          |
|    time_elapsed         | 31150       |
|    total_timesteps      | 112640      |
| train/                  |             |
|    approx_kl            | 0.041446112 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.000689   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.33e+03    |
|    n_updates            | 540         |
|    policy_gradient_loss | -0.00126    |
|    std                  | 0.897       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 398         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 56          |
|    time_elapsed         | 31356       |
|    total_timesteps      | 114688      |
| train/                  |             |
|    approx_kl            | 0.043770023 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.0278      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.288       |
|    n_updates            | 550         |
|    policy_gradient_loss | 0.0085      |
|    std                  | 0.907       |
|    value_loss           | 0.983       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 398         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 57          |
|    time_elapsed         | 31561       |
|    total_timesteps      | 116736      |
| train/                  |             |
|    approx_kl            | 0.029814618 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.557       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.495       |
|    n_updates            | 560         |
|    policy_gradient_loss | -0.00299    |
|    std                  | 0.91        |
|    value_loss           | 4.57        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 416         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 58          |
|    time_elapsed         | 31769       |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.025067454 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.273       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.522       |
|    n_updates            | 570         |
|    policy_gradient_loss | 0.00387     |
|    std                  | 0.911       |
|    value_loss           | 1.04        |
-----------------------------------------
Eval num_timesteps=120000, episode_reward=-99.90 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 120000      |
| train/                  |             |
|    approx_kl            | 0.034738164 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.796       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.79        |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.00157    |
|    std                  | 0.908       |
|    value_loss           | 3.95        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 411      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 59       |
|    time_elapsed    | 33777    |
|    total_timesteps | 120832   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 411         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 60          |
|    time_elapsed         | 33983       |
|    total_timesteps      | 122880      |
| train/                  |             |
|    approx_kl            | 0.017382737 |
|    clip_fraction        | 0.18        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.000804    |
|    learning_rate        | 0.0003      |
|    loss                 | 386         |
|    n_updates            | 590         |
|    policy_gradient_loss | -0.001      |
|    std                  | 0.906       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 427        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 61         |
|    time_elapsed         | 34188      |
|    total_timesteps      | 124928     |
| train/                  |            |
|    approx_kl            | 0.03432396 |
|    clip_fraction        | 0.301      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | -0.189     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.595      |
|    n_updates            | 600        |
|    policy_gradient_loss | -0.00333   |
|    std                  | 0.907      |
|    value_loss           | 1.3        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 427        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 62         |
|    time_elapsed         | 34393      |
|    total_timesteps      | 126976     |
| train/                  |            |
|    approx_kl            | 0.02811329 |
|    clip_fraction        | 0.23       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | 0.688      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.648      |
|    n_updates            | 610        |
|    policy_gradient_loss | -0.00768   |
|    std                  | 0.903      |
|    value_loss           | 2.65       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.35e+03   |
|    ep_rew_mean          | 441        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 63         |
|    time_elapsed         | 34599      |
|    total_timesteps      | 129024     |
| train/                  |            |
|    approx_kl            | 0.04392597 |
|    clip_fraction        | 0.284      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | 0.253      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.677      |
|    n_updates            | 620        |
|    policy_gradient_loss | 0.00356    |
|    std                  | 0.9        |
|    value_loss           | 1.24       |
----------------------------------------
Eval num_timesteps=130000, episode_reward=-99.92 +/- 0.03
Episode length: 3597.00 +/- 7.51
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 130000      |
| train/                  |             |
|    approx_kl            | 0.031587996 |
|    clip_fraction        | 0.283       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.326       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.408       |
|    n_updates            | 630         |
|    policy_gradient_loss | 0.00417     |
|    std                  | 0.897       |
|    value_loss           | 0.898       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 439      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 64       |
|    time_elapsed    | 36605    |
|    total_timesteps | 131072   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 439         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 65          |
|    time_elapsed         | 36811       |
|    total_timesteps      | 133120      |
| train/                  |             |
|    approx_kl            | 0.030860938 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.0113      |
|    learning_rate        | 0.0003      |
|    loss                 | 26.8        |
|    n_updates            | 640         |
|    policy_gradient_loss | -0.00647    |
|    std                  | 0.895       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 452        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 66         |
|    time_elapsed         | 37016      |
|    total_timesteps      | 135168     |
| train/                  |            |
|    approx_kl            | 0.03057329 |
|    clip_fraction        | 0.288      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | 0.0165     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.428      |
|    n_updates            | 650        |
|    policy_gradient_loss | 0.00727    |
|    std                  | 0.891      |
|    value_loss           | 1.13       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 467         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 67          |
|    time_elapsed         | 37222       |
|    total_timesteps      | 137216      |
| train/                  |             |
|    approx_kl            | 0.031710282 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.324       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.423       |
|    n_updates            | 660         |
|    policy_gradient_loss | 0.012       |
|    std                  | 0.887       |
|    value_loss           | 0.986       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 467         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 68          |
|    time_elapsed         | 37427       |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 0.020457737 |
|    clip_fraction        | 0.267       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.313       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.353       |
|    n_updates            | 670         |
|    policy_gradient_loss | -0.00076    |
|    std                  | 0.887       |
|    value_loss           | 1.27        |
-----------------------------------------
Eval num_timesteps=140000, episode_reward=-99.96 +/- 0.10
Episode length: 3597.60 +/- 6.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -100      |
| time/                   |           |
|    total_timesteps      | 140000    |
| train/                  |           |
|    approx_kl            | 0.0320514 |
|    clip_fraction        | 0.282     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.3     |
|    explained_variance   | 0.291     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.36      |
|    n_updates            | 680       |
|    policy_gradient_loss | 0.00196   |
|    std                  | 0.886     |
|    value_loss           | 1.01      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 464      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 69       |
|    time_elapsed    | 39434    |
|    total_timesteps | 141312   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 464         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 70          |
|    time_elapsed         | 39642       |
|    total_timesteps      | 143360      |
| train/                  |             |
|    approx_kl            | 0.030845145 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.00343    |
|    learning_rate        | 0.0003      |
|    loss                 | 8.95        |
|    n_updates            | 690         |
|    policy_gradient_loss | -0.00529    |
|    std                  | 0.885       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 479         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 71          |
|    time_elapsed         | 39847       |
|    total_timesteps      | 145408      |
| train/                  |             |
|    approx_kl            | 0.034277953 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.0738     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.508       |
|    n_updates            | 700         |
|    policy_gradient_loss | 0.0136      |
|    std                  | 0.888       |
|    value_loss           | 1.01        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 491         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 72          |
|    time_elapsed         | 40055       |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.029688165 |
|    clip_fraction        | 0.296       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.642       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.807       |
|    n_updates            | 710         |
|    policy_gradient_loss | 0.00369     |
|    std                  | 0.884       |
|    value_loss           | 1.14        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 491        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 73         |
|    time_elapsed         | 40260      |
|    total_timesteps      | 149504     |
| train/                  |            |
|    approx_kl            | 0.03747213 |
|    clip_fraction        | 0.296      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.3      |
|    explained_variance   | 0.367      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.432      |
|    n_updates            | 720        |
|    policy_gradient_loss | 0.00731    |
|    std                  | 0.88       |
|    value_loss           | 0.931      |
----------------------------------------
Eval num_timesteps=150000, episode_reward=-100.01 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 150000      |
| train/                  |             |
|    approx_kl            | 0.040508993 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.327       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.513       |
|    n_updates            | 730         |
|    policy_gradient_loss | 0.00703     |
|    std                  | 0.878       |
|    value_loss           | 0.901       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 488      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 74       |
|    time_elapsed    | 42268    |
|    total_timesteps | 151552   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 500         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 75          |
|    time_elapsed         | 42476       |
|    total_timesteps      | 153600      |
| train/                  |             |
|    approx_kl            | 0.036036365 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.000866    |
|    learning_rate        | 0.0003      |
|    loss                 | 4.81        |
|    n_updates            | 740         |
|    policy_gradient_loss | 0.00203     |
|    std                  | 0.881       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 500         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 76          |
|    time_elapsed         | 42681       |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.046096668 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.0281     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.405       |
|    n_updates            | 750         |
|    policy_gradient_loss | -0.000452   |
|    std                  | 0.878       |
|    value_loss           | 1.04        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 512         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 77          |
|    time_elapsed         | 42887       |
|    total_timesteps      | 157696      |
| train/                  |             |
|    approx_kl            | 0.029738838 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.257       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.445       |
|    n_updates            | 760         |
|    policy_gradient_loss | 0.00606     |
|    std                  | 0.877       |
|    value_loss           | 1.01        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 512         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 78          |
|    time_elapsed         | 43093       |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.028490813 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.664       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.454       |
|    n_updates            | 770         |
|    policy_gradient_loss | 0.00297     |
|    std                  | 0.882       |
|    value_loss           | 1.13        |
-----------------------------------------
Eval num_timesteps=160000, episode_reward=-99.96 +/- 0.10
Episode length: 3596.20 +/- 8.18
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -100       |
| time/                   |            |
|    total_timesteps      | 160000     |
| train/                  |            |
|    approx_kl            | 0.02456231 |
|    clip_fraction        | 0.281      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | 0.293      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.489      |
|    n_updates            | 780        |
|    policy_gradient_loss | 0.000492   |
|    std                  | 0.877      |
|    value_loss           | 0.925      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 508      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 79       |
|    time_elapsed    | 45100    |
|    total_timesteps | 161792   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 519         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 80          |
|    time_elapsed         | 45305       |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.033080645 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.00233     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.23e+03    |
|    n_updates            | 790         |
|    policy_gradient_loss | -0.00233    |
|    std                  | 0.879       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 519        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 81         |
|    time_elapsed         | 45511      |
|    total_timesteps      | 165888     |
| train/                  |            |
|    approx_kl            | 0.04296842 |
|    clip_fraction        | 0.266      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | 0.109      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.578      |
|    n_updates            | 800        |
|    policy_gradient_loss | -0.00123   |
|    std                  | 0.877      |
|    value_loss           | 1.92       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 531         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 82          |
|    time_elapsed         | 45716       |
|    total_timesteps      | 167936      |
| train/                  |             |
|    approx_kl            | 0.035141688 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.186       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.697       |
|    n_updates            | 810         |
|    policy_gradient_loss | 0.00835     |
|    std                  | 0.874       |
|    value_loss           | 1.1         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 531         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 83          |
|    time_elapsed         | 45922       |
|    total_timesteps      | 169984      |
| train/                  |             |
|    approx_kl            | 0.068781056 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.335       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.359       |
|    n_updates            | 820         |
|    policy_gradient_loss | 0.0125      |
|    std                  | 0.873       |
|    value_loss           | 0.817       |
-----------------------------------------
Eval num_timesteps=170000, episode_reward=-99.90 +/- 0.04
Episode length: 3597.40 +/- 5.43
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 170000     |
| train/                  |            |
|    approx_kl            | 0.06876799 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | 0.34       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.503      |
|    n_updates            | 830        |
|    policy_gradient_loss | 0.0113     |
|    std                  | 0.871      |
|    value_loss           | 0.974      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 528      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 84       |
|    time_elapsed    | 47930    |
|    total_timesteps | 172032   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 538        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 85         |
|    time_elapsed         | 48136      |
|    total_timesteps      | 174080     |
| train/                  |            |
|    approx_kl            | 0.02506634 |
|    clip_fraction        | 0.247      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | 0.00589    |
|    learning_rate        | 0.0003     |
|    loss                 | 3.93       |
|    n_updates            | 840        |
|    policy_gradient_loss | -0.00363   |
|    std                  | 0.866      |
|    value_loss           | 924        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 538         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 86          |
|    time_elapsed         | 48341       |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.055402953 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.58        |
|    learning_rate        | 0.0003      |
|    loss                 | 1.1         |
|    n_updates            | 850         |
|    policy_gradient_loss | 0.00102     |
|    std                  | 0.869       |
|    value_loss           | 2.8         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 548         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 87          |
|    time_elapsed         | 48546       |
|    total_timesteps      | 178176      |
| train/                  |             |
|    approx_kl            | 0.042520314 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.0219      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.435       |
|    n_updates            | 860         |
|    policy_gradient_loss | 0.0153      |
|    std                  | 0.869       |
|    value_loss           | 1.19        |
-----------------------------------------
Eval num_timesteps=180000, episode_reward=-99.89 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 180000      |
| train/                  |             |
|    approx_kl            | 0.036906876 |
|    clip_fraction        | 0.283       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.679       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.548       |
|    n_updates            | 870         |
|    policy_gradient_loss | 0.00231     |
|    std                  | 0.867       |
|    value_loss           | 0.879       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 544      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 88       |
|    time_elapsed    | 50555    |
|    total_timesteps | 180224   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 544         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 89          |
|    time_elapsed         | 50760       |
|    total_timesteps      | 182272      |
| train/                  |             |
|    approx_kl            | 0.025211003 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.00132     |
|    learning_rate        | 0.0003      |
|    loss                 | 180         |
|    n_updates            | 880         |
|    policy_gradient_loss | 0.00172     |
|    std                  | 0.87        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 555        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 90         |
|    time_elapsed         | 50966      |
|    total_timesteps      | 184320     |
| train/                  |            |
|    approx_kl            | 0.09942788 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | 0.0119     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.653      |
|    n_updates            | 890        |
|    policy_gradient_loss | 0.0156     |
|    std                  | 0.87       |
|    value_loss           | 1.26       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 555         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 91          |
|    time_elapsed         | 51173       |
|    total_timesteps      | 186368      |
| train/                  |             |
|    approx_kl            | 0.053513713 |
|    clip_fraction        | 0.348       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.0162      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.553       |
|    n_updates            | 900         |
|    policy_gradient_loss | 0.0116      |
|    std                  | 0.865       |
|    value_loss           | 0.96        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 565         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 92          |
|    time_elapsed         | 51379       |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 0.047454506 |
|    clip_fraction        | 0.326       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.279       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.415       |
|    n_updates            | 910         |
|    policy_gradient_loss | 0.006       |
|    std                  | 0.864       |
|    value_loss           | 0.99        |
-----------------------------------------
Eval num_timesteps=190000, episode_reward=-99.89 +/- 0.02
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 190000     |
| train/                  |            |
|    approx_kl            | 0.08069946 |
|    clip_fraction        | 0.307      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | -0.00691   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.596      |
|    n_updates            | 920        |
|    policy_gradient_loss | 0.00302    |
|    std                  | 0.862      |
|    value_loss           | 1.47       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 561      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 93       |
|    time_elapsed    | 53386    |
|    total_timesteps | 190464   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 561         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 94          |
|    time_elapsed         | 53592       |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 0.024546355 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -0.00156    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.94e+03    |
|    n_updates            | 930         |
|    policy_gradient_loss | 0.00337     |
|    std                  | 0.86        |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 570         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 95          |
|    time_elapsed         | 53797       |
|    total_timesteps      | 194560      |
| train/                  |             |
|    approx_kl            | 0.028881136 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | 0.0117      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.668       |
|    n_updates            | 940         |
|    policy_gradient_loss | 0.0139      |
|    std                  | 0.858       |
|    value_loss           | 1.35        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 570         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 96          |
|    time_elapsed         | 54002       |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.049651824 |
|    clip_fraction        | 0.313       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.96       |
|    explained_variance   | 0.279       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.577       |
|    n_updates            | 950         |
|    policy_gradient_loss | 0.00429     |
|    std                  | 0.848       |
|    value_loss           | 1.26        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 579       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 97        |
|    time_elapsed         | 54208     |
|    total_timesteps      | 198656    |
| train/                  |           |
|    approx_kl            | 0.0350117 |
|    clip_fraction        | 0.3       |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.93     |
|    explained_variance   | 0.316     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.457     |
|    n_updates            | 960       |
|    policy_gradient_loss | 0.0143    |
|    std                  | 0.849     |
|    value_loss           | 0.831     |
---------------------------------------
Eval num_timesteps=200000, episode_reward=-99.93 +/- 0.03
Episode length: 3597.00 +/- 6.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 200000      |
| train/                  |             |
|    approx_kl            | 0.051166393 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.89       |
|    explained_variance   | 0.257       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.399       |
|    n_updates            | 970         |
|    policy_gradient_loss | 0.00236     |
|    std                  | 0.842       |
|    value_loss           | 1.09        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 576      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 98       |
|    time_elapsed    | 56216    |
|    total_timesteps | 200704   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 576         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 99          |
|    time_elapsed         | 56421       |
|    total_timesteps      | 202752      |
| train/                  |             |
|    approx_kl            | 0.034587488 |
|    clip_fraction        | 0.31        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.86       |
|    explained_variance   | 0.00543     |
|    learning_rate        | 0.0003      |
|    loss                 | 16.9        |
|    n_updates            | 980         |
|    policy_gradient_loss | -0.0037     |
|    std                  | 0.842       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 583        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 100        |
|    time_elapsed         | 56626      |
|    total_timesteps      | 204800     |
| train/                  |            |
|    approx_kl            | 0.07669023 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.88      |
|    explained_variance   | 0.00529    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.786      |
|    n_updates            | 990        |
|    policy_gradient_loss | 0.0145     |
|    std                  | 0.845      |
|    value_loss           | 1.7        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 583         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 101         |
|    time_elapsed         | 56832       |
|    total_timesteps      | 206848      |
| train/                  |             |
|    approx_kl            | 0.040878125 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.91       |
|    explained_variance   | 0.0762      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.616       |
|    n_updates            | 1000        |
|    policy_gradient_loss | 0.0041      |
|    std                  | 0.847       |
|    value_loss           | 1.51        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 592         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 102         |
|    time_elapsed         | 57037       |
|    total_timesteps      | 208896      |
| train/                  |             |
|    approx_kl            | 0.040563665 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.93       |
|    explained_variance   | 0.319       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.378       |
|    n_updates            | 1010        |
|    policy_gradient_loss | 0.00718     |
|    std                  | 0.849       |
|    value_loss           | 0.898       |
-----------------------------------------
Eval num_timesteps=210000, episode_reward=-99.95 +/- 0.04
Episode length: 3597.00 +/- 6.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -100       |
| time/                   |            |
|    total_timesteps      | 210000     |
| train/                  |            |
|    approx_kl            | 0.04225615 |
|    clip_fraction        | 0.274      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.91      |
|    explained_variance   | 0.327      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.484      |
|    n_updates            | 1020       |
|    policy_gradient_loss | 0.00206    |
|    std                  | 0.843      |
|    value_loss           | 1.06       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 588      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 103      |
|    time_elapsed    | 59045    |
|    total_timesteps | 210944   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 588        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 104        |
|    time_elapsed         | 59251      |
|    total_timesteps      | 212992     |
| train/                  |            |
|    approx_kl            | 0.08193763 |
|    clip_fraction        | 0.31       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.9       |
|    explained_variance   | 0.000465   |
|    learning_rate        | 0.0003     |
|    loss                 | 166        |
|    n_updates            | 1030       |
|    policy_gradient_loss | -0.002     |
|    std                  | 0.847      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 598        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 105        |
|    time_elapsed         | 59456      |
|    total_timesteps      | 215040     |
| train/                  |            |
|    approx_kl            | 0.08093029 |
|    clip_fraction        | 0.298      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.92      |
|    explained_variance   | 0.00437    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.654      |
|    n_updates            | 1040       |
|    policy_gradient_loss | 0.0161     |
|    std                  | 0.847      |
|    value_loss           | 1.38       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 598         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 106         |
|    time_elapsed         | 59662       |
|    total_timesteps      | 217088      |
| train/                  |             |
|    approx_kl            | 0.037319172 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.91       |
|    explained_variance   | 0.156       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.339       |
|    n_updates            | 1050        |
|    policy_gradient_loss | 0.0124      |
|    std                  | 0.846       |
|    value_loss           | 0.856       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 606         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 107         |
|    time_elapsed         | 59867       |
|    total_timesteps      | 219136      |
| train/                  |             |
|    approx_kl            | 0.041046064 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.89       |
|    explained_variance   | 0.391       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.426       |
|    n_updates            | 1060        |
|    policy_gradient_loss | 0.00824     |
|    std                  | 0.842       |
|    value_loss           | 0.768       |
-----------------------------------------
Eval num_timesteps=220000, episode_reward=-99.95 +/- 0.04
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 220000     |
| train/                  |            |
|    approx_kl            | 0.05116632 |
|    clip_fraction        | 0.297      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.87      |
|    explained_variance   | 0.796      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.523      |
|    n_updates            | 1070       |
|    policy_gradient_loss | 0.00559    |
|    std                  | 0.842      |
|    value_loss           | 1.32       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 603      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 108      |
|    time_elapsed    | 61874    |
|    total_timesteps | 221184   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 603        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 109        |
|    time_elapsed         | 62079      |
|    total_timesteps      | 223232     |
| train/                  |            |
|    approx_kl            | 0.06942882 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.85      |
|    explained_variance   | -0.000647  |
|    learning_rate        | 0.0003     |
|    loss                 | 2.61e+03   |
|    n_updates            | 1080       |
|    policy_gradient_loss | 0.016      |
|    std                  | 0.839      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 611        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 110        |
|    time_elapsed         | 62284      |
|    total_timesteps      | 225280     |
| train/                  |            |
|    approx_kl            | 0.15273935 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.82      |
|    explained_variance   | 0.0127     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.542      |
|    n_updates            | 1090       |
|    policy_gradient_loss | 0.00552    |
|    std                  | 0.838      |
|    value_loss           | 1.28       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 619         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 111         |
|    time_elapsed         | 62492       |
|    total_timesteps      | 227328      |
| train/                  |             |
|    approx_kl            | 0.045390427 |
|    clip_fraction        | 0.335       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.8        |
|    explained_variance   | 0.293       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.448       |
|    n_updates            | 1100        |
|    policy_gradient_loss | 0.0154      |
|    std                  | 0.836       |
|    value_loss           | 0.984       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 619        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 112        |
|    time_elapsed         | 62698      |
|    total_timesteps      | 229376     |
| train/                  |            |
|    approx_kl            | 0.04790695 |
|    clip_fraction        | 0.296      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.82      |
|    explained_variance   | 0.218      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.483      |
|    n_updates            | 1110       |
|    policy_gradient_loss | 0.00287    |
|    std                  | 0.84       |
|    value_loss           | 1.12       |
----------------------------------------
Eval num_timesteps=230000, episode_reward=-99.95 +/- 0.05
Episode length: 3597.40 +/- 7.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 230000      |
| train/                  |             |
|    approx_kl            | 0.047251835 |
|    clip_fraction        | 0.329       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.81       |
|    explained_variance   | 0.31        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.468       |
|    n_updates            | 1120        |
|    policy_gradient_loss | 0.00462     |
|    std                  | 0.835       |
|    value_loss           | 0.929       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 616      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 113      |
|    time_elapsed    | 64705    |
|    total_timesteps | 231424   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 616        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 114        |
|    time_elapsed         | 64911      |
|    total_timesteps      | 233472     |
| train/                  |            |
|    approx_kl            | 0.04507889 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.78      |
|    explained_variance   | -0.000129  |
|    learning_rate        | 0.0003     |
|    loss                 | 119        |
|    n_updates            | 1130       |
|    policy_gradient_loss | 0.00422    |
|    std                  | 0.834      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 624        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 115        |
|    time_elapsed         | 65117      |
|    total_timesteps      | 235520     |
| train/                  |            |
|    approx_kl            | 0.13079529 |
|    clip_fraction        | 0.329      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.76      |
|    explained_variance   | 0.0239     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.597      |
|    n_updates            | 1140       |
|    policy_gradient_loss | 0.0203     |
|    std                  | 0.832      |
|    value_loss           | 1.28       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 631         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 116         |
|    time_elapsed         | 65323       |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.035185706 |
|    clip_fraction        | 0.331       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.74       |
|    explained_variance   | -0.0771     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.06        |
|    n_updates            | 1150        |
|    policy_gradient_loss | 0.00422     |
|    std                  | 0.83        |
|    value_loss           | 1.26        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 631         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 117         |
|    time_elapsed         | 65528       |
|    total_timesteps      | 239616      |
| train/                  |             |
|    approx_kl            | 0.047292516 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.73       |
|    explained_variance   | 0.708       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.505       |
|    n_updates            | 1160        |
|    policy_gradient_loss | 0.0032      |
|    std                  | 0.83        |
|    value_loss           | 1.25        |
-----------------------------------------
Eval num_timesteps=240000, episode_reward=-99.95 +/- 0.03
Episode length: 3597.00 +/- 6.07
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 240000    |
| train/                  |           |
|    approx_kl            | 0.0487708 |
|    clip_fraction        | 0.317     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.71     |
|    explained_variance   | 0.242     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.879     |
|    n_updates            | 1170      |
|    policy_gradient_loss | 0.00748   |
|    std                  | 0.827     |
|    value_loss           | 1.19      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 628      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 118      |
|    time_elapsed    | 67536    |
|    total_timesteps | 241664   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 635         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 119         |
|    time_elapsed         | 67741       |
|    total_timesteps      | 243712      |
| train/                  |             |
|    approx_kl            | 0.038890474 |
|    clip_fraction        | 0.35        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.7        |
|    explained_variance   | 0.00277     |
|    learning_rate        | 0.0003      |
|    loss                 | 347         |
|    n_updates            | 1180        |
|    policy_gradient_loss | 0.00768     |
|    std                  | 0.826       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 635        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 120        |
|    time_elapsed         | 67947      |
|    total_timesteps      | 245760     |
| train/                  |            |
|    approx_kl            | 0.12465342 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.67      |
|    explained_variance   | 0.0167     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.988      |
|    n_updates            | 1190       |
|    policy_gradient_loss | 0.0118     |
|    std                  | 0.823      |
|    value_loss           | 1.83       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 641        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 121        |
|    time_elapsed         | 68157      |
|    total_timesteps      | 247808     |
| train/                  |            |
|    approx_kl            | 0.05936542 |
|    clip_fraction        | 0.331      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.66      |
|    explained_variance   | 0.00967    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.829      |
|    n_updates            | 1200       |
|    policy_gradient_loss | 0.00816    |
|    std                  | 0.823      |
|    value_loss           | 1.74       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 641       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 122       |
|    time_elapsed         | 68362     |
|    total_timesteps      | 249856    |
| train/                  |           |
|    approx_kl            | 0.3672874 |
|    clip_fraction        | 0.386     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.65     |
|    explained_variance   | 0.0118    |
|    learning_rate        | 0.0003    |
|    loss                 | 1.27      |
|    n_updates            | 1210      |
|    policy_gradient_loss | 0.0164    |
|    std                  | 0.82      |
|    value_loss           | 1.52      |
---------------------------------------
Eval num_timesteps=250000, episode_reward=-99.91 +/- 0.03
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 250000    |
| train/                  |           |
|    approx_kl            | 0.0420996 |
|    clip_fraction        | 0.313     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.62     |
|    explained_variance   | 0.239     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.628     |
|    n_updates            | 1220      |
|    policy_gradient_loss | 0.00885   |
|    std                  | 0.816     |
|    value_loss           | 1.15      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 637      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 123      |
|    time_elapsed    | 70368    |
|    total_timesteps | 251904   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 644         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 124         |
|    time_elapsed         | 70574       |
|    total_timesteps      | 253952      |
| train/                  |             |
|    approx_kl            | 0.033326074 |
|    clip_fraction        | 0.326       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.6        |
|    explained_variance   | -0.0016     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.22e+03    |
|    n_updates            | 1230        |
|    policy_gradient_loss | -0.000136   |
|    std                  | 0.814       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 644        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 125        |
|    time_elapsed         | 70779      |
|    total_timesteps      | 256000     |
| train/                  |            |
|    approx_kl            | 0.39522442 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.56      |
|    explained_variance   | 0.028      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.603      |
|    n_updates            | 1240       |
|    policy_gradient_loss | 0.0149     |
|    std                  | 0.81       |
|    value_loss           | 1.35       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 649        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 126        |
|    time_elapsed         | 70985      |
|    total_timesteps      | 258048     |
| train/                  |            |
|    approx_kl            | 0.44200283 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.55      |
|    explained_variance   | 0.143      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.537      |
|    n_updates            | 1250       |
|    policy_gradient_loss | 0.0184     |
|    std                  | 0.813      |
|    value_loss           | 1.15       |
----------------------------------------
Eval num_timesteps=260000, episode_reward=-99.90 +/- 0.05
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 260000     |
| train/                  |            |
|    approx_kl            | 0.13275647 |
|    clip_fraction        | 0.303      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.56      |
|    explained_variance   | 0.284      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.457      |
|    n_updates            | 1260       |
|    policy_gradient_loss | 0.0113     |
|    std                  | 0.814      |
|    value_loss           | 0.902      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 645      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 127      |
|    time_elapsed    | 72993    |
|    total_timesteps | 260096   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 645         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 128         |
|    time_elapsed         | 73199       |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.038187407 |
|    clip_fraction        | 0.323       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.58       |
|    explained_variance   | -0.000921   |
|    learning_rate        | 0.0003      |
|    loss                 | 12.4        |
|    n_updates            | 1270        |
|    policy_gradient_loss | 0.00129     |
|    std                  | 0.817       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 650        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 129        |
|    time_elapsed         | 73404      |
|    total_timesteps      | 264192     |
| train/                  |            |
|    approx_kl            | 0.03756617 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.58      |
|    explained_variance   | 0.00635    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.606      |
|    n_updates            | 1280       |
|    policy_gradient_loss | 0.0119     |
|    std                  | 0.813      |
|    value_loss           | 1.37       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 650         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 130         |
|    time_elapsed         | 73612       |
|    total_timesteps      | 266240      |
| train/                  |             |
|    approx_kl            | 0.038122214 |
|    clip_fraction        | 0.357       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.54       |
|    explained_variance   | 0.000228    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.573       |
|    n_updates            | 1290        |
|    policy_gradient_loss | 0.0177      |
|    std                  | 0.808       |
|    value_loss           | 1.22        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 655        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 131        |
|    time_elapsed         | 73817      |
|    total_timesteps      | 268288     |
| train/                  |            |
|    approx_kl            | 0.39488363 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.54      |
|    explained_variance   | 0.00482    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.52       |
|    n_updates            | 1300       |
|    policy_gradient_loss | 0.0417     |
|    std                  | 0.811      |
|    value_loss           | 1.28       |
----------------------------------------
Eval num_timesteps=270000, episode_reward=-99.92 +/- 0.05
Episode length: 3596.80 +/- 7.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 270000      |
| train/                  |             |
|    approx_kl            | 0.036767893 |
|    clip_fraction        | 0.313       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.51       |
|    explained_variance   | 0.0175      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.38        |
|    n_updates            | 1310        |
|    policy_gradient_loss | 0.00867     |
|    std                  | 0.806       |
|    value_loss           | 1.08        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 652      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 132      |
|    time_elapsed    | 75823    |
|    total_timesteps | 270336   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 652        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 133        |
|    time_elapsed         | 76029      |
|    total_timesteps      | 272384     |
| train/                  |            |
|    approx_kl            | 0.04280664 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.49      |
|    explained_variance   | -0.00187   |
|    learning_rate        | 0.0003     |
|    loss                 | 178        |
|    n_updates            | 1320       |
|    policy_gradient_loss | 0.00624    |
|    std                  | 0.806      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 658        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 134        |
|    time_elapsed         | 76234      |
|    total_timesteps      | 274432     |
| train/                  |            |
|    approx_kl            | 0.25291163 |
|    clip_fraction        | 0.325      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.48      |
|    explained_variance   | 0.00816    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.371      |
|    n_updates            | 1330       |
|    policy_gradient_loss | 0.00826    |
|    std                  | 0.805      |
|    value_loss           | 1.01       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 658        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 135        |
|    time_elapsed         | 76440      |
|    total_timesteps      | 276480     |
| train/                  |            |
|    approx_kl            | 0.06375061 |
|    clip_fraction        | 0.284      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.46      |
|    explained_variance   | 0.267      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.483      |
|    n_updates            | 1340       |
|    policy_gradient_loss | 0.0156     |
|    std                  | 0.802      |
|    value_loss           | 1.04       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 663         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 136         |
|    time_elapsed         | 76645       |
|    total_timesteps      | 278528      |
| train/                  |             |
|    approx_kl            | 0.054393686 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.41       |
|    explained_variance   | 0.315       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.317       |
|    n_updates            | 1350        |
|    policy_gradient_loss | 0.00279     |
|    std                  | 0.798       |
|    value_loss           | 0.901       |
-----------------------------------------
Eval num_timesteps=280000, episode_reward=-99.88 +/- 0.06
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 280000      |
| train/                  |             |
|    approx_kl            | 0.094342604 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.38       |
|    explained_variance   | 0.292       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.631       |
|    n_updates            | 1360        |
|    policy_gradient_loss | 0.0107      |
|    std                  | 0.795       |
|    value_loss           | 1.04        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 660      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 137      |
|    time_elapsed    | 78652    |
|    total_timesteps | 280576   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 660         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 138         |
|    time_elapsed         | 78858       |
|    total_timesteps      | 282624      |
| train/                  |             |
|    approx_kl            | 0.028067026 |
|    clip_fraction        | 0.223       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.37       |
|    explained_variance   | 0.0365      |
|    learning_rate        | 0.0003      |
|    loss                 | 8.82        |
|    n_updates            | 1370        |
|    policy_gradient_loss | -0.00591    |
|    std                  | 0.796       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 665      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 139      |
|    time_elapsed         | 79064    |
|    total_timesteps      | 284672   |
| train/                  |          |
|    approx_kl            | 1.610749 |
|    clip_fraction        | 0.435    |
|    clip_range           | 0.2      |
|    entropy_loss         | -9.37    |
|    explained_variance   | 0.0774   |
|    learning_rate        | 0.0003   |
|    loss                 | 0.279    |
|    n_updates            | 1380     |
|    policy_gradient_loss | 0.0218   |
|    std                  | 0.794    |
|    value_loss           | 0.79     |
--------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 665         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 140         |
|    time_elapsed         | 79270       |
|    total_timesteps      | 286720      |
| train/                  |             |
|    approx_kl            | 0.041893497 |
|    clip_fraction        | 0.34        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.35       |
|    explained_variance   | 0.333       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.448       |
|    n_updates            | 1390        |
|    policy_gradient_loss | 0.115       |
|    std                  | 0.792       |
|    value_loss           | 0.855       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 670         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 141         |
|    time_elapsed         | 79475       |
|    total_timesteps      | 288768      |
| train/                  |             |
|    approx_kl            | 0.062131207 |
|    clip_fraction        | 0.355       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.31       |
|    explained_variance   | 0.397       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.384       |
|    n_updates            | 1400        |
|    policy_gradient_loss | 0.0119      |
|    std                  | 0.79        |
|    value_loss           | 0.766       |
-----------------------------------------
Eval num_timesteps=290000, episode_reward=-99.86 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 290000      |
| train/                  |             |
|    approx_kl            | 0.054280683 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.31       |
|    explained_variance   | -0.553      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.489       |
|    n_updates            | 1410        |
|    policy_gradient_loss | 0.00975     |
|    std                  | 0.793       |
|    value_loss           | 1.13        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 667      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 142      |
|    time_elapsed    | 81482    |
|    total_timesteps | 290816   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 667         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 143         |
|    time_elapsed         | 81687       |
|    total_timesteps      | 292864      |
| train/                  |             |
|    approx_kl            | 0.051428247 |
|    clip_fraction        | 0.33        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.33       |
|    explained_variance   | -0.00298    |
|    learning_rate        | 0.0003      |
|    loss                 | 7.03        |
|    n_updates            | 1420        |
|    policy_gradient_loss | 0.00478     |
|    std                  | 0.796       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 673        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 144        |
|    time_elapsed         | 81893      |
|    total_timesteps      | 294912     |
| train/                  |            |
|    approx_kl            | 0.62105465 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.34      |
|    explained_variance   | -0.0197    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.24       |
|    n_updates            | 1430       |
|    policy_gradient_loss | 0.0108     |
|    std                  | 0.795      |
|    value_loss           | 1.05       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 673         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 145         |
|    time_elapsed         | 82098       |
|    total_timesteps      | 296960      |
| train/                  |             |
|    approx_kl            | 0.039502595 |
|    clip_fraction        | 0.329       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.27       |
|    explained_variance   | 0.43        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.85        |
|    n_updates            | 1440        |
|    policy_gradient_loss | -0.000213   |
|    std                  | 0.785       |
|    value_loss           | 1.22        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 679         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 146         |
|    time_elapsed         | 82303       |
|    total_timesteps      | 299008      |
| train/                  |             |
|    approx_kl            | 0.057207465 |
|    clip_fraction        | 0.296       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.22       |
|    explained_variance   | 0.369       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.737       |
|    n_updates            | 1450        |
|    policy_gradient_loss | 0.0121      |
|    std                  | 0.784       |
|    value_loss           | 1.16        |
-----------------------------------------
Eval num_timesteps=300000, episode_reward=-99.87 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 300000      |
| train/                  |             |
|    approx_kl            | 0.037508518 |
|    clip_fraction        | 0.339       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.21       |
|    explained_variance   | 0.308       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.593       |
|    n_updates            | 1460        |
|    policy_gradient_loss | 0.00743     |
|    std                  | 0.783       |
|    value_loss           | 1.13        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 676      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 147      |
|    time_elapsed    | 84309    |
|    total_timesteps | 301056   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 676        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 148        |
|    time_elapsed         | 84515      |
|    total_timesteps      | 303104     |
| train/                  |            |
|    approx_kl            | 0.03669575 |
|    clip_fraction        | 0.304      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.21      |
|    explained_variance   | -0.000217  |
|    learning_rate        | 0.0003     |
|    loss                 | 1.81e+03   |
|    n_updates            | 1470       |
|    policy_gradient_loss | -0.00188   |
|    std                  | 0.785      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 682        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 149        |
|    time_elapsed         | 84720      |
|    total_timesteps      | 305152     |
| train/                  |            |
|    approx_kl            | 0.06706667 |
|    clip_fraction        | 0.313      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.21      |
|    explained_variance   | 0.186      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.601      |
|    n_updates            | 1480       |
|    policy_gradient_loss | 0.0103     |
|    std                  | 0.782      |
|    value_loss           | 1.16       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 687        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 150        |
|    time_elapsed         | 84926      |
|    total_timesteps      | 307200     |
| train/                  |            |
|    approx_kl            | 0.05499392 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.17      |
|    explained_variance   | 0.248      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.362      |
|    n_updates            | 1490       |
|    policy_gradient_loss | 0.00274    |
|    std                  | 0.78       |
|    value_loss           | 1.21       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 687        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 151        |
|    time_elapsed         | 85131      |
|    total_timesteps      | 309248     |
| train/                  |            |
|    approx_kl            | 0.06389262 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.14      |
|    explained_variance   | 0.43       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.472      |
|    n_updates            | 1500       |
|    policy_gradient_loss | 0.00171    |
|    std                  | 0.775      |
|    value_loss           | 0.841      |
----------------------------------------
Eval num_timesteps=310000, episode_reward=-99.87 +/- 0.05
Episode length: 3599.60 +/- 2.33
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 310000     |
| train/                  |            |
|    approx_kl            | 0.04487423 |
|    clip_fraction        | 0.299      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.1       |
|    explained_variance   | 0.385      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.58       |
|    n_updates            | 1510       |
|    policy_gradient_loss | 0.00963    |
|    std                  | 0.775      |
|    value_loss           | 1.16       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 685      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 152      |
|    time_elapsed    | 87138    |
|    total_timesteps | 311296   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 685         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 153         |
|    time_elapsed         | 87344       |
|    total_timesteps      | 313344      |
| train/                  |             |
|    approx_kl            | 0.059868194 |
|    clip_fraction        | 0.364       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.11       |
|    explained_variance   | 0.000841    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.19e+03    |
|    n_updates            | 1520        |
|    policy_gradient_loss | -0.00241    |
|    std                  | 0.776       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 690        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 154        |
|    time_elapsed         | 87549      |
|    total_timesteps      | 315392     |
| train/                  |            |
|    approx_kl            | 0.07431593 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.13      |
|    explained_variance   | 0.102      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.414      |
|    n_updates            | 1530       |
|    policy_gradient_loss | 0.0239     |
|    std                  | 0.778      |
|    value_loss           | 0.894      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 696        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 155        |
|    time_elapsed         | 87755      |
|    total_timesteps      | 317440     |
| train/                  |            |
|    approx_kl            | 0.04000496 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.11      |
|    explained_variance   | 0.381      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.635      |
|    n_updates            | 1540       |
|    policy_gradient_loss | 0.00991    |
|    std                  | 0.775      |
|    value_loss           | 1.16       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 696         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 156         |
|    time_elapsed         | 87960       |
|    total_timesteps      | 319488      |
| train/                  |             |
|    approx_kl            | 0.058823697 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.07       |
|    explained_variance   | 0.716       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.16        |
|    n_updates            | 1550        |
|    policy_gradient_loss | 0.00889     |
|    std                  | 0.769       |
|    value_loss           | 1.6         |
-----------------------------------------
Eval num_timesteps=320000, episode_reward=-99.87 +/- 0.03
Episode length: 3601.00 +/- 0.00
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 3.6e+03  |
|    mean_reward          | -99.9    |
| time/                   |          |
|    total_timesteps      | 320000   |
| train/                  |          |
|    approx_kl            | 0.279378 |
|    clip_fraction        | 0.304    |
|    clip_range           | 0.2      |
|    entropy_loss         | -9.06    |
|    explained_variance   | 0.353    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.657    |
|    n_updates            | 1560     |
|    policy_gradient_loss | 0.0214   |
|    std                  | 0.772    |
|    value_loss           | 1.29     |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 693      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 157      |
|    time_elapsed    | 89968    |
|    total_timesteps | 321536   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 693         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 158         |
|    time_elapsed         | 90173       |
|    total_timesteps      | 323584      |
| train/                  |             |
|    approx_kl            | 0.050745226 |
|    clip_fraction        | 0.36        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.07       |
|    explained_variance   | 0.000395    |
|    learning_rate        | 0.0003      |
|    loss                 | 641         |
|    n_updates            | 1570        |
|    policy_gradient_loss | -0.00168    |
|    std                  | 0.771       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 699        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 159        |
|    time_elapsed         | 90380      |
|    total_timesteps      | 325632     |
| train/                  |            |
|    approx_kl            | 0.64502275 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.04      |
|    explained_variance   | 0.0721     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.464      |
|    n_updates            | 1580       |
|    policy_gradient_loss | 0.024      |
|    std                  | 0.765      |
|    value_loss           | 1.06       |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 705      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 160      |
|    time_elapsed         | 90586    |
|    total_timesteps      | 327680   |
| train/                  |          |
|    approx_kl            | 0.180804 |
|    clip_fraction        | 0.314    |
|    clip_range           | 0.2      |
|    entropy_loss         | -9       |
|    explained_variance   | -0.0942  |
|    learning_rate        | 0.0003   |
|    loss                 | 0.392    |
|    n_updates            | 1590     |
|    policy_gradient_loss | 0.00592  |
|    std                  | 0.765    |
|    value_loss           | 1.01     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 705       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 161       |
|    time_elapsed         | 90791     |
|    total_timesteps      | 329728    |
| train/                  |           |
|    approx_kl            | 0.0309017 |
|    clip_fraction        | 0.339     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.01     |
|    explained_variance   | 0.43      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.445     |
|    n_updates            | 1600      |
|    policy_gradient_loss | 0.011     |
|    std                  | 0.765     |
|    value_loss           | 0.832     |
---------------------------------------
Eval num_timesteps=330000, episode_reward=-99.86 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 330000      |
| train/                  |             |
|    approx_kl            | 0.062791735 |
|    clip_fraction        | 0.304       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.98       |
|    explained_variance   | 0.411       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.617       |
|    n_updates            | 1610        |
|    policy_gradient_loss | 0.0105      |
|    std                  | 0.761       |
|    value_loss           | 0.745       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 702      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 162      |
|    time_elapsed    | 92797    |
|    total_timesteps | 331776   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 707        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 163        |
|    time_elapsed         | 93002      |
|    total_timesteps      | 333824     |
| train/                  |            |
|    approx_kl            | 0.04816039 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.97      |
|    explained_variance   | -0.0003    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.67e+03   |
|    n_updates            | 1620       |
|    policy_gradient_loss | 0.00095    |
|    std                  | 0.762      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 707       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 164       |
|    time_elapsed         | 93209     |
|    total_timesteps      | 335872    |
| train/                  |           |
|    approx_kl            | 0.2777967 |
|    clip_fraction        | 0.391     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.98     |
|    explained_variance   | -0.18     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.516     |
|    n_updates            | 1630      |
|    policy_gradient_loss | 0.0185    |
|    std                  | 0.762     |
|    value_loss           | 1.23      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 724        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 165        |
|    time_elapsed         | 93414      |
|    total_timesteps      | 337920     |
| train/                  |            |
|    approx_kl            | 0.05530887 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.97      |
|    explained_variance   | 0.318      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.446      |
|    n_updates            | 1640       |
|    policy_gradient_loss | 0.0153     |
|    std                  | 0.761      |
|    value_loss           | 0.935      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 724         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 166         |
|    time_elapsed         | 93620       |
|    total_timesteps      | 339968      |
| train/                  |             |
|    approx_kl            | 0.027627423 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.97       |
|    explained_variance   | 0.383       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.36        |
|    n_updates            | 1650        |
|    policy_gradient_loss | 0.00764     |
|    std                  | 0.762       |
|    value_loss           | 0.936       |
-----------------------------------------
Eval num_timesteps=340000, episode_reward=-99.89 +/- 0.04
Episode length: 3597.20 +/- 7.11
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 340000      |
| train/                  |             |
|    approx_kl            | 0.030213714 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.96       |
|    explained_variance   | 0.363       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.472       |
|    n_updates            | 1660        |
|    policy_gradient_loss | 0.0123      |
|    std                  | 0.761       |
|    value_loss           | 0.976       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 733      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 167      |
|    time_elapsed    | 95627    |
|    total_timesteps | 342016   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 751         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 168         |
|    time_elapsed         | 95833       |
|    total_timesteps      | 344064      |
| train/                  |             |
|    approx_kl            | 0.048688866 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.96       |
|    explained_variance   | 0.00858     |
|    learning_rate        | 0.0003      |
|    loss                 | 7.78        |
|    n_updates            | 1670        |
|    policy_gradient_loss | -0.00352    |
|    std                  | 0.761       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 751        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 169        |
|    time_elapsed         | 96038      |
|    total_timesteps      | 346112     |
| train/                  |            |
|    approx_kl            | 0.28879377 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.94      |
|    explained_variance   | 0.0326     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.395      |
|    n_updates            | 1680       |
|    policy_gradient_loss | 0.0186     |
|    std                  | 0.757      |
|    value_loss           | 1.15       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 765        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 170        |
|    time_elapsed         | 96245      |
|    total_timesteps      | 348160     |
| train/                  |            |
|    approx_kl            | 0.07799335 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.91      |
|    explained_variance   | 0.354      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.382      |
|    n_updates            | 1690       |
|    policy_gradient_loss | 0.0167     |
|    std                  | 0.756      |
|    value_loss           | 0.947      |
----------------------------------------
Eval num_timesteps=350000, episode_reward=-99.82 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 350000      |
| train/                  |             |
|    approx_kl            | 0.043648306 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.91       |
|    explained_variance   | 0.158       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.401       |
|    n_updates            | 1700        |
|    policy_gradient_loss | 0.00553     |
|    std                  | 0.754       |
|    value_loss           | 0.949       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 769      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 171      |
|    time_elapsed    | 98253    |
|    total_timesteps | 350208   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 769         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 172         |
|    time_elapsed         | 98458       |
|    total_timesteps      | 352256      |
| train/                  |             |
|    approx_kl            | 0.054193832 |
|    clip_fraction        | 0.349       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.91       |
|    explained_variance   | 0.00167     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.35e+03    |
|    n_updates            | 1710        |
|    policy_gradient_loss | 0.00963     |
|    std                  | 0.758       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 786        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 173        |
|    time_elapsed         | 98664      |
|    total_timesteps      | 354304     |
| train/                  |            |
|    approx_kl            | 0.04433644 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.94      |
|    explained_variance   | -0.00431   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.344      |
|    n_updates            | 1720       |
|    policy_gradient_loss | 0.0161     |
|    std                  | 0.76       |
|    value_loss           | 0.952      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 786        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 174        |
|    time_elapsed         | 98869      |
|    total_timesteps      | 356352     |
| train/                  |            |
|    approx_kl            | 0.06352053 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.91      |
|    explained_variance   | 0.39       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.379      |
|    n_updates            | 1730       |
|    policy_gradient_loss | 0.0193     |
|    std                  | 0.755      |
|    value_loss           | 0.744      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 797        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 175        |
|    time_elapsed         | 99075      |
|    total_timesteps      | 358400     |
| train/                  |            |
|    approx_kl            | 0.03665962 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.88      |
|    explained_variance   | 0.458      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.284      |
|    n_updates            | 1740       |
|    policy_gradient_loss | 0.00787    |
|    std                  | 0.753      |
|    value_loss           | 0.725      |
----------------------------------------
Eval num_timesteps=360000, episode_reward=-99.83 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 360000      |
| train/                  |             |
|    approx_kl            | 0.035977498 |
|    clip_fraction        | 0.336       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.84       |
|    explained_variance   | 0.429       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.253       |
|    n_updates            | 1750        |
|    policy_gradient_loss | 0.0131      |
|    std                  | 0.75        |
|    value_loss           | 0.724       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 799      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 176      |
|    time_elapsed    | 101081   |
|    total_timesteps | 360448   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 799        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 177        |
|    time_elapsed         | 101286     |
|    total_timesteps      | 362496     |
| train/                  |            |
|    approx_kl            | 0.10664506 |
|    clip_fraction        | 0.351      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.81      |
|    explained_variance   | -0.000656  |
|    learning_rate        | 0.0003     |
|    loss                 | 101        |
|    n_updates            | 1760       |
|    policy_gradient_loss | -0.00107   |
|    std                  | 0.749      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 814        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 178        |
|    time_elapsed         | 101492     |
|    total_timesteps      | 364544     |
| train/                  |            |
|    approx_kl            | 0.93083876 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.82      |
|    explained_variance   | 0.0453     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.493      |
|    n_updates            | 1770       |
|    policy_gradient_loss | 0.0139     |
|    std                  | 0.749      |
|    value_loss           | 1.23       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 814         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 179         |
|    time_elapsed         | 101697      |
|    total_timesteps      | 366592      |
| train/                  |             |
|    approx_kl            | 0.037601024 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.79       |
|    explained_variance   | 0.411       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.424       |
|    n_updates            | 1780        |
|    policy_gradient_loss | 0.0159      |
|    std                  | 0.746       |
|    value_loss           | 0.847       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 822        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 180        |
|    time_elapsed         | 101902     |
|    total_timesteps      | 368640     |
| train/                  |            |
|    approx_kl            | 0.03828852 |
|    clip_fraction        | 0.321      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.73      |
|    explained_variance   | 0.452      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.412      |
|    n_updates            | 1790       |
|    policy_gradient_loss | 0.0176     |
|    std                  | 0.74       |
|    value_loss           | 0.825      |
----------------------------------------
Eval num_timesteps=370000, episode_reward=-99.82 +/- 0.03
Episode length: 3595.80 +/- 7.11
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 370000      |
| train/                  |             |
|    approx_kl            | 0.034492273 |
|    clip_fraction        | 0.319       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.7        |
|    explained_variance   | 0.387       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.534       |
|    n_updates            | 1800        |
|    policy_gradient_loss | 0.0095      |
|    std                  | 0.74        |
|    value_loss           | 0.955       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 823      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 181      |
|    time_elapsed    | 103910   |
|    total_timesteps | 370688   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 823         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 182         |
|    time_elapsed         | 104117      |
|    total_timesteps      | 372736      |
| train/                  |             |
|    approx_kl            | 0.077521995 |
|    clip_fraction        | 0.305       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.71       |
|    explained_variance   | 0.119       |
|    learning_rate        | 0.0003      |
|    loss                 | 12.9        |
|    n_updates            | 1810        |
|    policy_gradient_loss | -0.000553   |
|    std                  | 0.742       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 835        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 183        |
|    time_elapsed         | 104322     |
|    total_timesteps      | 374784     |
| train/                  |            |
|    approx_kl            | 0.11749992 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.68      |
|    explained_variance   | 0.01       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.653      |
|    n_updates            | 1820       |
|    policy_gradient_loss | 0.0163     |
|    std                  | 0.737      |
|    value_loss           | 1.41       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 835        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 184        |
|    time_elapsed         | 104528     |
|    total_timesteps      | 376832     |
| train/                  |            |
|    approx_kl            | 0.12367503 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.66      |
|    explained_variance   | 0.932      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.19       |
|    n_updates            | 1830       |
|    policy_gradient_loss | -0.004     |
|    std                  | 0.738      |
|    value_loss           | 6.15       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 841         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 185         |
|    time_elapsed         | 104733      |
|    total_timesteps      | 378880      |
| train/                  |             |
|    approx_kl            | 0.101558074 |
|    clip_fraction        | 0.392       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.64       |
|    explained_variance   | 0.333       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.447       |
|    n_updates            | 1840        |
|    policy_gradient_loss | 0.037       |
|    std                  | 0.735       |
|    value_loss           | 1.12        |
-----------------------------------------
Eval num_timesteps=380000, episode_reward=-99.85 +/- 0.04
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 380000     |
| train/                  |            |
|    approx_kl            | 0.21022587 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.63      |
|    explained_variance   | -0.188     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.438      |
|    n_updates            | 1850       |
|    policy_gradient_loss | 0.0256     |
|    std                  | 0.733      |
|    value_loss           | 1.41       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 839      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 186      |
|    time_elapsed    | 106741   |
|    total_timesteps | 380928   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 839        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 187        |
|    time_elapsed         | 106948     |
|    total_timesteps      | 382976     |
| train/                  |            |
|    approx_kl            | 0.05499441 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.63      |
|    explained_variance   | 0.00128    |
|    learning_rate        | 0.0003     |
|    loss                 | 743        |
|    n_updates            | 1860       |
|    policy_gradient_loss | 0.00752    |
|    std                  | 0.735      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 852       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 188       |
|    time_elapsed         | 107154    |
|    total_timesteps      | 385024    |
| train/                  |           |
|    approx_kl            | 2.3970428 |
|    clip_fraction        | 0.418     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.65     |
|    explained_variance   | 0.00397   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.655     |
|    n_updates            | 1870      |
|    policy_gradient_loss | 0.0271    |
|    std                  | 0.737     |
|    value_loss           | 1.54      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 852        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 189        |
|    time_elapsed         | 107359     |
|    total_timesteps      | 387072     |
| train/                  |            |
|    approx_kl            | 0.10041332 |
|    clip_fraction        | 0.323      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.66      |
|    explained_variance   | 0.943      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.6        |
|    n_updates            | 1880       |
|    policy_gradient_loss | 0.00592    |
|    std                  | 0.738      |
|    value_loss           | 4.78       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 853        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 190        |
|    time_elapsed         | 107565     |
|    total_timesteps      | 389120     |
| train/                  |            |
|    approx_kl            | 0.11355083 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.64      |
|    explained_variance   | 0.017      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.425      |
|    n_updates            | 1890       |
|    policy_gradient_loss | 0.0299     |
|    std                  | 0.734      |
|    value_loss           | 1.07       |
----------------------------------------
Eval num_timesteps=390000, episode_reward=-99.82 +/- 0.04
Episode length: 3597.20 +/- 7.60
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 390000    |
| train/                  |           |
|    approx_kl            | 0.2122458 |
|    clip_fraction        | 0.35      |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.61     |
|    explained_variance   | 0.309     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.382     |
|    n_updates            | 1900      |
|    policy_gradient_loss | 0.00774   |
|    std                  | 0.731     |
|    value_loss           | 1.55      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 851      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 191      |
|    time_elapsed    | 109571   |
|    total_timesteps | 391168   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 851         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 192         |
|    time_elapsed         | 109776      |
|    total_timesteps      | 393216      |
| train/                  |             |
|    approx_kl            | 0.058725365 |
|    clip_fraction        | 0.376       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.58       |
|    explained_variance   | 0.000644    |
|    learning_rate        | 0.0003      |
|    loss                 | 396         |
|    n_updates            | 1910        |
|    policy_gradient_loss | -0.00132    |
|    std                  | 0.729       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 864       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 193       |
|    time_elapsed         | 109982    |
|    total_timesteps      | 395264    |
| train/                  |           |
|    approx_kl            | 1.4054694 |
|    clip_fraction        | 0.412     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.56     |
|    explained_variance   | -0.00719  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.774     |
|    n_updates            | 1920      |
|    policy_gradient_loss | 0.0243    |
|    std                  | 0.725     |
|    value_loss           | 1.56      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 869      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 194      |
|    time_elapsed         | 110187   |
|    total_timesteps      | 397312   |
| train/                  |          |
|    approx_kl            | 2.718216 |
|    clip_fraction        | 0.447    |
|    clip_range           | 0.2      |
|    entropy_loss         | -8.54    |
|    explained_variance   | -0.0243  |
|    learning_rate        | 0.0003   |
|    loss                 | 0.678    |
|    n_updates            | 1930     |
|    policy_gradient_loss | 0.0154   |
|    std                  | 0.725    |
|    value_loss           | 1.25     |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 869        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 195        |
|    time_elapsed         | 110394     |
|    total_timesteps      | 399360     |
| train/                  |            |
|    approx_kl            | 0.35847527 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.53      |
|    explained_variance   | -0.00097   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.638      |
|    n_updates            | 1940       |
|    policy_gradient_loss | 0.0358     |
|    std                  | 0.724      |
|    value_loss           | 1.53       |
----------------------------------------
Eval num_timesteps=400000, episode_reward=-99.82 +/- 0.03
Episode length: 3600.00 +/- 2.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 400000      |
| train/                  |             |
|    approx_kl            | 0.070987105 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.5        |
|    explained_variance   | 0.32        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.476       |
|    n_updates            | 1950        |
|    policy_gradient_loss | 0.0109      |
|    std                  | 0.721       |
|    value_loss           | 1.01        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 867      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 196      |
|    time_elapsed    | 112402   |
|    total_timesteps | 401408   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 867         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 197         |
|    time_elapsed         | 112607      |
|    total_timesteps      | 403456      |
| train/                  |             |
|    approx_kl            | 0.045249265 |
|    clip_fraction        | 0.358       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.5        |
|    explained_variance   | -0.00122    |
|    learning_rate        | 0.0003      |
|    loss                 | 740         |
|    n_updates            | 1960        |
|    policy_gradient_loss | 0.00258     |
|    std                  | 0.723       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 878        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 198        |
|    time_elapsed         | 112813     |
|    total_timesteps      | 405504     |
| train/                  |            |
|    approx_kl            | 0.83459604 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.5       |
|    explained_variance   | 0.00225    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.768      |
|    n_updates            | 1970       |
|    policy_gradient_loss | 0.0239     |
|    std                  | 0.719      |
|    value_loss           | 1.47       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 883        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 199        |
|    time_elapsed         | 113018     |
|    total_timesteps      | 407552     |
| train/                  |            |
|    approx_kl            | 0.36106533 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.46      |
|    explained_variance   | -0.154     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.671      |
|    n_updates            | 1980       |
|    policy_gradient_loss | 0.0327     |
|    std                  | 0.715      |
|    value_loss           | 1.41       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 883        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 200        |
|    time_elapsed         | 113224     |
|    total_timesteps      | 409600     |
| train/                  |            |
|    approx_kl            | 0.10521482 |
|    clip_fraction        | 0.368      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.45      |
|    explained_variance   | 0.912      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.08       |
|    n_updates            | 1990       |
|    policy_gradient_loss | 0.0051     |
|    std                  | 0.717      |
|    value_loss           | 2.42       |
----------------------------------------
Eval num_timesteps=410000, episode_reward=-99.80 +/- 0.07
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 410000     |
| train/                  |            |
|    approx_kl            | 0.24690352 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.42      |
|    explained_variance   | -6.75e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.873      |
|    n_updates            | 2000       |
|    policy_gradient_loss | 0.0149     |
|    std                  | 0.712      |
|    value_loss           | 1.47       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 879      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 201      |
|    time_elapsed    | 115231   |
|    total_timesteps | 411648   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 887         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 202         |
|    time_elapsed         | 115437      |
|    total_timesteps      | 413696      |
| train/                  |             |
|    approx_kl            | 0.038929436 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.4        |
|    explained_variance   | 0.0818      |
|    learning_rate        | 0.0003      |
|    loss                 | 7.57        |
|    n_updates            | 2010        |
|    policy_gradient_loss | 0.000823    |
|    std                  | 0.712       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 887       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 203       |
|    time_elapsed         | 115642    |
|    total_timesteps      | 415744    |
| train/                  |           |
|    approx_kl            | 1.3246326 |
|    clip_fraction        | 0.405     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.38     |
|    explained_variance   | -0.266    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.363     |
|    n_updates            | 2020      |
|    policy_gradient_loss | 0.0215    |
|    std                  | 0.709     |
|    value_loss           | 1.02      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 890        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 204        |
|    time_elapsed         | 115848     |
|    total_timesteps      | 417792     |
| train/                  |            |
|    approx_kl            | 0.04524553 |
|    clip_fraction        | 0.335      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.37      |
|    explained_variance   | 0.293      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.715      |
|    n_updates            | 2030       |
|    policy_gradient_loss | 0.0164     |
|    std                  | 0.709      |
|    value_loss           | 1.53       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 890        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 205        |
|    time_elapsed         | 116053     |
|    total_timesteps      | 419840     |
| train/                  |            |
|    approx_kl            | 0.05468384 |
|    clip_fraction        | 0.328      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.36      |
|    explained_variance   | 0.938      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.715      |
|    n_updates            | 2040       |
|    policy_gradient_loss | 0.00421    |
|    std                  | 0.709      |
|    value_loss           | 3.03       |
----------------------------------------
Eval num_timesteps=420000, episode_reward=-99.83 +/- 0.03
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 420000      |
| train/                  |             |
|    approx_kl            | 0.039865956 |
|    clip_fraction        | 0.329       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.34       |
|    explained_variance   | 0.335       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.74        |
|    n_updates            | 2050        |
|    policy_gradient_loss | 0.0138      |
|    std                  | 0.705       |
|    value_loss           | 1.13        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 885      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 206      |
|    time_elapsed    | 118059   |
|    total_timesteps | 421888   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 895        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 207        |
|    time_elapsed         | 118265     |
|    total_timesteps      | 423936     |
| train/                  |            |
|    approx_kl            | 0.08178576 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.33      |
|    explained_variance   | 0.00172    |
|    learning_rate        | 0.0003     |
|    loss                 | 23.2       |
|    n_updates            | 2060       |
|    policy_gradient_loss | 0.00586    |
|    std                  | 0.707      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 895        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 208        |
|    time_elapsed         | 118470     |
|    total_timesteps      | 425984     |
| train/                  |            |
|    approx_kl            | 0.86066747 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.35      |
|    explained_variance   | -0.00281   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.433      |
|    n_updates            | 2070       |
|    policy_gradient_loss | 0.0122     |
|    std                  | 0.707      |
|    value_loss           | 1.14       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 898       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 209       |
|    time_elapsed         | 118676    |
|    total_timesteps      | 428032    |
| train/                  |           |
|    approx_kl            | 0.0760508 |
|    clip_fraction        | 0.351     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.33     |
|    explained_variance   | 0.299     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.508     |
|    n_updates            | 2080      |
|    policy_gradient_loss | 0.0133    |
|    std                  | 0.703     |
|    value_loss           | 1.15      |
---------------------------------------
Eval num_timesteps=430000, episode_reward=-99.79 +/- 0.05
Episode length: 3597.20 +/- 6.65
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 430000      |
| train/                  |             |
|    approx_kl            | 0.049637724 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.31       |
|    explained_variance   | 0.105       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.467       |
|    n_updates            | 2090        |
|    policy_gradient_loss | 0.00418     |
|    std                  | 0.702       |
|    value_loss           | 1.04        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 894      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 210      |
|    time_elapsed    | 120684   |
|    total_timesteps | 430080   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 894         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 211         |
|    time_elapsed         | 120890      |
|    total_timesteps      | 432128      |
| train/                  |             |
|    approx_kl            | 0.054770295 |
|    clip_fraction        | 0.384       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.31       |
|    explained_variance   | -0.00161    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.52e+03    |
|    n_updates            | 2100        |
|    policy_gradient_loss | -0.00336    |
|    std                  | 0.702       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 904       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 212       |
|    time_elapsed         | 121095    |
|    total_timesteps      | 434176    |
| train/                  |           |
|    approx_kl            | 0.5484663 |
|    clip_fraction        | 0.394     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.28     |
|    explained_variance   | 0.000992  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.409     |
|    n_updates            | 2110      |
|    policy_gradient_loss | 0.02      |
|    std                  | 0.698     |
|    value_loss           | 1.19      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 904         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 213         |
|    time_elapsed         | 121301      |
|    total_timesteps      | 436224      |
| train/                  |             |
|    approx_kl            | 0.087563366 |
|    clip_fraction        | 0.365       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.27       |
|    explained_variance   | 0.359       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.487       |
|    n_updates            | 2120        |
|    policy_gradient_loss | 0.017       |
|    std                  | 0.7         |
|    value_loss           | 0.811       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 907         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 214         |
|    time_elapsed         | 121506      |
|    total_timesteps      | 438272      |
| train/                  |             |
|    approx_kl            | 0.057327785 |
|    clip_fraction        | 0.31        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.26       |
|    explained_variance   | 0.292       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.621       |
|    n_updates            | 2130        |
|    policy_gradient_loss | 0.0139      |
|    std                  | 0.697       |
|    value_loss           | 1.25        |
-----------------------------------------
Eval num_timesteps=440000, episode_reward=-99.86 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 440000      |
| train/                  |             |
|    approx_kl            | 0.039108664 |
|    clip_fraction        | 0.34        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.25       |
|    explained_variance   | 0.899       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.593       |
|    n_updates            | 2140        |
|    policy_gradient_loss | 0.00599     |
|    std                  | 0.698       |
|    value_loss           | 2.61        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 901      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 215      |
|    time_elapsed    | 123513   |
|    total_timesteps | 440320   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 901        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 216        |
|    time_elapsed         | 123718     |
|    total_timesteps      | 442368     |
| train/                  |            |
|    approx_kl            | 0.05539257 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.26      |
|    explained_variance   | -0.000214  |
|    learning_rate        | 0.0003     |
|    loss                 | 11.6       |
|    n_updates            | 2150       |
|    policy_gradient_loss | 0.00362    |
|    std                  | 0.699      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 911       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 217       |
|    time_elapsed         | 123923    |
|    total_timesteps      | 444416    |
| train/                  |           |
|    approx_kl            | 0.5501521 |
|    clip_fraction        | 0.41      |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.26     |
|    explained_variance   | 0.00394   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.63      |
|    n_updates            | 2160      |
|    policy_gradient_loss | 0.0207    |
|    std                  | 0.698     |
|    value_loss           | 1.39      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 911        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 218        |
|    time_elapsed         | 124129     |
|    total_timesteps      | 446464     |
| train/                  |            |
|    approx_kl            | 0.19586447 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.23      |
|    explained_variance   | 0.768      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.697      |
|    n_updates            | 2170       |
|    policy_gradient_loss | 0.00411    |
|    std                  | 0.694      |
|    value_loss           | 2.55       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 914         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 219         |
|    time_elapsed         | 124335      |
|    total_timesteps      | 448512      |
| train/                  |             |
|    approx_kl            | 0.036398403 |
|    clip_fraction        | 0.368       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.2        |
|    explained_variance   | 0.358       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.333       |
|    n_updates            | 2180        |
|    policy_gradient_loss | 0.0153      |
|    std                  | 0.693       |
|    value_loss           | 0.821       |
-----------------------------------------
Eval num_timesteps=450000, episode_reward=-99.84 +/- 0.03
Episode length: 3596.80 +/- 8.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 450000     |
| train/                  |            |
|    approx_kl            | 0.19761097 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.2       |
|    explained_variance   | 0.321      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.672      |
|    n_updates            | 2190       |
|    policy_gradient_loss | 0.0222     |
|    std                  | 0.695      |
|    value_loss           | 1.11       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 909      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 220      |
|    time_elapsed    | 126341   |
|    total_timesteps | 450560   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 909         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 221         |
|    time_elapsed         | 126546      |
|    total_timesteps      | 452608      |
| train/                  |             |
|    approx_kl            | 0.055101097 |
|    clip_fraction        | 0.413       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.21       |
|    explained_variance   | 3.04e-06    |
|    learning_rate        | 0.0003      |
|    loss                 | 30.2        |
|    n_updates            | 2200        |
|    policy_gradient_loss | 0.00809     |
|    std                  | 0.693       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 919        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 222        |
|    time_elapsed         | 126752     |
|    total_timesteps      | 454656     |
| train/                  |            |
|    approx_kl            | 0.21466246 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.19      |
|    explained_variance   | 0.00398    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.696      |
|    n_updates            | 2210       |
|    policy_gradient_loss | 0.0233     |
|    std                  | 0.69       |
|    value_loss           | 1.36       |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 919      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 223      |
|    time_elapsed         | 126957   |
|    total_timesteps      | 456704   |
| train/                  |          |
|    approx_kl            | 0.63442  |
|    clip_fraction        | 0.391    |
|    clip_range           | 0.2      |
|    entropy_loss         | -8.14    |
|    explained_variance   | 0.00657  |
|    learning_rate        | 0.0003   |
|    loss                 | 0.33     |
|    n_updates            | 2220     |
|    policy_gradient_loss | 0.0225   |
|    std                  | 0.687    |
|    value_loss           | 1.07     |
--------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 922         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 224         |
|    time_elapsed         | 127163      |
|    total_timesteps      | 458752      |
| train/                  |             |
|    approx_kl            | 0.049395304 |
|    clip_fraction        | 0.373       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.1        |
|    explained_variance   | 0.307       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.582       |
|    n_updates            | 2230        |
|    policy_gradient_loss | 0.0161      |
|    std                  | 0.683       |
|    value_loss           | 1.13        |
-----------------------------------------
Eval num_timesteps=460000, episode_reward=-99.88 +/- 0.01
Episode length: 3598.00 +/- 5.06
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 460000      |
| train/                  |             |
|    approx_kl            | 0.043137968 |
|    clip_fraction        | 0.317       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.05       |
|    explained_variance   | 0.332       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.483       |
|    n_updates            | 2240        |
|    policy_gradient_loss | 0.00683     |
|    std                  | 0.678       |
|    value_loss           | 0.936       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 917      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 225      |
|    time_elapsed    | 129169   |
|    total_timesteps | 460800   |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.33e+03 |
|    ep_rew_mean          | 917      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 226      |
|    time_elapsed         | 129374   |
|    total_timesteps      | 462848   |
| train/                  |          |
|    approx_kl            | 0.068886 |
|    clip_fraction        | 0.398    |
|    clip_range           | 0.2      |
|    entropy_loss         | -8.02    |
|    explained_variance   | 0.00229  |
|    learning_rate        | 0.0003   |
|    loss                 | 45.2     |
|    n_updates            | 2250     |
|    policy_gradient_loss | 0.00901  |
|    std                  | 0.678    |
|    value_loss           | 1.05e+03 |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 926        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 227        |
|    time_elapsed         | 129580     |
|    total_timesteps      | 464896     |
| train/                  |            |
|    approx_kl            | 0.32802606 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8         |
|    explained_variance   | 0.000891   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.366      |
|    n_updates            | 2260       |
|    policy_gradient_loss | 0.0117     |
|    std                  | 0.673      |
|    value_loss           | 1.34       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 926         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 228         |
|    time_elapsed         | 129785      |
|    total_timesteps      | 466944      |
| train/                  |             |
|    approx_kl            | 0.042169318 |
|    clip_fraction        | 0.33        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.95       |
|    explained_variance   | 0.237       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.795       |
|    n_updates            | 2270        |
|    policy_gradient_loss | 0.00653     |
|    std                  | 0.671       |
|    value_loss           | 1.35        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 929        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 229        |
|    time_elapsed         | 129991     |
|    total_timesteps      | 468992     |
| train/                  |            |
|    approx_kl            | 0.10896283 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.93      |
|    explained_variance   | 0.299      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.523      |
|    n_updates            | 2280       |
|    policy_gradient_loss | 0.0149     |
|    std                  | 0.668      |
|    value_loss           | 1.13       |
----------------------------------------
Eval num_timesteps=470000, episode_reward=-99.84 +/- 0.09
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 470000     |
| train/                  |            |
|    approx_kl            | 0.11426846 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.92      |
|    explained_variance   | 0.467      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.444      |
|    n_updates            | 2290       |
|    policy_gradient_loss | 0.00572    |
|    std                  | 0.668      |
|    value_loss           | 1.18       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 924      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 230      |
|    time_elapsed    | 131999   |
|    total_timesteps | 471040   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 924        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 231        |
|    time_elapsed         | 132204     |
|    total_timesteps      | 473088     |
| train/                  |            |
|    approx_kl            | 0.07858215 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.92      |
|    explained_variance   | 0.000175   |
|    learning_rate        | 0.0003     |
|    loss                 | 2.15e+03   |
|    n_updates            | 2300       |
|    policy_gradient_loss | 0.00107    |
|    std                  | 0.668      |
|    value_loss           | 1.06e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 934        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 232        |
|    time_elapsed         | 132411     |
|    total_timesteps      | 475136     |
| train/                  |            |
|    approx_kl            | 0.09301935 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.89      |
|    explained_variance   | -0.119     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.387      |
|    n_updates            | 2310       |
|    policy_gradient_loss | 0.0153     |
|    std                  | 0.664      |
|    value_loss           | 1.25       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 937        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 233        |
|    time_elapsed         | 132617     |
|    total_timesteps      | 477184     |
| train/                  |            |
|    approx_kl            | 0.12894192 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.85      |
|    explained_variance   | 0.293      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.553      |
|    n_updates            | 2320       |
|    policy_gradient_loss | 0.0137     |
|    std                  | 0.661      |
|    value_loss           | 1.09       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 937        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 234        |
|    time_elapsed         | 132822     |
|    total_timesteps      | 479232     |
| train/                  |            |
|    approx_kl            | 0.21377093 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.82      |
|    explained_variance   | 0.308      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.548      |
|    n_updates            | 2330       |
|    policy_gradient_loss | 0.0145     |
|    std                  | 0.66       |
|    value_loss           | 1.31       |
----------------------------------------
Eval num_timesteps=480000, episode_reward=-99.85 +/- 0.04
Episode length: 3599.80 +/- 1.47
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 480000     |
| train/                  |            |
|    approx_kl            | 0.12274683 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.8       |
|    explained_variance   | 0.258      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.66       |
|    n_updates            | 2340       |
|    policy_gradient_loss | 0.00639    |
|    std                  | 0.658      |
|    value_loss           | 1.29       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 931      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 235      |
|    time_elapsed    | 134828   |
|    total_timesteps | 481280   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 931         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 236         |
|    time_elapsed         | 135034      |
|    total_timesteps      | 483328      |
| train/                  |             |
|    approx_kl            | 0.050806127 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.8        |
|    explained_variance   | 0.000413    |
|    learning_rate        | 0.0003      |
|    loss                 | 5.08        |
|    n_updates            | 2350        |
|    policy_gradient_loss | 0.00243     |
|    std                  | 0.661       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 942       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 237       |
|    time_elapsed         | 135239    |
|    total_timesteps      | 485376    |
| train/                  |           |
|    approx_kl            | 1.5418646 |
|    clip_fraction        | 0.412     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.79     |
|    explained_variance   | 0.00519   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.636     |
|    n_updates            | 2360      |
|    policy_gradient_loss | 0.0186    |
|    std                  | 0.654     |
|    value_loss           | 1.44      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 947        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 238        |
|    time_elapsed         | 135445     |
|    total_timesteps      | 487424     |
| train/                  |            |
|    approx_kl            | 0.06388874 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.73      |
|    explained_variance   | 0.3        |
|    learning_rate        | 0.0003     |
|    loss                 | 0.538      |
|    n_updates            | 2370       |
|    policy_gradient_loss | 0.0179     |
|    std                  | 0.65       |
|    value_loss           | 0.944      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 947        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 239        |
|    time_elapsed         | 135650     |
|    total_timesteps      | 489472     |
| train/                  |            |
|    approx_kl            | 0.18847302 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.71      |
|    explained_variance   | 0.311      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.429      |
|    n_updates            | 2380       |
|    policy_gradient_loss | 0.0285     |
|    std                  | 0.653      |
|    value_loss           | 0.969      |
----------------------------------------
Eval num_timesteps=490000, episode_reward=-99.84 +/- 0.05
Episode length: 3597.40 +/- 7.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 490000     |
| train/                  |            |
|    approx_kl            | 0.33478594 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.71      |
|    explained_variance   | 0.28       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.396      |
|    n_updates            | 2390       |
|    policy_gradient_loss | 0.0274     |
|    std                  | 0.653      |
|    value_loss           | 1.02       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 943      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 240      |
|    time_elapsed    | 137656   |
|    total_timesteps | 491520   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 943        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 241        |
|    time_elapsed         | 137862     |
|    total_timesteps      | 493568     |
| train/                  |            |
|    approx_kl            | 0.10203853 |
|    clip_fraction        | 0.481      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.72      |
|    explained_variance   | 0.00082    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.33e+03   |
|    n_updates            | 2400       |
|    policy_gradient_loss | 0.0101     |
|    std                  | 0.653      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 954       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 242       |
|    time_elapsed         | 138067    |
|    total_timesteps      | 495616    |
| train/                  |           |
|    approx_kl            | 1.2316252 |
|    clip_fraction        | 0.44      |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.74     |
|    explained_variance   | 0.00201   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.406     |
|    n_updates            | 2410      |
|    policy_gradient_loss | 0.0195    |
|    std                  | 0.656     |
|    value_loss           | 1.26      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 958       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 243       |
|    time_elapsed         | 138272    |
|    total_timesteps      | 497664    |
| train/                  |           |
|    approx_kl            | 0.6122291 |
|    clip_fraction        | 0.4       |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.75     |
|    explained_variance   | 0.0184    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.435     |
|    n_updates            | 2420      |
|    policy_gradient_loss | 0.0105    |
|    std                  | 0.654     |
|    value_loss           | 0.935     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 958        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 244        |
|    time_elapsed         | 138478     |
|    total_timesteps      | 499712     |
| train/                  |            |
|    approx_kl            | 0.12965766 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.72      |
|    explained_variance   | 0.307      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.56       |
|    n_updates            | 2430       |
|    policy_gradient_loss | 0.0154     |
|    std                  | 0.651      |
|    value_loss           | 1.1        |
----------------------------------------
Eval num_timesteps=500000, episode_reward=-99.82 +/- 0.03
Episode length: 3597.60 +/- 5.43
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 500000     |
| train/                  |            |
|    approx_kl            | 0.26349187 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.69      |
|    explained_variance   | 0.367      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.353      |
|    n_updates            | 2440       |
|    policy_gradient_loss | 0.0173     |
|    std                  | 0.649      |
|    value_loss           | 0.75       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 954      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 245      |
|    time_elapsed    | 140487   |
|    total_timesteps | 501760   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 966        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 246        |
|    time_elapsed         | 140692     |
|    total_timesteps      | 503808     |
| train/                  |            |
|    approx_kl            | 0.09126225 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.67      |
|    explained_variance   | -0.000452  |
|    learning_rate        | 0.0003     |
|    loss                 | 501        |
|    n_updates            | 2450       |
|    policy_gradient_loss | 0.00533    |
|    std                  | 0.648      |
|    value_loss           | 1.05e+03   |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 966      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 247      |
|    time_elapsed         | 140898   |
|    total_timesteps      | 505856   |
| train/                  |          |
|    approx_kl            | 0.960086 |
|    clip_fraction        | 0.406    |
|    clip_range           | 0.2      |
|    entropy_loss         | -7.67    |
|    explained_variance   | -0.24    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.712    |
|    n_updates            | 2460     |
|    policy_gradient_loss | 0.0317   |
|    std                  | 0.648    |
|    value_loss           | 1.42     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 969       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 248       |
|    time_elapsed         | 141103    |
|    total_timesteps      | 507904    |
| train/                  |           |
|    approx_kl            | 0.3378269 |
|    clip_fraction        | 0.4       |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.65     |
|    explained_variance   | 0.000253  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.366     |
|    n_updates            | 2470      |
|    policy_gradient_loss | 0.0325    |
|    std                  | 0.646     |
|    value_loss           | 1.15      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 969         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 249         |
|    time_elapsed         | 141309      |
|    total_timesteps      | 509952      |
| train/                  |             |
|    approx_kl            | 0.079291925 |
|    clip_fraction        | 0.358       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.63       |
|    explained_variance   | 0.318       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.337       |
|    n_updates            | 2480        |
|    policy_gradient_loss | 0.0133      |
|    std                  | 0.646       |
|    value_loss           | 0.833       |
-----------------------------------------
Eval num_timesteps=510000, episode_reward=-99.77 +/- 0.09
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 510000      |
| train/                  |             |
|    approx_kl            | 0.053438738 |
|    clip_fraction        | 0.357       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.61       |
|    explained_variance   | 0.319       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.501       |
|    n_updates            | 2490        |
|    policy_gradient_loss | 0.0163      |
|    std                  | 0.644       |
|    value_loss           | 0.82        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 965      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 250      |
|    time_elapsed    | 143315   |
|    total_timesteps | 512000   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 976        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 251        |
|    time_elapsed         | 143521     |
|    total_timesteps      | 514048     |
| train/                  |            |
|    approx_kl            | 0.11852904 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.61      |
|    explained_variance   | -0.00306   |
|    learning_rate        | 0.0003     |
|    loss                 | 105        |
|    n_updates            | 2500       |
|    policy_gradient_loss | 0.00162    |
|    std                  | 0.647      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 976        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 252        |
|    time_elapsed         | 143727     |
|    total_timesteps      | 516096     |
| train/                  |            |
|    approx_kl            | 0.45657277 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.63      |
|    explained_variance   | -0.0185    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.532      |
|    n_updates            | 2510       |
|    policy_gradient_loss | 0.0191     |
|    std                  | 0.646      |
|    value_loss           | 1.29       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 980        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 253        |
|    time_elapsed         | 143932     |
|    total_timesteps      | 518144     |
| train/                  |            |
|    approx_kl            | 0.23798847 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.61      |
|    explained_variance   | 0.175      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.426      |
|    n_updates            | 2520       |
|    policy_gradient_loss | 0.017      |
|    std                  | 0.643      |
|    value_loss           | 0.753      |
----------------------------------------
Eval num_timesteps=520000, episode_reward=-99.83 +/- 0.05
Episode length: 3598.40 +/- 5.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 520000     |
| train/                  |            |
|    approx_kl            | 0.11829154 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.57      |
|    explained_variance   | 0.0422     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.356      |
|    n_updates            | 2530       |
|    policy_gradient_loss | 0.012      |
|    std                  | 0.639      |
|    value_loss           | 0.782      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 976      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 254      |
|    time_elapsed    | 145938   |
|    total_timesteps | 520192   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 976        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 255        |
|    time_elapsed         | 146144     |
|    total_timesteps      | 522240     |
| train/                  |            |
|    approx_kl            | 0.11379047 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.56      |
|    explained_variance   | -0.000916  |
|    learning_rate        | 0.0003     |
|    loss                 | 1.81e+03   |
|    n_updates            | 2540       |
|    policy_gradient_loss | 0.00427    |
|    std                  | 0.641      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 987       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 256       |
|    time_elapsed         | 146349    |
|    total_timesteps      | 524288    |
| train/                  |           |
|    approx_kl            | 2.6014318 |
|    clip_fraction        | 0.433     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.56     |
|    explained_variance   | 5.48e-06  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.777     |
|    n_updates            | 2550      |
|    policy_gradient_loss | 0.00536   |
|    std                  | 0.639     |
|    value_loss           | 1.18      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 987        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 257        |
|    time_elapsed         | 146554     |
|    total_timesteps      | 526336     |
| train/                  |            |
|    approx_kl            | 0.26194122 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.52      |
|    explained_variance   | 0.914      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.458      |
|    n_updates            | 2560       |
|    policy_gradient_loss | 0.00683    |
|    std                  | 0.635      |
|    value_loss           | 2.41       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 990        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 258        |
|    time_elapsed         | 146760     |
|    total_timesteps      | 528384     |
| train/                  |            |
|    approx_kl            | 0.06342277 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.51      |
|    explained_variance   | 0.396      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.451      |
|    n_updates            | 2570       |
|    policy_gradient_loss | 0.0253     |
|    std                  | 0.636      |
|    value_loss           | 0.843      |
----------------------------------------
Eval num_timesteps=530000, episode_reward=-99.79 +/- 0.05
Episode length: 3595.00 +/- 8.65
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 530000    |
| train/                  |           |
|    approx_kl            | 0.5772612 |
|    clip_fraction        | 0.379     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.52     |
|    explained_variance   | 0.326     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.69      |
|    n_updates            | 2580      |
|    policy_gradient_loss | 0.0237    |
|    std                  | 0.636     |
|    value_loss           | 1.06      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 986      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 259      |
|    time_elapsed    | 148769   |
|    total_timesteps | 530432   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 986         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 260         |
|    time_elapsed         | 148976      |
|    total_timesteps      | 532480      |
| train/                  |             |
|    approx_kl            | 0.061283663 |
|    clip_fraction        | 0.372       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.52       |
|    explained_variance   | -0.0028     |
|    learning_rate        | 0.0003      |
|    loss                 | 35          |
|    n_updates            | 2590        |
|    policy_gradient_loss | -0.000701   |
|    std                  | 0.636       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 997       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 261       |
|    time_elapsed         | 149181    |
|    total_timesteps      | 534528    |
| train/                  |           |
|    approx_kl            | 1.2436168 |
|    clip_fraction        | 0.396     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.49     |
|    explained_variance   | -0.00121  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.487     |
|    n_updates            | 2600      |
|    policy_gradient_loss | 0.00954   |
|    std                  | 0.632     |
|    value_loss           | 1.3       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 997       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 262       |
|    time_elapsed         | 149386    |
|    total_timesteps      | 536576    |
| train/                  |           |
|    approx_kl            | 0.1524558 |
|    clip_fraction        | 0.389     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.48     |
|    explained_variance   | 0.167     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.844     |
|    n_updates            | 2610      |
|    policy_gradient_loss | 0.0123    |
|    std                  | 0.633     |
|    value_loss           | 1.17      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1e+03       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 263         |
|    time_elapsed         | 149592      |
|    total_timesteps      | 538624      |
| train/                  |             |
|    approx_kl            | 0.097556576 |
|    clip_fraction        | 0.367       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.48       |
|    explained_variance   | 0.314       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.572       |
|    n_updates            | 2620        |
|    policy_gradient_loss | 0.0164      |
|    std                  | 0.632       |
|    value_loss           | 1.08        |
-----------------------------------------
Eval num_timesteps=540000, episode_reward=-99.80 +/- 0.07
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 540000     |
| train/                  |            |
|    approx_kl            | 0.10460359 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.47      |
|    explained_variance   | 0.899      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.989      |
|    n_updates            | 2630       |
|    policy_gradient_loss | 0.0172     |
|    std                  | 0.631      |
|    value_loss           | 2.43       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 996      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 264      |
|    time_elapsed    | 151598   |
|    total_timesteps | 540672   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 996        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 265        |
|    time_elapsed         | 151804     |
|    total_timesteps      | 542720     |
| train/                  |            |
|    approx_kl            | 0.05888313 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.45      |
|    explained_variance   | 0.000514   |
|    learning_rate        | 0.0003     |
|    loss                 | 4.19       |
|    n_updates            | 2640       |
|    policy_gradient_loss | 0.0114     |
|    std                  | 0.63       |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.01e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 266        |
|    time_elapsed         | 152010     |
|    total_timesteps      | 544768     |
| train/                  |            |
|    approx_kl            | 0.39540377 |
|    clip_fraction        | 0.448      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.46      |
|    explained_variance   | 0.0492     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.537      |
|    n_updates            | 2650       |
|    policy_gradient_loss | 0.024      |
|    std                  | 0.633      |
|    value_loss           | 1.18       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.01e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 267        |
|    time_elapsed         | 152215     |
|    total_timesteps      | 546816     |
| train/                  |            |
|    approx_kl            | 0.13760588 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.47      |
|    explained_variance   | 0.36       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.432      |
|    n_updates            | 2660       |
|    policy_gradient_loss | 0.0207     |
|    std                  | 0.63       |
|    value_loss           | 0.778      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.01e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 268        |
|    time_elapsed         | 152421     |
|    total_timesteps      | 548864     |
| train/                  |            |
|    approx_kl            | 0.06784462 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.45      |
|    explained_variance   | 0.337      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.439      |
|    n_updates            | 2670       |
|    policy_gradient_loss | 0.019      |
|    std                  | 0.629      |
|    value_loss           | 0.884      |
----------------------------------------
Eval num_timesteps=550000, episode_reward=-99.74 +/- 0.06
Episode length: 3596.00 +/- 10.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 550000     |
| train/                  |            |
|    approx_kl            | 0.15348823 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.43      |
|    explained_variance   | 0.188      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.353      |
|    n_updates            | 2680       |
|    policy_gradient_loss | 0.0166     |
|    std                  | 0.627      |
|    value_loss           | 1.2        |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.01e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 269      |
|    time_elapsed    | 154427   |
|    total_timesteps | 550912   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 1.01e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 270       |
|    time_elapsed         | 154633    |
|    total_timesteps      | 552960    |
| train/                  |           |
|    approx_kl            | 0.0530475 |
|    clip_fraction        | 0.403     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.42     |
|    explained_variance   | -0.000681 |
|    learning_rate        | 0.0003    |
|    loss                 | 14.1      |
|    n_updates            | 2690      |
|    policy_gradient_loss | 0.00545   |
|    std                  | 0.626     |
|    value_loss           | 1.04e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 271        |
|    time_elapsed         | 154838     |
|    total_timesteps      | 555008     |
| train/                  |            |
|    approx_kl            | 0.61612713 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.42      |
|    explained_variance   | 0.00156    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.55       |
|    n_updates            | 2700       |
|    policy_gradient_loss | 0.0167     |
|    std                  | 0.624      |
|    value_loss           | 1.35       |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 1.02e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 272      |
|    time_elapsed         | 155044   |
|    total_timesteps      | 557056   |
| train/                  |          |
|    approx_kl            | 0.163523 |
|    clip_fraction        | 0.397    |
|    clip_range           | 0.2      |
|    entropy_loss         | -7.38    |
|    explained_variance   | 0.297    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.642    |
|    n_updates            | 2710     |
|    policy_gradient_loss | 0.0314   |
|    std                  | 0.623    |
|    value_loss           | 1.24     |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 273        |
|    time_elapsed         | 155250     |
|    total_timesteps      | 559104     |
| train/                  |            |
|    approx_kl            | 0.46164435 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.38      |
|    explained_variance   | 0.33       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.526      |
|    n_updates            | 2720       |
|    policy_gradient_loss | 0.0233     |
|    std                  | 0.622      |
|    value_loss           | 0.998      |
----------------------------------------
Eval num_timesteps=560000, episode_reward=-99.87 +/- 0.02
Episode length: 3597.40 +/- 7.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 560000      |
| train/                  |             |
|    approx_kl            | 0.093031615 |
|    clip_fraction        | 0.355       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.36       |
|    explained_variance   | 0.886       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.01        |
|    n_updates            | 2730        |
|    policy_gradient_loss | -0.00361    |
|    std                  | 0.621       |
|    value_loss           | 6.69        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.01e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 274      |
|    time_elapsed    | 157256   |
|    total_timesteps | 561152   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.01e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 275        |
|    time_elapsed         | 157461     |
|    total_timesteps      | 563200     |
| train/                  |            |
|    approx_kl            | 0.06204784 |
|    clip_fraction        | 0.452      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.35      |
|    explained_variance   | 0.000965   |
|    learning_rate        | 0.0003     |
|    loss                 | 41.2       |
|    n_updates            | 2740       |
|    policy_gradient_loss | 0.0064     |
|    std                  | 0.621      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 276       |
|    time_elapsed         | 157666    |
|    total_timesteps      | 565248    |
| train/                  |           |
|    approx_kl            | 0.2986275 |
|    clip_fraction        | 0.43      |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.37     |
|    explained_variance   | 0.000678  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.673     |
|    n_updates            | 2750      |
|    policy_gradient_loss | 0.0191    |
|    std                  | 0.623     |
|    value_loss           | 1.24      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 277       |
|    time_elapsed         | 157872    |
|    total_timesteps      | 567296    |
| train/                  |           |
|    approx_kl            | 1.0704745 |
|    clip_fraction        | 0.4       |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.37     |
|    explained_variance   | 0.136     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.498     |
|    n_updates            | 2760      |
|    policy_gradient_loss | 5.52e-05  |
|    std                  | 0.622     |
|    value_loss           | 1.1       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 278        |
|    time_elapsed         | 158077     |
|    total_timesteps      | 569344     |
| train/                  |            |
|    approx_kl            | 0.06175577 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.37      |
|    explained_variance   | -0.248     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.438      |
|    n_updates            | 2770       |
|    policy_gradient_loss | 0.0153     |
|    std                  | 0.624      |
|    value_loss           | 1.27       |
----------------------------------------
Eval num_timesteps=570000, episode_reward=-99.87 +/- 0.02
Episode length: 3600.60 +/- 0.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 570000    |
| train/                  |           |
|    approx_kl            | 0.3575328 |
|    clip_fraction        | 0.381     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.36     |
|    explained_variance   | 0.414     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.315     |
|    n_updates            | 2780      |
|    policy_gradient_loss | 0.00625   |
|    std                  | 0.621     |
|    value_loss           | 0.653     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 279      |
|    time_elapsed    | 160083   |
|    total_timesteps | 571392   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 280        |
|    time_elapsed         | 160289     |
|    total_timesteps      | 573440     |
| train/                  |            |
|    approx_kl            | 0.08048853 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.35      |
|    explained_variance   | 0.0345     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.78e+03   |
|    n_updates            | 2790       |
|    policy_gradient_loss | 0.0014     |
|    std                  | 0.621      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.04e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 281       |
|    time_elapsed         | 160496    |
|    total_timesteps      | 575488    |
| train/                  |           |
|    approx_kl            | 2.1533005 |
|    clip_fraction        | 0.424     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.33     |
|    explained_variance   | 0.0884    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.472     |
|    n_updates            | 2800      |
|    policy_gradient_loss | 0.0187    |
|    std                  | 0.618     |
|    value_loss           | 0.927     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 282        |
|    time_elapsed         | 160701     |
|    total_timesteps      | 577536     |
| train/                  |            |
|    approx_kl            | 0.20591538 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.28      |
|    explained_variance   | 0.384      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.394      |
|    n_updates            | 2810       |
|    policy_gradient_loss | 0.0232     |
|    std                  | 0.614      |
|    value_loss           | 0.928      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 283        |
|    time_elapsed         | 160907     |
|    total_timesteps      | 579584     |
| train/                  |            |
|    approx_kl            | 0.37070814 |
|    clip_fraction        | 0.453      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.24      |
|    explained_variance   | 0.0549     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.366      |
|    n_updates            | 2820       |
|    policy_gradient_loss | 0.0182     |
|    std                  | 0.614      |
|    value_loss           | 0.91       |
----------------------------------------
Eval num_timesteps=580000, episode_reward=-99.83 +/- 0.06
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 580000     |
| train/                  |            |
|    approx_kl            | 0.61064804 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.23      |
|    explained_variance   | 0.353      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.327      |
|    n_updates            | 2830       |
|    policy_gradient_loss | 0.0244     |
|    std                  | 0.611      |
|    value_loss           | 0.69       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 284      |
|    time_elapsed    | 162913   |
|    total_timesteps | 581632   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 285         |
|    time_elapsed         | 163118      |
|    total_timesteps      | 583680      |
| train/                  |             |
|    approx_kl            | 0.035250816 |
|    clip_fraction        | 0.399       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.22       |
|    explained_variance   | -0.000389   |
|    learning_rate        | 0.0003      |
|    loss                 | 285         |
|    n_updates            | 2840        |
|    policy_gradient_loss | 0.00769     |
|    std                  | 0.612       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.05e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 286       |
|    time_elapsed         | 163324    |
|    total_timesteps      | 585728    |
| train/                  |           |
|    approx_kl            | 1.5222559 |
|    clip_fraction        | 0.436     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.21     |
|    explained_variance   | 0.0135    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.256     |
|    n_updates            | 2850      |
|    policy_gradient_loss | 0.0159    |
|    std                  | 0.609     |
|    value_loss           | 0.856     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 287        |
|    time_elapsed         | 163529     |
|    total_timesteps      | 587776     |
| train/                  |            |
|    approx_kl            | 0.48714155 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.17      |
|    explained_variance   | 0.345      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.52       |
|    n_updates            | 2860       |
|    policy_gradient_loss | 0.0236     |
|    std                  | 0.608      |
|    value_loss           | 0.902      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.05e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 288       |
|    time_elapsed         | 163735    |
|    total_timesteps      | 589824    |
| train/                  |           |
|    approx_kl            | 0.0728868 |
|    clip_fraction        | 0.342     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.16     |
|    explained_variance   | 0.38      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.371     |
|    n_updates            | 2870      |
|    policy_gradient_loss | 0.0231    |
|    std                  | 0.608     |
|    value_loss           | 0.81      |
---------------------------------------
Eval num_timesteps=590000, episode_reward=-99.83 +/- 0.04
Episode length: 3596.60 +/- 8.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 590000     |
| train/                  |            |
|    approx_kl            | 0.14637904 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.14      |
|    explained_variance   | 0.332      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.34       |
|    n_updates            | 2880       |
|    policy_gradient_loss | 0.0151     |
|    std                  | 0.605      |
|    value_loss           | 0.94       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 289      |
|    time_elapsed    | 165741   |
|    total_timesteps | 591872   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.06e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 290        |
|    time_elapsed         | 165946     |
|    total_timesteps      | 593920     |
| train/                  |            |
|    approx_kl            | 0.17253646 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.12      |
|    explained_variance   | 5.58e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 872        |
|    n_updates            | 2890       |
|    policy_gradient_loss | 0.00743    |
|    std                  | 0.605      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.06e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 291       |
|    time_elapsed         | 166151    |
|    total_timesteps      | 595968    |
| train/                  |           |
|    approx_kl            | 0.8789966 |
|    clip_fraction        | 0.41      |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.12     |
|    explained_variance   | 0.0158    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.531     |
|    n_updates            | 2900      |
|    policy_gradient_loss | 0.0154    |
|    std                  | 0.606     |
|    value_loss           | 0.992     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.07e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 292         |
|    time_elapsed         | 166357      |
|    total_timesteps      | 598016      |
| train/                  |             |
|    approx_kl            | 0.039691463 |
|    clip_fraction        | 0.382       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.12       |
|    explained_variance   | 0.242       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.516       |
|    n_updates            | 2910        |
|    policy_gradient_loss | 0.019       |
|    std                  | 0.603       |
|    value_loss           | 0.988       |
-----------------------------------------
Eval num_timesteps=600000, episode_reward=-99.86 +/- 0.05
Episode length: 3600.40 +/- 1.20
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 600000    |
| train/                  |           |
|    approx_kl            | 1.1144164 |
|    clip_fraction        | 0.376     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.1      |
|    explained_variance   | -0.0673   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.368     |
|    n_updates            | 2920      |
|    policy_gradient_loss | 0.0174    |
|    std                  | 0.603     |
|    value_loss           | 0.925     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.06e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 293      |
|    time_elapsed    | 168363   |
|    total_timesteps | 600064   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 294         |
|    time_elapsed         | 168568      |
|    total_timesteps      | 602112      |
| train/                  |             |
|    approx_kl            | 0.089283004 |
|    clip_fraction        | 0.46        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.12       |
|    explained_variance   | -0.000163   |
|    learning_rate        | 0.0003      |
|    loss                 | 44.8        |
|    n_updates            | 2930        |
|    policy_gradient_loss | 0.00979     |
|    std                  | 0.606       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.08e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 295       |
|    time_elapsed         | 168774    |
|    total_timesteps      | 604160    |
| train/                  |           |
|    approx_kl            | 1.6073871 |
|    clip_fraction        | 0.442     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.12     |
|    explained_variance   | 9.19e-05  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.494     |
|    n_updates            | 2940      |
|    policy_gradient_loss | 0.0499    |
|    std                  | 0.603     |
|    value_loss           | 1.25      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 1.08e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 296      |
|    time_elapsed         | 168979   |
|    total_timesteps      | 606208   |
| train/                  |          |
|    approx_kl            | 1.012632 |
|    clip_fraction        | 0.402    |
|    clip_range           | 0.2      |
|    entropy_loss         | -7.12    |
|    explained_variance   | 0.0205   |
|    learning_rate        | 0.0003   |
|    loss                 | 0.587    |
|    n_updates            | 2950     |
|    policy_gradient_loss | 0.014    |
|    std                  | 0.603    |
|    value_loss           | 1.13     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 1.08e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 297      |
|    time_elapsed         | 169185   |
|    total_timesteps      | 608256   |
| train/                  |          |
|    approx_kl            | 0.232853 |
|    clip_fraction        | 0.352    |
|    clip_range           | 0.2      |
|    entropy_loss         | -7.09    |
|    explained_variance   | 0.00258  |
|    learning_rate        | 0.0003   |
|    loss                 | 0.376    |
|    n_updates            | 2960     |
|    policy_gradient_loss | 0.0169   |
|    std                  | 0.599    |
|    value_loss           | 1.07     |
--------------------------------------
Eval num_timesteps=610000, episode_reward=-99.86 +/- 0.04
Episode length: 3595.80 +/- 9.91
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 610000     |
| train/                  |            |
|    approx_kl            | 0.45721292 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.07      |
|    explained_variance   | 0.289      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.3        |
|    n_updates            | 2970       |
|    policy_gradient_loss | 0.0192     |
|    std                  | 0.599      |
|    value_loss           | 0.911      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.08e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 298      |
|    time_elapsed    | 171191   |
|    total_timesteps | 610304   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.08e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 299        |
|    time_elapsed         | 171397     |
|    total_timesteps      | 612352     |
| train/                  |            |
|    approx_kl            | 0.06497228 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.07      |
|    explained_variance   | 0.0564     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.98e+03   |
|    n_updates            | 2980       |
|    policy_gradient_loss | -0.000778  |
|    std                  | 0.599      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.09e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 300        |
|    time_elapsed         | 171602     |
|    total_timesteps      | 614400     |
| train/                  |            |
|    approx_kl            | 0.84537673 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.06      |
|    explained_variance   | 5.07e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.889      |
|    n_updates            | 2990       |
|    policy_gradient_loss | 0.0206     |
|    std                  | 0.597      |
|    value_loss           | 1.45       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.09e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 301       |
|    time_elapsed         | 171810    |
|    total_timesteps      | 616448    |
| train/                  |           |
|    approx_kl            | 1.5950531 |
|    clip_fraction        | 0.365     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.07     |
|    explained_variance   | -0.597    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.442     |
|    n_updates            | 3000      |
|    policy_gradient_loss | 0.0127    |
|    std                  | 0.599     |
|    value_loss           | 1.34      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.09e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 302       |
|    time_elapsed         | 172015    |
|    total_timesteps      | 618496    |
| train/                  |           |
|    approx_kl            | 0.6011423 |
|    clip_fraction        | 0.374     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.05     |
|    explained_variance   | 0.295     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.569     |
|    n_updates            | 3010      |
|    policy_gradient_loss | 0.014     |
|    std                  | 0.595     |
|    value_loss           | 1.17      |
---------------------------------------
Eval num_timesteps=620000, episode_reward=-99.80 +/- 0.03
Episode length: 3598.40 +/- 5.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 620000     |
| train/                  |            |
|    approx_kl            | 0.08430868 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7         |
|    explained_variance   | 0.428      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.451      |
|    n_updates            | 3020       |
|    policy_gradient_loss | 0.0138     |
|    std                  | 0.592      |
|    value_loss           | 0.975      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.09e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 303      |
|    time_elapsed    | 174022   |
|    total_timesteps | 620544   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 1.09e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 304       |
|    time_elapsed         | 174227    |
|    total_timesteps      | 622592    |
| train/                  |           |
|    approx_kl            | 0.1828093 |
|    clip_fraction        | 0.485     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.99     |
|    explained_variance   | 0.00155   |
|    learning_rate        | 0.0003    |
|    loss                 | 10.7      |
|    n_updates            | 3030      |
|    policy_gradient_loss | 0.0124    |
|    std                  | 0.594     |
|    value_loss           | 1.05e+03  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.1e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 305       |
|    time_elapsed         | 174435    |
|    total_timesteps      | 624640    |
| train/                  |           |
|    approx_kl            | 1.8811979 |
|    clip_fraction        | 0.517     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.03     |
|    explained_variance   | 0.000841  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.752     |
|    n_updates            | 3040      |
|    policy_gradient_loss | 0.021     |
|    std                  | 0.596     |
|    value_loss           | 1.23      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.1e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 306       |
|    time_elapsed         | 174640    |
|    total_timesteps      | 626688    |
| train/                  |           |
|    approx_kl            | 1.8462259 |
|    clip_fraction        | 0.416     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.01     |
|    explained_variance   | 0.0426    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.935     |
|    n_updates            | 3050      |
|    policy_gradient_loss | 0.0278    |
|    std                  | 0.594     |
|    value_loss           | 1.38      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.1e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 307        |
|    time_elapsed         | 174846     |
|    total_timesteps      | 628736     |
| train/                  |            |
|    approx_kl            | 0.59070474 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.99      |
|    explained_variance   | 0.00106    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.539      |
|    n_updates            | 3060       |
|    policy_gradient_loss | 0.0144     |
|    std                  | 0.592      |
|    value_loss           | 1.11       |
----------------------------------------
Eval num_timesteps=630000, episode_reward=-99.81 +/- 0.04
Episode length: 3600.60 +/- 0.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 630000    |
| train/                  |           |
|    approx_kl            | 1.9535234 |
|    clip_fraction        | 0.398     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.96     |
|    explained_variance   | 0.000653  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.628     |
|    n_updates            | 3070      |
|    policy_gradient_loss | 0.00524   |
|    std                  | 0.591     |
|    value_loss           | 1.23      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.1e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 308      |
|    time_elapsed    | 176852   |
|    total_timesteps | 630784   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.1e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 309        |
|    time_elapsed         | 177057     |
|    total_timesteps      | 632832     |
| train/                  |            |
|    approx_kl            | 0.18867275 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.96      |
|    explained_variance   | 0.000152   |
|    learning_rate        | 0.0003     |
|    loss                 | 3.22       |
|    n_updates            | 3080       |
|    policy_gradient_loss | 0.00254    |
|    std                  | 0.592      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.11e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 310       |
|    time_elapsed         | 177263    |
|    total_timesteps      | 634880    |
| train/                  |           |
|    approx_kl            | 1.8513834 |
|    clip_fraction        | 0.41      |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.93     |
|    explained_variance   | -7.75e-06 |
|    learning_rate        | 0.0003    |
|    loss                 | 0.45      |
|    n_updates            | 3090      |
|    policy_gradient_loss | 0.0134    |
|    std                  | 0.587     |
|    value_loss           | 1.14      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 1.11e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 311      |
|    time_elapsed         | 177470   |
|    total_timesteps      | 636928   |
| train/                  |          |
|    approx_kl            | 4.383783 |
|    clip_fraction        | 0.433    |
|    clip_range           | 0.2      |
|    entropy_loss         | -6.89    |
|    explained_variance   | 0.213    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.692    |
|    n_updates            | 3100     |
|    policy_gradient_loss | 0.0183   |
|    std                  | 0.588    |
|    value_loss           | 1.11     |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.11e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 312        |
|    time_elapsed         | 177676     |
|    total_timesteps      | 638976     |
| train/                  |            |
|    approx_kl            | 0.39599204 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.91      |
|    explained_variance   | 0.00171    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.418      |
|    n_updates            | 3110       |
|    policy_gradient_loss | 0.0126     |
|    std                  | 0.588      |
|    value_loss           | 0.985      |
----------------------------------------
Eval num_timesteps=640000, episode_reward=-99.82 +/- 0.03
Episode length: 3600.20 +/- 1.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 640000     |
| train/                  |            |
|    approx_kl            | 0.12566586 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.9       |
|    explained_variance   | 0.922      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.822      |
|    n_updates            | 3120       |
|    policy_gradient_loss | -0.00522   |
|    std                  | 0.586      |
|    value_loss           | 3.96       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.11e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 313      |
|    time_elapsed    | 179682   |
|    total_timesteps | 641024   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.11e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 314        |
|    time_elapsed         | 179887     |
|    total_timesteps      | 643072     |
| train/                  |            |
|    approx_kl            | 0.14819309 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.89      |
|    explained_variance   | 0.000254   |
|    learning_rate        | 0.0003     |
|    loss                 | 7.89       |
|    n_updates            | 3130       |
|    policy_gradient_loss | 0.00469    |
|    std                  | 0.587      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.12e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 315       |
|    time_elapsed         | 180093    |
|    total_timesteps      | 645120    |
| train/                  |           |
|    approx_kl            | 1.6353433 |
|    clip_fraction        | 0.372     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.88     |
|    explained_variance   | -0.199    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.463     |
|    n_updates            | 3140      |
|    policy_gradient_loss | 0.0146    |
|    std                  | 0.583     |
|    value_loss           | 1.13      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.12e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 316        |
|    time_elapsed         | 180298     |
|    total_timesteps      | 647168     |
| train/                  |            |
|    approx_kl            | 0.37254387 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.84      |
|    explained_variance   | 0.354      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.47       |
|    n_updates            | 3150       |
|    policy_gradient_loss | 0.0306     |
|    std                  | 0.582      |
|    value_loss           | 0.846      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.12e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 317        |
|    time_elapsed         | 180504     |
|    total_timesteps      | 649216     |
| train/                  |            |
|    approx_kl            | 0.10855299 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.81      |
|    explained_variance   | 0.31       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.456      |
|    n_updates            | 3160       |
|    policy_gradient_loss | 0.0348     |
|    std                  | 0.579      |
|    value_loss           | 1.17       |
----------------------------------------
Eval num_timesteps=650000, episode_reward=-99.87 +/- 0.03
Episode length: 3597.60 +/- 6.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 650000     |
| train/                  |            |
|    approx_kl            | 0.22918233 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.78      |
|    explained_variance   | 0.371      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.637      |
|    n_updates            | 3170       |
|    policy_gradient_loss | 0.0218     |
|    std                  | 0.576      |
|    value_loss           | 0.921      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.12e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 318      |
|    time_elapsed    | 182510   |
|    total_timesteps | 651264   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.12e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 319        |
|    time_elapsed         | 182716     |
|    total_timesteps      | 653312     |
| train/                  |            |
|    approx_kl            | 0.27981752 |
|    clip_fraction        | 0.484      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.76      |
|    explained_variance   | 0.000447   |
|    learning_rate        | 0.0003     |
|    loss                 | 4.93       |
|    n_updates            | 3180       |
|    policy_gradient_loss | 0.0191     |
|    std                  | 0.575      |
|    value_loss           | 1.05e+03   |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 1.13e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 320      |
|    time_elapsed         | 182922   |
|    total_timesteps      | 655360   |
| train/                  |          |
|    approx_kl            | 3.181258 |
|    clip_fraction        | 0.398    |
|    clip_range           | 0.2      |
|    entropy_loss         | -6.71    |
|    explained_variance   | 0.00342  |
|    learning_rate        | 0.0003   |
|    loss                 | 0.661    |
|    n_updates            | 3190     |
|    policy_gradient_loss | 0.0054   |
|    std                  | 0.571    |
|    value_loss           | 1.47     |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.13e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 321        |
|    time_elapsed         | 183128     |
|    total_timesteps      | 657408     |
| train/                  |            |
|    approx_kl            | 0.10187055 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.68      |
|    explained_variance   | 0.367      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.443      |
|    n_updates            | 3200       |
|    policy_gradient_loss | 0.0149     |
|    std                  | 0.571      |
|    value_loss           | 1.04       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.13e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 322        |
|    time_elapsed         | 183333     |
|    total_timesteps      | 659456     |
| train/                  |            |
|    approx_kl            | 0.24262604 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.66      |
|    explained_variance   | 0.322      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.63       |
|    n_updates            | 3210       |
|    policy_gradient_loss | 0.0202     |
|    std                  | 0.569      |
|    value_loss           | 1.07       |
----------------------------------------
Eval num_timesteps=660000, episode_reward=-99.84 +/- 0.06
Episode length: 3597.20 +/- 6.65
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 660000     |
| train/                  |            |
|    approx_kl            | 0.27891234 |
|    clip_fraction        | 0.332      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.65      |
|    explained_variance   | 0.357      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.464      |
|    n_updates            | 3220       |
|    policy_gradient_loss | 0.0112     |
|    std                  | 0.57       |
|    value_loss           | 0.849      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.13e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 323      |
|    time_elapsed    | 185340   |
|    total_timesteps | 661504   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.13e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 324         |
|    time_elapsed         | 185546      |
|    total_timesteps      | 663552      |
| train/                  |             |
|    approx_kl            | 0.050472517 |
|    clip_fraction        | 0.362       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.67       |
|    explained_variance   | 0.00101     |
|    learning_rate        | 0.0003      |
|    loss                 | 123         |
|    n_updates            | 3230        |
|    policy_gradient_loss | 0.00146     |
|    std                  | 0.572       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.14e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 325       |
|    time_elapsed         | 185752    |
|    total_timesteps      | 665600    |
| train/                  |           |
|    approx_kl            | 2.4178817 |
|    clip_fraction        | 0.418     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.66     |
|    explained_variance   | 0.248     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.373     |
|    n_updates            | 3240      |
|    policy_gradient_loss | 0.0223    |
|    std                  | 0.57      |
|    value_loss           | 0.873     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.14e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 326        |
|    time_elapsed         | 185957     |
|    total_timesteps      | 667648     |
| train/                  |            |
|    approx_kl            | 0.21043746 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.61      |
|    explained_variance   | 0.346      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.536      |
|    n_updates            | 3250       |
|    policy_gradient_loss | 0.0369     |
|    std                  | 0.566      |
|    value_loss           | 0.914      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.14e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 327        |
|    time_elapsed         | 186162     |
|    total_timesteps      | 669696     |
| train/                  |            |
|    approx_kl            | 0.41490212 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.61      |
|    explained_variance   | 0.385      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.609      |
|    n_updates            | 3260       |
|    policy_gradient_loss | 0.0276     |
|    std                  | 0.57       |
|    value_loss           | 1.03       |
----------------------------------------
Eval num_timesteps=670000, episode_reward=-99.85 +/- 0.04
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 670000     |
| train/                  |            |
|    approx_kl            | 0.14976712 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.6       |
|    explained_variance   | 0.38       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.635      |
|    n_updates            | 3270       |
|    policy_gradient_loss | 0.0277     |
|    std                  | 0.567      |
|    value_loss           | 1.01       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.14e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 328      |
|    time_elapsed    | 188169   |
|    total_timesteps | 671744   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.15e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 329         |
|    time_elapsed         | 188374      |
|    total_timesteps      | 673792      |
| train/                  |             |
|    approx_kl            | 0.049952596 |
|    clip_fraction        | 0.385       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.58       |
|    explained_variance   | -0.00163    |
|    learning_rate        | 0.0003      |
|    loss                 | 6.08        |
|    n_updates            | 3280        |
|    policy_gradient_loss | 0.0021      |
|    std                  | 0.568       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.15e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 330        |
|    time_elapsed         | 188579     |
|    total_timesteps      | 675840     |
| train/                  |            |
|    approx_kl            | 0.20917253 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.58      |
|    explained_variance   | 0.000872   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.351      |
|    n_updates            | 3290       |
|    policy_gradient_loss | 0.0218     |
|    std                  | 0.567      |
|    value_loss           | 1.29       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.15e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 331        |
|    time_elapsed         | 188785     |
|    total_timesteps      | 677888     |
| train/                  |            |
|    approx_kl            | 0.52599674 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.58      |
|    explained_variance   | 0.333      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.457      |
|    n_updates            | 3300       |
|    policy_gradient_loss | 0.0318     |
|    std                  | 0.568      |
|    value_loss           | 1.12       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.15e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 332        |
|    time_elapsed         | 188990     |
|    total_timesteps      | 679936     |
| train/                  |            |
|    approx_kl            | 0.31353387 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.57      |
|    explained_variance   | 0.349      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.359      |
|    n_updates            | 3310       |
|    policy_gradient_loss | 0.036      |
|    std                  | 0.565      |
|    value_loss           | 0.815      |
----------------------------------------
Eval num_timesteps=680000, episode_reward=-99.85 +/- 0.04
Episode length: 3597.20 +/- 6.21
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 680000    |
| train/                  |           |
|    approx_kl            | 0.7891768 |
|    clip_fraction        | 0.382     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.55     |
|    explained_variance   | 0.425     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.397     |
|    n_updates            | 3320      |
|    policy_gradient_loss | 0.0316    |
|    std                  | 0.564     |
|    value_loss           | 0.741     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.15e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 333      |
|    time_elapsed    | 190996   |
|    total_timesteps | 681984   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.16e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 334        |
|    time_elapsed         | 191202     |
|    total_timesteps      | 684032     |
| train/                  |            |
|    approx_kl            | 0.07624538 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.55      |
|    explained_variance   | 0.000468   |
|    learning_rate        | 0.0003     |
|    loss                 | 126        |
|    n_updates            | 3330       |
|    policy_gradient_loss | 0.00605    |
|    std                  | 0.566      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.16e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 335        |
|    time_elapsed         | 191407     |
|    total_timesteps      | 686080     |
| train/                  |            |
|    approx_kl            | 0.47674403 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.55      |
|    explained_variance   | -0.00254   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.695      |
|    n_updates            | 3340       |
|    policy_gradient_loss | 0.0115     |
|    std                  | 0.563      |
|    value_loss           | 1.43       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.17e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 336       |
|    time_elapsed         | 191612    |
|    total_timesteps      | 688128    |
| train/                  |           |
|    approx_kl            | 0.3943526 |
|    clip_fraction        | 0.395     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.49     |
|    explained_variance   | 0.000422  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.613     |
|    n_updates            | 3350      |
|    policy_gradient_loss | 0.0214    |
|    std                  | 0.559     |
|    value_loss           | 1.33      |
---------------------------------------
Eval num_timesteps=690000, episode_reward=-99.83 +/- 0.04
Episode length: 3599.80 +/- 2.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 690000    |
| train/                  |           |
|    approx_kl            | 3.0945332 |
|    clip_fraction        | 0.434     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.45     |
|    explained_variance   | 0.0722    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.684     |
|    n_updates            | 3360      |
|    policy_gradient_loss | 0.0463    |
|    std                  | 0.557     |
|    value_loss           | 1.35      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.16e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 337      |
|    time_elapsed    | 193619   |
|    total_timesteps | 690176   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.16e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 338         |
|    time_elapsed         | 193825      |
|    total_timesteps      | 692224      |
| train/                  |             |
|    approx_kl            | 0.071615726 |
|    clip_fraction        | 0.427       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.42       |
|    explained_variance   | -7.52e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 5.03        |
|    n_updates            | 3370        |
|    policy_gradient_loss | 0.00415     |
|    std                  | 0.556       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.17e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 339        |
|    time_elapsed         | 194031     |
|    total_timesteps      | 694272     |
| train/                  |            |
|    approx_kl            | 0.71762013 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.36      |
|    explained_variance   | 7.3e-05    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.498      |
|    n_updates            | 3380       |
|    policy_gradient_loss | 0.0146     |
|    std                  | 0.55       |
|    value_loss           | 1.15       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.17e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 340        |
|    time_elapsed         | 194236     |
|    total_timesteps      | 696320     |
| train/                  |            |
|    approx_kl            | 0.58078283 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.31      |
|    explained_variance   | 0.346      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.564      |
|    n_updates            | 3390       |
|    policy_gradient_loss | 0.0371     |
|    std                  | 0.549      |
|    value_loss           | 1.23       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.18e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 341        |
|    time_elapsed         | 194441     |
|    total_timesteps      | 698368     |
| train/                  |            |
|    approx_kl            | 0.50377256 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.3       |
|    explained_variance   | 0.39       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.418      |
|    n_updates            | 3400       |
|    policy_gradient_loss | 0.0293     |
|    std                  | 0.548      |
|    value_loss           | 0.901      |
----------------------------------------
Eval num_timesteps=700000, episode_reward=-99.83 +/- 0.03
Episode length: 3600.40 +/- 1.20
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 700000    |
| train/                  |           |
|    approx_kl            | 0.7497078 |
|    clip_fraction        | 0.339     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.27     |
|    explained_variance   | 0.389     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.564     |
|    n_updates            | 3410      |
|    policy_gradient_loss | 0.0367    |
|    std                  | 0.545     |
|    value_loss           | 0.832     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.17e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 342      |
|    time_elapsed    | 196448   |
|    total_timesteps | 700416   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.17e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 343        |
|    time_elapsed         | 196653     |
|    total_timesteps      | 702464     |
| train/                  |            |
|    approx_kl            | 0.08293245 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.25      |
|    explained_variance   | 0.000264   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.23e+03   |
|    n_updates            | 3420       |
|    policy_gradient_loss | 0.00847    |
|    std                  | 0.545      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.18e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 344       |
|    time_elapsed         | 196858    |
|    total_timesteps      | 704512    |
| train/                  |           |
|    approx_kl            | 4.2751637 |
|    clip_fraction        | 0.391     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.24     |
|    explained_variance   | 0.000296  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.423     |
|    n_updates            | 3430      |
|    policy_gradient_loss | 0.0168    |
|    std                  | 0.544     |
|    value_loss           | 1.12      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.18e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 345        |
|    time_elapsed         | 197064     |
|    total_timesteps      | 706560     |
| train/                  |            |
|    approx_kl            | 0.31334537 |
|    clip_fraction        | 0.296      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.21      |
|    explained_variance   | -0.615     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.959      |
|    n_updates            | 3440       |
|    policy_gradient_loss | 0.0168     |
|    std                  | 0.543      |
|    value_loss           | 1.45       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.19e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 346       |
|    time_elapsed         | 197269    |
|    total_timesteps      | 708608    |
| train/                  |           |
|    approx_kl            | 0.9132343 |
|    clip_fraction        | 0.363     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.18     |
|    explained_variance   | 0.369     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.463     |
|    n_updates            | 3450      |
|    policy_gradient_loss | 0.02      |
|    std                  | 0.541     |
|    value_loss           | 0.957     |
---------------------------------------
Eval num_timesteps=710000, episode_reward=-99.86 +/- 0.02
Episode length: 3597.60 +/- 6.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 710000     |
| train/                  |            |
|    approx_kl            | 0.17934042 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.14      |
|    explained_variance   | 0.597      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.565      |
|    n_updates            | 3460       |
|    policy_gradient_loss | 0.0193     |
|    std                  | 0.541      |
|    value_loss           | 1.79       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.18e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 347      |
|    time_elapsed    | 199275   |
|    total_timesteps | 710656   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.18e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 348         |
|    time_elapsed         | 199481      |
|    total_timesteps      | 712704      |
| train/                  |             |
|    approx_kl            | 0.095610715 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.14       |
|    explained_variance   | 0.000522    |
|    learning_rate        | 0.0003      |
|    loss                 | 3.43        |
|    n_updates            | 3470        |
|    policy_gradient_loss | 0.00379     |
|    std                  | 0.541       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.19e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 349       |
|    time_elapsed         | 199688    |
|    total_timesteps      | 714752    |
| train/                  |           |
|    approx_kl            | 0.8511309 |
|    clip_fraction        | 0.339     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.14     |
|    explained_variance   | 0.383     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.362     |
|    n_updates            | 3480      |
|    policy_gradient_loss | 0.0225    |
|    std                  | 0.542     |
|    value_loss           | 0.784     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.19e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 350        |
|    time_elapsed         | 199893     |
|    total_timesteps      | 716800     |
| train/                  |            |
|    approx_kl            | 0.23001955 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.11      |
|    explained_variance   | 0.403      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.535      |
|    n_updates            | 3490       |
|    policy_gradient_loss | 0.02       |
|    std                  | 0.538      |
|    value_loss           | 0.862      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.2e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 351        |
|    time_elapsed         | 200101     |
|    total_timesteps      | 718848     |
| train/                  |            |
|    approx_kl            | 0.13884297 |
|    clip_fraction        | 0.351      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.06      |
|    explained_variance   | 0.376      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.736      |
|    n_updates            | 3500       |
|    policy_gradient_loss | 0.0423     |
|    std                  | 0.535      |
|    value_loss           | 0.946      |
----------------------------------------
Eval num_timesteps=720000, episode_reward=-99.83 +/- 0.02
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 720000    |
| train/                  |           |
|    approx_kl            | 0.9007417 |
|    clip_fraction        | 0.381     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.02     |
|    explained_variance   | 0.464     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.303     |
|    n_updates            | 3510      |
|    policy_gradient_loss | 0.0393    |
|    std                  | 0.531     |
|    value_loss           | 0.772     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.2e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 352      |
|    time_elapsed    | 202112   |
|    total_timesteps | 720896   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.2e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 353        |
|    time_elapsed         | 202317     |
|    total_timesteps      | 722944     |
| train/                  |            |
|    approx_kl            | 0.16264546 |
|    clip_fraction        | 0.505      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.01      |
|    explained_variance   | -0.000773  |
|    learning_rate        | 0.0003     |
|    loss                 | 55.6       |
|    n_updates            | 3520       |
|    policy_gradient_loss | 0.0136     |
|    std                  | 0.534      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.21e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 354       |
|    time_elapsed         | 202523    |
|    total_timesteps      | 724992    |
| train/                  |           |
|    approx_kl            | 0.5394943 |
|    clip_fraction        | 0.369     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.02     |
|    explained_variance   | 0.000812  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.417     |
|    n_updates            | 3530      |
|    policy_gradient_loss | 0.0154    |
|    std                  | 0.532     |
|    value_loss           | 0.85      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.21e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 355       |
|    time_elapsed         | 202729    |
|    total_timesteps      | 727040    |
| train/                  |           |
|    approx_kl            | 0.5054852 |
|    clip_fraction        | 0.33      |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.01     |
|    explained_variance   | -0.0709   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.667     |
|    n_updates            | 3540      |
|    policy_gradient_loss | 0.0188    |
|    std                  | 0.533     |
|    value_loss           | 1.35      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.21e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 356       |
|    time_elapsed         | 202934    |
|    total_timesteps      | 729088    |
| train/                  |           |
|    approx_kl            | 1.3077648 |
|    clip_fraction        | 0.363     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.01     |
|    explained_variance   | 0.416     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.385     |
|    n_updates            | 3550      |
|    policy_gradient_loss | 0.0637    |
|    std                  | 0.533     |
|    value_loss           | 0.89      |
---------------------------------------
Eval num_timesteps=730000, episode_reward=-99.84 +/- 0.04
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 730000     |
| train/                  |            |
|    approx_kl            | 0.27986786 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.99      |
|    explained_variance   | 0.194      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.585      |
|    n_updates            | 3560       |
|    policy_gradient_loss | 0.0262     |
|    std                  | 0.533      |
|    value_loss           | 1.23       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.21e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 357      |
|    time_elapsed    | 204940   |
|    total_timesteps | 731136   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.21e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 358        |
|    time_elapsed         | 205146     |
|    total_timesteps      | 733184     |
| train/                  |            |
|    approx_kl            | 0.18115449 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6         |
|    explained_variance   | -0.000474  |
|    learning_rate        | 0.0003     |
|    loss                 | 167        |
|    n_updates            | 3570       |
|    policy_gradient_loss | 0.0085     |
|    std                  | 0.536      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.22e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 359       |
|    time_elapsed         | 205351    |
|    total_timesteps      | 735232    |
| train/                  |           |
|    approx_kl            | 3.2659812 |
|    clip_fraction        | 0.486     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.02     |
|    explained_variance   | 0.000219  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.49      |
|    n_updates            | 3580      |
|    policy_gradient_loss | 0.0214    |
|    std                  | 0.535     |
|    value_loss           | 1.06      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.23e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 360        |
|    time_elapsed         | 205556     |
|    total_timesteps      | 737280     |
| train/                  |            |
|    approx_kl            | 0.37627864 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.01      |
|    explained_variance   | 0.401      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.337      |
|    n_updates            | 3590       |
|    policy_gradient_loss | 0.0289     |
|    std                  | 0.535      |
|    value_loss           | 0.787      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.23e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 361        |
|    time_elapsed         | 205762     |
|    total_timesteps      | 739328     |
| train/                  |            |
|    approx_kl            | 0.58268106 |
|    clip_fraction        | 0.346      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.01      |
|    explained_variance   | 0.325      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.583      |
|    n_updates            | 3600       |
|    policy_gradient_loss | 0.0231     |
|    std                  | 0.536      |
|    value_loss           | 0.982      |
----------------------------------------
Eval num_timesteps=740000, episode_reward=-99.83 +/- 0.06
Episode length: 3596.80 +/- 8.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 740000    |
| train/                  |           |
|    approx_kl            | 0.0441148 |
|    clip_fraction        | 0.299     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6        |
|    explained_variance   | 0.462     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.34      |
|    n_updates            | 3610      |
|    policy_gradient_loss | 0.00931   |
|    std                  | 0.533     |
|    value_loss           | 0.747     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.22e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 362      |
|    time_elapsed    | 207768   |
|    total_timesteps | 741376   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.22e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 363        |
|    time_elapsed         | 207973     |
|    total_timesteps      | 743424     |
| train/                  |            |
|    approx_kl            | 0.10516251 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.99      |
|    explained_variance   | -0.000396  |
|    learning_rate        | 0.0003     |
|    loss                 | 1.95e+03   |
|    n_updates            | 3620       |
|    policy_gradient_loss | 0.0227     |
|    std                  | 0.535      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.24e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 364       |
|    time_elapsed         | 208179    |
|    total_timesteps      | 745472    |
| train/                  |           |
|    approx_kl            | 0.9516474 |
|    clip_fraction        | 0.42      |
|    clip_range           | 0.2       |
|    entropy_loss         | -6        |
|    explained_variance   | 0.000101  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.637     |
|    n_updates            | 3630      |
|    policy_gradient_loss | 0.0128    |
|    std                  | 0.535     |
|    value_loss           | 1.39      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.24e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 365        |
|    time_elapsed         | 208384     |
|    total_timesteps      | 747520     |
| train/                  |            |
|    approx_kl            | 0.15936103 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.97      |
|    explained_variance   | 0.00155    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.328      |
|    n_updates            | 3640       |
|    policy_gradient_loss | 0.033      |
|    std                  | 0.532      |
|    value_loss           | 1.42       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.24e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 366        |
|    time_elapsed         | 208590     |
|    total_timesteps      | 749568     |
| train/                  |            |
|    approx_kl            | 0.06998635 |
|    clip_fraction        | 0.292      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.92      |
|    explained_variance   | 0.312      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.467      |
|    n_updates            | 3650       |
|    policy_gradient_loss | 0.00591    |
|    std                  | 0.529      |
|    value_loss           | 0.989      |
----------------------------------------
Eval num_timesteps=750000, episode_reward=-99.87 +/- 0.04
Episode length: 3598.60 +/- 4.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 750000     |
| train/                  |            |
|    approx_kl            | 0.07302618 |
|    clip_fraction        | 0.321      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.91      |
|    explained_variance   | 0.452      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.38       |
|    n_updates            | 3660       |
|    policy_gradient_loss | 0.182      |
|    std                  | 0.531      |
|    value_loss           | 0.713      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.24e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 367      |
|    time_elapsed    | 210597   |
|    total_timesteps | 751616   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.25e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 368        |
|    time_elapsed         | 210802     |
|    total_timesteps      | 753664     |
| train/                  |            |
|    approx_kl            | 0.18144706 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.94      |
|    explained_variance   | 0.00161    |
|    learning_rate        | 0.0003     |
|    loss                 | 43.7       |
|    n_updates            | 3670       |
|    policy_gradient_loss | 0.016      |
|    std                  | 0.533      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.25e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 369       |
|    time_elapsed         | 211008    |
|    total_timesteps      | 755712    |
| train/                  |           |
|    approx_kl            | 2.0679836 |
|    clip_fraction        | 0.405     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.94     |
|    explained_variance   | 0.00176   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.31      |
|    n_updates            | 3680      |
|    policy_gradient_loss | 0.0102    |
|    std                  | 0.53      |
|    value_loss           | 0.907     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.26e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 370        |
|    time_elapsed         | 211213     |
|    total_timesteps      | 757760     |
| train/                  |            |
|    approx_kl            | 0.09571554 |
|    clip_fraction        | 0.322      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.91      |
|    explained_variance   | 0.368      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.558      |
|    n_updates            | 3690       |
|    policy_gradient_loss | 0.0141     |
|    std                  | 0.528      |
|    value_loss           | 1.02       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.26e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 371       |
|    time_elapsed         | 211419    |
|    total_timesteps      | 759808    |
| train/                  |           |
|    approx_kl            | 2.0356553 |
|    clip_fraction        | 0.393     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.86     |
|    explained_variance   | 0.408     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.41      |
|    n_updates            | 3700      |
|    policy_gradient_loss | 0.0232    |
|    std                  | 0.524     |
|    value_loss           | 0.756     |
---------------------------------------
Eval num_timesteps=760000, episode_reward=-99.81 +/- 0.06
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 760000    |
| train/                  |           |
|    approx_kl            | 0.5846987 |
|    clip_fraction        | 0.402     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.81     |
|    explained_variance   | 0.495     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.437     |
|    n_updates            | 3710      |
|    policy_gradient_loss | 0.0274    |
|    std                  | 0.522     |
|    value_loss           | 0.687     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.25e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 372      |
|    time_elapsed    | 213425   |
|    total_timesteps | 761856   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.26e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 373        |
|    time_elapsed         | 213630     |
|    total_timesteps      | 763904     |
| train/                  |            |
|    approx_kl            | 0.33828706 |
|    clip_fraction        | 0.309      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.79      |
|    explained_variance   | 0.0293     |
|    learning_rate        | 0.0003     |
|    loss                 | 9.91       |
|    n_updates            | 3720       |
|    policy_gradient_loss | 0.00612    |
|    std                  | 0.522      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.26e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 374        |
|    time_elapsed         | 213836     |
|    total_timesteps      | 765952     |
| train/                  |            |
|    approx_kl            | 0.89441705 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.79      |
|    explained_variance   | 0.00428    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.398      |
|    n_updates            | 3730       |
|    policy_gradient_loss | 0.0143     |
|    std                  | 0.522      |
|    value_loss           | 1.15       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.27e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 375       |
|    time_elapsed         | 214044    |
|    total_timesteps      | 768000    |
| train/                  |           |
|    approx_kl            | 0.6685019 |
|    clip_fraction        | 0.408     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.74     |
|    explained_variance   | 0.414     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.316     |
|    n_updates            | 3740      |
|    policy_gradient_loss | 0.0389    |
|    std                  | 0.518     |
|    value_loss           | 0.765     |
---------------------------------------
Eval num_timesteps=770000, episode_reward=-99.82 +/- 0.05
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 770000     |
| train/                  |            |
|    approx_kl            | 0.53317785 |
|    clip_fraction        | 0.456      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.71      |
|    explained_variance   | 0.462      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.357      |
|    n_updates            | 3750       |
|    policy_gradient_loss | 0.0458     |
|    std                  | 0.519      |
|    value_loss           | 0.762      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.26e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 376      |
|    time_elapsed    | 216050   |
|    total_timesteps | 770048   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.26e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 377        |
|    time_elapsed         | 216258     |
|    total_timesteps      | 772096     |
| train/                  |            |
|    approx_kl            | 0.69369596 |
|    clip_fraction        | 0.442      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.72      |
|    explained_variance   | 0.000276   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.52e+03   |
|    n_updates            | 3760       |
|    policy_gradient_loss | 0.0184     |
|    std                  | 0.519      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.27e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 378       |
|    time_elapsed         | 216463    |
|    total_timesteps      | 774144    |
| train/                  |           |
|    approx_kl            | 4.9053025 |
|    clip_fraction        | 0.405     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.72     |
|    explained_variance   | 0.00276   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.35      |
|    n_updates            | 3770      |
|    policy_gradient_loss | 0.0184    |
|    std                  | 0.518     |
|    value_loss           | 0.8       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.27e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 379        |
|    time_elapsed         | 216668     |
|    total_timesteps      | 776192     |
| train/                  |            |
|    approx_kl            | 0.22708207 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.72      |
|    explained_variance   | 0.435      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.339      |
|    n_updates            | 3780       |
|    policy_gradient_loss | 0.0247     |
|    std                  | 0.517      |
|    value_loss           | 0.808      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.28e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 380        |
|    time_elapsed         | 216874     |
|    total_timesteps      | 778240     |
| train/                  |            |
|    approx_kl            | 0.56163067 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.68      |
|    explained_variance   | 0.449      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.41       |
|    n_updates            | 3790       |
|    policy_gradient_loss | 0.0368     |
|    std                  | 0.513      |
|    value_loss           | 0.784      |
----------------------------------------
Eval num_timesteps=780000, episode_reward=-99.78 +/- 0.08
Episode length: 3600.60 +/- 0.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 780000    |
| train/                  |           |
|    approx_kl            | 0.3124619 |
|    clip_fraction        | 0.39      |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.64     |
|    explained_variance   | 0.399     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.333     |
|    n_updates            | 3800      |
|    policy_gradient_loss | 0.0222    |
|    std                  | 0.511     |
|    value_loss           | 0.831     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.27e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 381      |
|    time_elapsed    | 218881   |
|    total_timesteps | 780288   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.27e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 382        |
|    time_elapsed         | 219086     |
|    total_timesteps      | 782336     |
| train/                  |            |
|    approx_kl            | 0.17043698 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.64      |
|    explained_variance   | 0.00138    |
|    learning_rate        | 0.0003     |
|    loss                 | 91.8       |
|    n_updates            | 3810       |
|    policy_gradient_loss | 0.0112     |
|    std                  | 0.514      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.29e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 383       |
|    time_elapsed         | 219292    |
|    total_timesteps      | 784384    |
| train/                  |           |
|    approx_kl            | 1.8407753 |
|    clip_fraction        | 0.431     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.65     |
|    explained_variance   | 0.00922   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.263     |
|    n_updates            | 3820      |
|    policy_gradient_loss | 0.0103    |
|    std                  | 0.513     |
|    value_loss           | 0.937     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.29e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 384        |
|    time_elapsed         | 219498     |
|    total_timesteps      | 786432     |
| train/                  |            |
|    approx_kl            | 0.91744184 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.64      |
|    explained_variance   | 0.941      |
|    learning_rate        | 0.0003     |
|    loss                 | 3.16       |
|    n_updates            | 3830       |
|    policy_gradient_loss | 0.0144     |
|    std                  | 0.514      |
|    value_loss           | 7.03       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.29e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 385        |
|    time_elapsed         | 219704     |
|    total_timesteps      | 788480     |
| train/                  |            |
|    approx_kl            | 0.41244373 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.65      |
|    explained_variance   | 0.457      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.378      |
|    n_updates            | 3840       |
|    policy_gradient_loss | 0.028      |
|    std                  | 0.513      |
|    value_loss           | 0.691      |
----------------------------------------
Eval num_timesteps=790000, episode_reward=-99.84 +/- 0.05
Episode length: 3598.20 +/- 5.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 790000     |
| train/                  |            |
|    approx_kl            | 0.11637192 |
|    clip_fraction        | 0.288      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.65      |
|    explained_variance   | 0.949      |
|    learning_rate        | 0.0003     |
|    loss                 | 4.06       |
|    n_updates            | 3850       |
|    policy_gradient_loss | 0.00852    |
|    std                  | 0.512      |
|    value_loss           | 12.9       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.28e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 386      |
|    time_elapsed    | 221711   |
|    total_timesteps | 790528   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 1.28e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 387       |
|    time_elapsed         | 221918    |
|    total_timesteps      | 792576    |
| train/                  |           |
|    approx_kl            | 0.9115413 |
|    clip_fraction        | 0.363     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.65     |
|    explained_variance   | -0.000174 |
|    learning_rate        | 0.0003    |
|    loss                 | 63.7      |
|    n_updates            | 3860      |
|    policy_gradient_loss | 0.00962   |
|    std                  | 0.513     |
|    value_loss           | 1.04e+03  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.29e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 388       |
|    time_elapsed         | 222124    |
|    total_timesteps      | 794624    |
| train/                  |           |
|    approx_kl            | 3.7305205 |
|    clip_fraction        | 0.503     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.65     |
|    explained_variance   | -0.00732  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.243     |
|    n_updates            | 3870      |
|    policy_gradient_loss | 0.0312    |
|    std                  | 0.51      |
|    value_loss           | 0.876     |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.29e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 389       |
|    time_elapsed         | 222329    |
|    total_timesteps      | 796672    |
| train/                  |           |
|    approx_kl            | 1.4910574 |
|    clip_fraction        | 0.482     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.62     |
|    explained_variance   | 0.991     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.713     |
|    n_updates            | 3880      |
|    policy_gradient_loss | 0.041     |
|    std                  | 0.509     |
|    value_loss           | 1.39      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.29e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 390       |
|    time_elapsed         | 222535    |
|    total_timesteps      | 798720    |
| train/                  |           |
|    approx_kl            | 3.2498322 |
|    clip_fraction        | 0.465     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.6      |
|    explained_variance   | 0.926     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.531     |
|    n_updates            | 3890      |
|    policy_gradient_loss | 0.0121    |
|    std                  | 0.509     |
|    value_loss           | 4.39      |
---------------------------------------
Eval num_timesteps=800000, episode_reward=-99.85 +/- 0.03
Episode length: 3600.60 +/- 0.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 800000    |
| train/                  |           |
|    approx_kl            | 1.1873761 |
|    clip_fraction        | 0.45      |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.6      |
|    explained_variance   | 0.371     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.4       |
|    n_updates            | 3900      |
|    policy_gradient_loss | 0.0335    |
|    std                  | 0.509     |
|    value_loss           | 0.708     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.28e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 391      |
|    time_elapsed    | 224541   |
|    total_timesteps | 800768   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 1.28e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 392       |
|    time_elapsed         | 224746    |
|    total_timesteps      | 802816    |
| train/                  |           |
|    approx_kl            | 0.2633519 |
|    clip_fraction        | 0.366     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.61     |
|    explained_variance   | 1.29e-05  |
|    learning_rate        | 0.0003    |
|    loss                 | 5.68      |
|    n_updates            | 3910      |
|    policy_gradient_loss | 0.00931   |
|    std                  | 0.51      |
|    value_loss           | 1.05e+03  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.29e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 393       |
|    time_elapsed         | 224951    |
|    total_timesteps      | 804864    |
| train/                  |           |
|    approx_kl            | 2.9021235 |
|    clip_fraction        | 0.453     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.62     |
|    explained_variance   | 0.00735   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.472     |
|    n_updates            | 3920      |
|    policy_gradient_loss | 0.0138    |
|    std                  | 0.511     |
|    value_loss           | 0.966     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.29e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 394        |
|    time_elapsed         | 225157     |
|    total_timesteps      | 806912     |
| train/                  |            |
|    approx_kl            | 0.39089173 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.59      |
|    explained_variance   | 0.265      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.606      |
|    n_updates            | 3930       |
|    policy_gradient_loss | 0.0325     |
|    std                  | 0.51       |
|    value_loss           | 1.07       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.3e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 395       |
|    time_elapsed         | 225362    |
|    total_timesteps      | 808960    |
| train/                  |           |
|    approx_kl            | 0.7866963 |
|    clip_fraction        | 0.392     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.58     |
|    explained_variance   | 0.431     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.312     |
|    n_updates            | 3940      |
|    policy_gradient_loss | 0.0395    |
|    std                  | 0.509     |
|    value_loss           | 0.659     |
---------------------------------------
Eval num_timesteps=810000, episode_reward=-99.81 +/- 0.02
Episode length: 3600.40 +/- 1.20
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 810000    |
| train/                  |           |
|    approx_kl            | 2.5210514 |
|    clip_fraction        | 0.439     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.58     |
|    explained_variance   | 0.333     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.229     |
|    n_updates            | 3950      |
|    policy_gradient_loss | 0.0305    |
|    std                  | 0.51      |
|    value_loss           | 0.657     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.29e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 396      |
|    time_elapsed    | 227370   |
|    total_timesteps | 811008   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 1.29e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 397       |
|    time_elapsed         | 227576    |
|    total_timesteps      | 813056    |
| train/                  |           |
|    approx_kl            | 0.1426557 |
|    clip_fraction        | 0.41      |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.59     |
|    explained_variance   | -0.000109 |
|    learning_rate        | 0.0003    |
|    loss                 | 504       |
|    n_updates            | 3960      |
|    policy_gradient_loss | 0.0122    |
|    std                  | 0.51      |
|    value_loss           | 1.05e+03  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.3e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 398       |
|    time_elapsed         | 227782    |
|    total_timesteps      | 815104    |
| train/                  |           |
|    approx_kl            | 1.9889672 |
|    clip_fraction        | 0.473     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.58     |
|    explained_variance   | 0.000789  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.405     |
|    n_updates            | 3970      |
|    policy_gradient_loss | 0.0156    |
|    std                  | 0.508     |
|    value_loss           | 0.972     |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.3e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 399       |
|    time_elapsed         | 227987    |
|    total_timesteps      | 817152    |
| train/                  |           |
|    approx_kl            | 1.6265097 |
|    clip_fraction        | 0.423     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.55     |
|    explained_variance   | 0.44      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.332     |
|    n_updates            | 3980      |
|    policy_gradient_loss | 0.0465    |
|    std                  | 0.508     |
|    value_loss           | 0.552     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.3e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 400        |
|    time_elapsed         | 228192     |
|    total_timesteps      | 819200     |
| train/                  |            |
|    approx_kl            | 0.28496638 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.56      |
|    explained_variance   | 0.372      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.38       |
|    n_updates            | 3990       |
|    policy_gradient_loss | 0.0464     |
|    std                  | 0.511      |
|    value_loss           | 0.743      |
----------------------------------------
Eval num_timesteps=820000, episode_reward=-99.84 +/- 0.04
Episode length: 3599.00 +/- 4.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 820000     |
| train/                  |            |
|    approx_kl            | 0.24546733 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.58      |
|    explained_variance   | 0.409      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.454      |
|    n_updates            | 4000       |
|    policy_gradient_loss | 0.0412     |
|    std                  | 0.511      |
|    value_loss           | 0.638      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.3e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 401      |
|    time_elapsed    | 230199   |
|    total_timesteps | 821248   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 1.3e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 402       |
|    time_elapsed         | 230404    |
|    total_timesteps      | 823296    |
| train/                  |           |
|    approx_kl            | 0.6342784 |
|    clip_fraction        | 0.483     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.57     |
|    explained_variance   | 0.0142    |
|    learning_rate        | 0.0003    |
|    loss                 | 354       |
|    n_updates            | 4010      |
|    policy_gradient_loss | 0.0242    |
|    std                  | 0.51      |
|    value_loss           | 1.05e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.31e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 403        |
|    time_elapsed         | 230609     |
|    total_timesteps      | 825344     |
| train/                  |            |
|    approx_kl            | 0.90570843 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.57      |
|    explained_variance   | 0.00464    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.364      |
|    n_updates            | 4020       |
|    policy_gradient_loss | 0.0205     |
|    std                  | 0.509      |
|    value_loss           | 0.719      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.31e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 404        |
|    time_elapsed         | 230815     |
|    total_timesteps      | 827392     |
| train/                  |            |
|    approx_kl            | 0.62879515 |
|    clip_fraction        | 0.454      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.53      |
|    explained_variance   | 0.357      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.443      |
|    n_updates            | 4030       |
|    policy_gradient_loss | 0.0333     |
|    std                  | 0.505      |
|    value_loss           | 0.854      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.31e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 405       |
|    time_elapsed         | 231021    |
|    total_timesteps      | 829440    |
| train/                  |           |
|    approx_kl            | 0.7212813 |
|    clip_fraction        | 0.417     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.45     |
|    explained_variance   | 0.545     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.232     |
|    n_updates            | 4040      |
|    policy_gradient_loss | 0.0272    |
|    std                  | 0.5       |
|    value_loss           | 0.537     |
---------------------------------------
Eval num_timesteps=830000, episode_reward=-99.85 +/- 0.03
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 830000    |
| train/                  |           |
|    approx_kl            | 0.5101292 |
|    clip_fraction        | 0.378     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.42     |
|    explained_variance   | 0.415     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.357     |
|    n_updates            | 4050      |
|    policy_gradient_loss | 0.0302    |
|    std                  | 0.5       |
|    value_loss           | 0.695     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.3e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 406      |
|    time_elapsed    | 233027   |
|    total_timesteps | 831488   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.3e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 407        |
|    time_elapsed         | 233232     |
|    total_timesteps      | 833536     |
| train/                  |            |
|    approx_kl            | 0.64455473 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.41      |
|    explained_variance   | -0.00189   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.96e+03   |
|    n_updates            | 4060       |
|    policy_gradient_loss | 0.00909    |
|    std                  | 0.499      |
|    value_loss           | 1.05e+03   |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 1.31e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 408      |
|    time_elapsed         | 233440   |
|    total_timesteps      | 835584   |
| train/                  |          |
|    approx_kl            | 4.943575 |
|    clip_fraction        | 0.428    |
|    clip_range           | 0.2      |
|    entropy_loss         | -5.39    |
|    explained_variance   | 0.00199  |
|    learning_rate        | 0.0003   |
|    loss                 | 0.532    |
|    n_updates            | 4070     |
|    policy_gradient_loss | 0.00786  |
|    std                  | 0.497    |
|    value_loss           | 1.2      |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.31e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 409        |
|    time_elapsed         | 233645     |
|    total_timesteps      | 837632     |
| train/                  |            |
|    approx_kl            | 0.57500774 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.35      |
|    explained_variance   | 0.403      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.311      |
|    n_updates            | 4080       |
|    policy_gradient_loss | 0.0188     |
|    std                  | 0.495      |
|    value_loss           | 0.813      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.31e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 410       |
|    time_elapsed         | 233851    |
|    total_timesteps      | 839680    |
| train/                  |           |
|    approx_kl            | 1.4746075 |
|    clip_fraction        | 0.399     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.31     |
|    explained_variance   | 0.502     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.416     |
|    n_updates            | 4090      |
|    policy_gradient_loss | 0.0274    |
|    std                  | 0.494     |
|    value_loss           | 0.726     |
---------------------------------------
Eval num_timesteps=840000, episode_reward=-99.84 +/- 0.04
Episode length: 3601.00 +/- 0.00
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 3.6e+03  |
|    mean_reward          | -99.8    |
| time/                   |          |
|    total_timesteps      | 840000   |
| train/                  |          |
|    approx_kl            | 1.134316 |
|    clip_fraction        | 0.335    |
|    clip_range           | 0.2      |
|    entropy_loss         | -5.31    |
|    explained_variance   | 0.394    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.47     |
|    n_updates            | 4100     |
|    policy_gradient_loss | 0.0153   |
|    std                  | 0.495    |
|    value_loss           | 0.888    |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.3e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 411      |
|    time_elapsed    | 235857   |
|    total_timesteps | 841728   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.32e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 412        |
|    time_elapsed         | 236062     |
|    total_timesteps      | 843776     |
| train/                  |            |
|    approx_kl            | 0.43791083 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.31      |
|    explained_variance   | 0.00242    |
|    learning_rate        | 0.0003     |
|    loss                 | 85         |
|    n_updates            | 4110       |
|    policy_gradient_loss | 0.0236     |
|    std                  | 0.496      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.32e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 413       |
|    time_elapsed         | 236268    |
|    total_timesteps      | 845824    |
| train/                  |           |
|    approx_kl            | 1.3121169 |
|    clip_fraction        | 0.403     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.34     |
|    explained_variance   | 0.735     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.65      |
|    n_updates            | 4120      |
|    policy_gradient_loss | 0.00553   |
|    std                  | 0.497     |
|    value_loss           | 1.58      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.32e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 414       |
|    time_elapsed         | 236473    |
|    total_timesteps      | 847872    |
| train/                  |           |
|    approx_kl            | 0.1544558 |
|    clip_fraction        | 0.375     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.32     |
|    explained_variance   | 0.442     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.322     |
|    n_updates            | 4130      |
|    policy_gradient_loss | 0.0219    |
|    std                  | 0.494     |
|    value_loss           | 0.749     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.32e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 415        |
|    time_elapsed         | 236681     |
|    total_timesteps      | 849920     |
| train/                  |            |
|    approx_kl            | 0.24283503 |
|    clip_fraction        | 0.346      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.3       |
|    explained_variance   | 0.74       |
|    learning_rate        | 0.0003     |
|    loss                 | 1.23       |
|    n_updates            | 4140       |
|    policy_gradient_loss | 0.0193     |
|    std                  | 0.494      |
|    value_loss           | 1.25       |
----------------------------------------
Eval num_timesteps=850000, episode_reward=-99.85 +/- 0.05
Episode length: 3598.20 +/- 5.60
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 850000    |
| train/                  |           |
|    approx_kl            | 1.1518344 |
|    clip_fraction        | 0.387     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.29     |
|    explained_variance   | 0.415     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.343     |
|    n_updates            | 4150      |
|    policy_gradient_loss | 0.0275    |
|    std                  | 0.494     |
|    value_loss           | 0.782     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.31e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 416      |
|    time_elapsed    | 238687   |
|    total_timesteps | 851968   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.32e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 417        |
|    time_elapsed         | 238892     |
|    total_timesteps      | 854016     |
| train/                  |            |
|    approx_kl            | 0.23528568 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.28      |
|    explained_variance   | -0.000716  |
|    learning_rate        | 0.0003     |
|    loss                 | 4.25e+03   |
|    n_updates            | 4160       |
|    policy_gradient_loss | 0.00858    |
|    std                  | 0.491      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.32e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 418       |
|    time_elapsed         | 239098    |
|    total_timesteps      | 856064    |
| train/                  |           |
|    approx_kl            | 1.1883838 |
|    clip_fraction        | 0.447     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.24     |
|    explained_variance   | 0.0044    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.293     |
|    n_updates            | 4170      |
|    policy_gradient_loss | 0.0447    |
|    std                  | 0.491     |
|    value_loss           | 0.762     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.32e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 419        |
|    time_elapsed         | 239304     |
|    total_timesteps      | 858112     |
| train/                  |            |
|    approx_kl            | 0.30069262 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.21      |
|    explained_variance   | 0.453      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.379      |
|    n_updates            | 4180       |
|    policy_gradient_loss | 0.0193     |
|    std                  | 0.488      |
|    value_loss           | 0.787      |
----------------------------------------
Eval num_timesteps=860000, episode_reward=-99.85 +/- 0.04
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 860000     |
| train/                  |            |
|    approx_kl            | 0.61735904 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.17      |
|    explained_variance   | 0.616      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.374      |
|    n_updates            | 4190       |
|    policy_gradient_loss | 0.00837    |
|    std                  | 0.487      |
|    value_loss           | 0.69       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.32e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 420      |
|    time_elapsed    | 241311   |
|    total_timesteps | 860160   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.32e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 421        |
|    time_elapsed         | 241517     |
|    total_timesteps      | 862208     |
| train/                  |            |
|    approx_kl            | 0.14273879 |
|    clip_fraction        | 0.266      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.16      |
|    explained_variance   | 0.00184    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.96e+03   |
|    n_updates            | 4200       |
|    policy_gradient_loss | -0.000578  |
|    std                  | 0.487      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.33e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 422       |
|    time_elapsed         | 241722    |
|    total_timesteps      | 864256    |
| train/                  |           |
|    approx_kl            | 3.1132216 |
|    clip_fraction        | 0.374     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.13     |
|    explained_variance   | 0.00506   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.434     |
|    n_updates            | 4210      |
|    policy_gradient_loss | 0.0155    |
|    std                  | 0.485     |
|    value_loss           | 0.842     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.33e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 423        |
|    time_elapsed         | 241927     |
|    total_timesteps      | 866304     |
| train/                  |            |
|    approx_kl            | 0.16609664 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.1       |
|    explained_variance   | 0.408      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.418      |
|    n_updates            | 4220       |
|    policy_gradient_loss | 0.0193     |
|    std                  | 0.485      |
|    value_loss           | 0.833      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.33e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 424        |
|    time_elapsed         | 242133     |
|    total_timesteps      | 868352     |
| train/                  |            |
|    approx_kl            | 0.44539878 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.06      |
|    explained_variance   | 0.495      |
|    learning_rate        | 0.0003     |
|    loss                 | 4.41       |
|    n_updates            | 4230       |
|    policy_gradient_loss | 0.0329     |
|    std                  | 0.481      |
|    value_loss           | 0.586      |
----------------------------------------
Eval num_timesteps=870000, episode_reward=-99.85 +/- 0.05
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 870000     |
| train/                  |            |
|    approx_kl            | 0.90059185 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.03      |
|    explained_variance   | 0.398      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.357      |
|    n_updates            | 4240       |
|    policy_gradient_loss | 0.0298     |
|    std                  | 0.48       |
|    value_loss           | 0.715      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.33e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 425      |
|    time_elapsed    | 244139   |
|    total_timesteps | 870400   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.33e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 426        |
|    time_elapsed         | 244344     |
|    total_timesteps      | 872448     |
| train/                  |            |
|    approx_kl            | 0.23880218 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.03      |
|    explained_variance   | 0.000602   |
|    learning_rate        | 0.0003     |
|    loss                 | 5.46       |
|    n_updates            | 4250       |
|    policy_gradient_loss | 0.0181     |
|    std                  | 0.483      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.34e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 427       |
|    time_elapsed         | 244550    |
|    total_timesteps      | 874496    |
| train/                  |           |
|    approx_kl            | 1.6140981 |
|    clip_fraction        | 0.45      |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.04     |
|    explained_variance   | 0.00798   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.572     |
|    n_updates            | 4260      |
|    policy_gradient_loss | 0.028     |
|    std                  | 0.482     |
|    value_loss           | 0.809     |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.34e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 428       |
|    time_elapsed         | 244755    |
|    total_timesteps      | 876544    |
| train/                  |           |
|    approx_kl            | 0.9983482 |
|    clip_fraction        | 0.396     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.02     |
|    explained_variance   | 0.515     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.267     |
|    n_updates            | 4270      |
|    policy_gradient_loss | 0.0225    |
|    std                  | 0.482     |
|    value_loss           | 0.77      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.34e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 429        |
|    time_elapsed         | 244961     |
|    total_timesteps      | 878592     |
| train/                  |            |
|    approx_kl            | 0.20325845 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5         |
|    explained_variance   | 0.501      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.203      |
|    n_updates            | 4280       |
|    policy_gradient_loss | 0.03       |
|    std                  | 0.482      |
|    value_loss           | 0.597      |
----------------------------------------
Eval num_timesteps=880000, episode_reward=-99.83 +/- 0.03
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 880000     |
| train/                  |            |
|    approx_kl            | 0.24206406 |
|    clip_fraction        | 0.329      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.97      |
|    explained_variance   | 0.521      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.261      |
|    n_updates            | 4290       |
|    policy_gradient_loss | 0.0122     |
|    std                  | 0.48       |
|    value_loss           | 0.574      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.33e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 430      |
|    time_elapsed    | 246967   |
|    total_timesteps | 880640   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.33e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 431        |
|    time_elapsed         | 247172     |
|    total_timesteps      | 882688     |
| train/                  |            |
|    approx_kl            | 0.15974589 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.96      |
|    explained_variance   | -0.000299  |
|    learning_rate        | 0.0003     |
|    loss                 | 898        |
|    n_updates            | 4300       |
|    policy_gradient_loss | 0.0118     |
|    std                  | 0.48       |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.34e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 432       |
|    time_elapsed         | 247377    |
|    total_timesteps      | 884736    |
| train/                  |           |
|    approx_kl            | 0.5317663 |
|    clip_fraction        | 0.402     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.95     |
|    explained_variance   | 0.00439   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.283     |
|    n_updates            | 4310      |
|    policy_gradient_loss | 0.0163    |
|    std                  | 0.478     |
|    value_loss           | 0.735     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.34e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 433        |
|    time_elapsed         | 247583     |
|    total_timesteps      | 886784     |
| train/                  |            |
|    approx_kl            | 0.22291136 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.91      |
|    explained_variance   | 0.406      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.283      |
|    n_updates            | 4320       |
|    policy_gradient_loss | 0.032      |
|    std                  | 0.475      |
|    value_loss           | 0.578      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.35e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 434       |
|    time_elapsed         | 247788    |
|    total_timesteps      | 888832    |
| train/                  |           |
|    approx_kl            | 1.3075448 |
|    clip_fraction        | 0.32      |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.87     |
|    explained_variance   | 0.506     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.376     |
|    n_updates            | 4330      |
|    policy_gradient_loss | 0.023     |
|    std                  | 0.474     |
|    value_loss           | 0.627     |
---------------------------------------
Eval num_timesteps=890000, episode_reward=-99.87 +/- 0.01
Episode length: 3597.20 +/- 7.11
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 890000    |
| train/                  |           |
|    approx_kl            | 0.4088378 |
|    clip_fraction        | 0.4       |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.83     |
|    explained_variance   | 0.605     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.249     |
|    n_updates            | 4340      |
|    policy_gradient_loss | 0.0175    |
|    std                  | 0.471     |
|    value_loss           | 0.631     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.34e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 435      |
|    time_elapsed    | 249795   |
|    total_timesteps | 890880   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 1.34e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 436       |
|    time_elapsed         | 250001    |
|    total_timesteps      | 892928    |
| train/                  |           |
|    approx_kl            | 0.6842328 |
|    clip_fraction        | 0.379     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.81     |
|    explained_variance   | 2.72e-05  |
|    learning_rate        | 0.0003    |
|    loss                 | 93.7      |
|    n_updates            | 4350      |
|    policy_gradient_loss | 0.0125    |
|    std                  | 0.471     |
|    value_loss           | 1.06e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.35e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 437        |
|    time_elapsed         | 250209     |
|    total_timesteps      | 894976     |
| train/                  |            |
|    approx_kl            | 0.45752293 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.83      |
|    explained_variance   | 0.000618   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.258      |
|    n_updates            | 4360       |
|    policy_gradient_loss | 0.0237     |
|    std                  | 0.473      |
|    value_loss           | 0.934      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.35e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 438       |
|    time_elapsed         | 250414    |
|    total_timesteps      | 897024    |
| train/                  |           |
|    approx_kl            | 0.5430317 |
|    clip_fraction        | 0.399     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.81     |
|    explained_variance   | 0.423     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.296     |
|    n_updates            | 4370      |
|    policy_gradient_loss | 0.0287    |
|    std                  | 0.472     |
|    value_loss           | 0.862     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.35e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 439        |
|    time_elapsed         | 250620     |
|    total_timesteps      | 899072     |
| train/                  |            |
|    approx_kl            | 0.24183455 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.78      |
|    explained_variance   | 0.464      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.281      |
|    n_updates            | 4380       |
|    policy_gradient_loss | 0.0936     |
|    std                  | 0.47       |
|    value_loss           | 0.708      |
----------------------------------------
Eval num_timesteps=900000, episode_reward=-99.87 +/- 0.04
Episode length: 3601.00 +/- 0.00
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 3.6e+03  |
|    mean_reward          | -99.9    |
| time/                   |          |
|    total_timesteps      | 900000   |
| train/                  |          |
|    approx_kl            | 1.107232 |
|    clip_fraction        | 0.424    |
|    clip_range           | 0.2      |
|    entropy_loss         | -4.78    |
|    explained_variance   | 0.238    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.516    |
|    n_updates            | 4390     |
|    policy_gradient_loss | 0.0311   |
|    std                  | 0.472    |
|    value_loss           | 1.47     |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.35e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 440      |
|    time_elapsed    | 252626   |
|    total_timesteps | 901120   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.35e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 441        |
|    time_elapsed         | 252831     |
|    total_timesteps      | 903168     |
| train/                  |            |
|    approx_kl            | 0.44992346 |
|    clip_fraction        | 0.436      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.8       |
|    explained_variance   | -0.000848  |
|    learning_rate        | 0.0003     |
|    loss                 | 18.7       |
|    n_updates            | 4400       |
|    policy_gradient_loss | 0.0138     |
|    std                  | 0.471      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.36e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 442       |
|    time_elapsed         | 253040    |
|    total_timesteps      | 905216    |
| train/                  |           |
|    approx_kl            | 1.8000677 |
|    clip_fraction        | 0.516     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.79     |
|    explained_variance   | 0.00153   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.448     |
|    n_updates            | 4410      |
|    policy_gradient_loss | 0.036     |
|    std                  | 0.471     |
|    value_loss           | 1.14      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.36e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 443        |
|    time_elapsed         | 253249     |
|    total_timesteps      | 907264     |
| train/                  |            |
|    approx_kl            | 0.89108974 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.79      |
|    explained_variance   | 0.331      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.517      |
|    n_updates            | 4420       |
|    policy_gradient_loss | 0.0377     |
|    std                  | 0.471      |
|    value_loss           | 1.3        |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.36e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 444       |
|    time_elapsed         | 253456    |
|    total_timesteps      | 909312    |
| train/                  |           |
|    approx_kl            | 0.6847367 |
|    clip_fraction        | 0.392     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.78     |
|    explained_variance   | 0.457     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.304     |
|    n_updates            | 4430      |
|    policy_gradient_loss | 0.0273    |
|    std                  | 0.47      |
|    value_loss           | 0.699     |
---------------------------------------
Eval num_timesteps=910000, episode_reward=-99.89 +/- 0.02
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 910000     |
| train/                  |            |
|    approx_kl            | 0.80552185 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.74      |
|    explained_variance   | 0.507      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.257      |
|    n_updates            | 4440       |
|    policy_gradient_loss | 0.0264     |
|    std                  | 0.468      |
|    value_loss           | 0.611      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.35e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 445      |
|    time_elapsed    | 255462   |
|    total_timesteps | 911360   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 1.35e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 446       |
|    time_elapsed         | 255668    |
|    total_timesteps      | 913408    |
| train/                  |           |
|    approx_kl            | 0.6019764 |
|    clip_fraction        | 0.442     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.71     |
|    explained_variance   | 0.000178  |
|    learning_rate        | 0.0003    |
|    loss                 | 2.75e+03  |
|    n_updates            | 4450      |
|    policy_gradient_loss | 0.00719   |
|    std                  | 0.467     |
|    value_loss           | 1.04e+03  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.36e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 447       |
|    time_elapsed         | 255874    |
|    total_timesteps      | 915456    |
| train/                  |           |
|    approx_kl            | 0.5960643 |
|    clip_fraction        | 0.394     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.67     |
|    explained_variance   | 0.402     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.333     |
|    n_updates            | 4460      |
|    policy_gradient_loss | 0.0201    |
|    std                  | 0.464     |
|    value_loss           | 0.654     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.37e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 448        |
|    time_elapsed         | 256079     |
|    total_timesteps      | 917504     |
| train/                  |            |
|    approx_kl            | 0.49471804 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.62      |
|    explained_variance   | 0.571      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.257      |
|    n_updates            | 4470       |
|    policy_gradient_loss | 0.0208     |
|    std                  | 0.462      |
|    value_loss           | 0.561      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.37e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 449        |
|    time_elapsed         | 256285     |
|    total_timesteps      | 919552     |
| train/                  |            |
|    approx_kl            | 0.11742912 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.61      |
|    explained_variance   | 0.49       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.315      |
|    n_updates            | 4480       |
|    policy_gradient_loss | 0.0216     |
|    std                  | 0.462      |
|    value_loss           | 0.634      |
----------------------------------------
Eval num_timesteps=920000, episode_reward=-99.82 +/- 0.03
Episode length: 3597.80 +/- 6.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 920000    |
| train/                  |           |
|    approx_kl            | 1.7321651 |
|    clip_fraction        | 0.396     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.59     |
|    explained_variance   | 0.51      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.271     |
|    n_updates            | 4490      |
|    policy_gradient_loss | 0.041     |
|    std                  | 0.461     |
|    value_loss           | 0.619     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.36e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 450      |
|    time_elapsed    | 258291   |
|    total_timesteps | 921600   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.37e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 451       |
|    time_elapsed         | 258498    |
|    total_timesteps      | 923648    |
| train/                  |           |
|    approx_kl            | 0.2891075 |
|    clip_fraction        | 0.365     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.58     |
|    explained_variance   | 0.000453  |
|    learning_rate        | 0.0003    |
|    loss                 | 4.48      |
|    n_updates            | 4500      |
|    policy_gradient_loss | 0.00564   |
|    std                  | 0.461     |
|    value_loss           | 1.05e+03  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.37e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 452       |
|    time_elapsed         | 258704    |
|    total_timesteps      | 925696    |
| train/                  |           |
|    approx_kl            | 1.8022684 |
|    clip_fraction        | 0.421     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.58     |
|    explained_variance   | 0.139     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.307     |
|    n_updates            | 4510      |
|    policy_gradient_loss | 0.0177    |
|    std                  | 0.461     |
|    value_loss           | 0.907     |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.37e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 453       |
|    time_elapsed         | 258909    |
|    total_timesteps      | 927744    |
| train/                  |           |
|    approx_kl            | 2.1349416 |
|    clip_fraction        | 0.41      |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.57     |
|    explained_variance   | 0.359     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.503     |
|    n_updates            | 4520      |
|    policy_gradient_loss | 0.0288    |
|    std                  | 0.461     |
|    value_loss           | 1         |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.37e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 454       |
|    time_elapsed         | 259115    |
|    total_timesteps      | 929792    |
| train/                  |           |
|    approx_kl            | 1.0718793 |
|    clip_fraction        | 0.395     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.56     |
|    explained_variance   | 0.487     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.494     |
|    n_updates            | 4530      |
|    policy_gradient_loss | 0.0371    |
|    std                  | 0.459     |
|    value_loss           | 0.681     |
---------------------------------------
Eval num_timesteps=930000, episode_reward=-99.86 +/- 0.04
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 930000    |
| train/                  |           |
|    approx_kl            | 0.5189483 |
|    clip_fraction        | 0.337     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.53     |
|    explained_variance   | 0.452     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.449     |
|    n_updates            | 4540      |
|    policy_gradient_loss | 0.0142    |
|    std                  | 0.458     |
|    value_loss           | 0.773     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.37e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 455      |
|    time_elapsed    | 261123   |
|    total_timesteps | 931840   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.38e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 456       |
|    time_elapsed         | 261328    |
|    total_timesteps      | 933888    |
| train/                  |           |
|    approx_kl            | 1.0897337 |
|    clip_fraction        | 0.327     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.51     |
|    explained_variance   | 0.00016   |
|    learning_rate        | 0.0003    |
|    loss                 | 4.95      |
|    n_updates            | 4550      |
|    policy_gradient_loss | 0.00679   |
|    std                  | 0.458     |
|    value_loss           | 1.05e+03  |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 1.38e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 457      |
|    time_elapsed         | 261533   |
|    total_timesteps      | 935936   |
| train/                  |          |
|    approx_kl            | 1.119082 |
|    clip_fraction        | 0.39     |
|    clip_range           | 0.2      |
|    entropy_loss         | -4.5     |
|    explained_variance   | 0.923    |
|    learning_rate        | 0.0003   |
|    loss                 | 1.79     |
|    n_updates            | 4560     |
|    policy_gradient_loss | 0.000823 |
|    std                  | 0.455    |
|    value_loss           | 3.08     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.38e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 458       |
|    time_elapsed         | 261739    |
|    total_timesteps      | 937984    |
| train/                  |           |
|    approx_kl            | 0.2466808 |
|    clip_fraction        | 0.475     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.46     |
|    explained_variance   | 0.365     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.316     |
|    n_updates            | 4570      |
|    policy_gradient_loss | 0.0219    |
|    std                  | 0.454     |
|    value_loss           | 0.859     |
---------------------------------------
Eval num_timesteps=940000, episode_reward=-99.86 +/- 0.02
Episode length: 3599.40 +/- 3.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 940000     |
| train/                  |            |
|    approx_kl            | 0.65527236 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.44      |
|    explained_variance   | 0.443      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.283      |
|    n_updates            | 4580       |
|    policy_gradient_loss | 0.0219     |
|    std                  | 0.453      |
|    value_loss           | 0.668      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.37e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 459      |
|    time_elapsed    | 263745   |
|    total_timesteps | 940032   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 1.37e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 460       |
|    time_elapsed         | 263951    |
|    total_timesteps      | 942080    |
| train/                  |           |
|    approx_kl            | 0.1293284 |
|    clip_fraction        | 0.363     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.42     |
|    explained_variance   | 0.000842  |
|    learning_rate        | 0.0003    |
|    loss                 | 133       |
|    n_updates            | 4590      |
|    policy_gradient_loss | 0.00762   |
|    std                  | 0.453     |
|    value_loss           | 1.05e+03  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.38e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 461       |
|    time_elapsed         | 264156    |
|    total_timesteps      | 944128    |
| train/                  |           |
|    approx_kl            | 2.1849768 |
|    clip_fraction        | 0.405     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.39     |
|    explained_variance   | -1.62     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.367     |
|    n_updates            | 4600      |
|    policy_gradient_loss | 0.0253    |
|    std                  | 0.451     |
|    value_loss           | 0.915     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.38e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 462        |
|    time_elapsed         | 264362     |
|    total_timesteps      | 946176     |
| train/                  |            |
|    approx_kl            | 0.18364301 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.38      |
|    explained_variance   | 0.0621     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.593      |
|    n_updates            | 4610       |
|    policy_gradient_loss | 0.0196     |
|    std                  | 0.45       |
|    value_loss           | 3.45       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.39e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 463       |
|    time_elapsed         | 264568    |
|    total_timesteps      | 948224    |
| train/                  |           |
|    approx_kl            | 0.5628443 |
|    clip_fraction        | 0.398     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.34     |
|    explained_variance   | 0.0926    |
|    learning_rate        | 0.0003    |
|    loss                 | 1.36      |
|    n_updates            | 4620      |
|    policy_gradient_loss | 0.0203    |
|    std                  | 0.447     |
|    value_loss           | 3.15      |
---------------------------------------
Eval num_timesteps=950000, episode_reward=-99.91 +/- 0.04
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 950000     |
| train/                  |            |
|    approx_kl            | 0.59208685 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.31      |
|    explained_variance   | 0.4        |
|    learning_rate        | 0.0003     |
|    loss                 | 0.279      |
|    n_updates            | 4630       |
|    policy_gradient_loss | 0.0258     |
|    std                  | 0.446      |
|    value_loss           | 0.94       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.38e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 464      |
|    time_elapsed    | 266574   |
|    total_timesteps | 950272   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.38e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 465        |
|    time_elapsed         | 266779     |
|    total_timesteps      | 952320     |
| train/                  |            |
|    approx_kl            | 0.24402334 |
|    clip_fraction        | 0.248      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.31      |
|    explained_variance   | 0.0225     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.19e+03   |
|    n_updates            | 4640       |
|    policy_gradient_loss | -0.00199   |
|    std                  | 0.446      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.39e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 466        |
|    time_elapsed         | 266985     |
|    total_timesteps      | 954368     |
| train/                  |            |
|    approx_kl            | 0.41957816 |
|    clip_fraction        | 0.287      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.29      |
|    explained_variance   | 0.348      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.354      |
|    n_updates            | 4650       |
|    policy_gradient_loss | 0.0187     |
|    std                  | 0.445      |
|    value_loss           | 0.67       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.39e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 467       |
|    time_elapsed         | 267193    |
|    total_timesteps      | 956416    |
| train/                  |           |
|    approx_kl            | 0.9812236 |
|    clip_fraction        | 0.416     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.28     |
|    explained_variance   | 0.449     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.272     |
|    n_updates            | 4660      |
|    policy_gradient_loss | 0.0349    |
|    std                  | 0.446     |
|    value_loss           | 0.731     |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.39e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 468       |
|    time_elapsed         | 267399    |
|    total_timesteps      | 958464    |
| train/                  |           |
|    approx_kl            | 0.2573032 |
|    clip_fraction        | 0.38      |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.28     |
|    explained_variance   | 0.192     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.976     |
|    n_updates            | 4670      |
|    policy_gradient_loss | 0.0153    |
|    std                  | 0.445     |
|    value_loss           | 1.86      |
---------------------------------------
Eval num_timesteps=960000, episode_reward=-99.84 +/- 0.06
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 960000    |
| train/                  |           |
|    approx_kl            | 2.3331184 |
|    clip_fraction        | 0.398     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.27     |
|    explained_variance   | 0.457     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.376     |
|    n_updates            | 4680      |
|    policy_gradient_loss | 0.0251    |
|    std                  | 0.445     |
|    value_loss           | 0.776     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.39e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 469      |
|    time_elapsed    | 269405   |
|    total_timesteps | 960512   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.39e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 470        |
|    time_elapsed         | 269610     |
|    total_timesteps      | 962560     |
| train/                  |            |
|    approx_kl            | 0.70284545 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.26      |
|    explained_variance   | 0.00191    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.07e+03   |
|    n_updates            | 4690       |
|    policy_gradient_loss | 0.0181     |
|    std                  | 0.444      |
|    value_loss           | 1.04e+03   |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 1.4e+03  |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 471      |
|    time_elapsed         | 269816   |
|    total_timesteps      | 964608   |
| train/                  |          |
|    approx_kl            | 0.350428 |
|    clip_fraction        | 0.418    |
|    clip_range           | 0.2      |
|    entropy_loss         | -4.25    |
|    explained_variance   | 0.00284  |
|    learning_rate        | 0.0003   |
|    loss                 | 0.39     |
|    n_updates            | 4700     |
|    policy_gradient_loss | 0.0243   |
|    std                  | 0.444    |
|    value_loss           | 0.867    |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.4e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 472       |
|    time_elapsed         | 270021    |
|    total_timesteps      | 966656    |
| train/                  |           |
|    approx_kl            | 1.7032163 |
|    clip_fraction        | 0.405     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.23     |
|    explained_variance   | 0.531     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.378     |
|    n_updates            | 4710      |
|    policy_gradient_loss | 0.0133    |
|    std                  | 0.444     |
|    value_loss           | 1.5       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.4e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 473        |
|    time_elapsed         | 270227     |
|    total_timesteps      | 968704     |
| train/                  |            |
|    approx_kl            | 0.28813055 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.22      |
|    explained_variance   | 0.539      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.385      |
|    n_updates            | 4720       |
|    policy_gradient_loss | 0.025      |
|    std                  | 0.444      |
|    value_loss           | 0.586      |
----------------------------------------
Eval num_timesteps=970000, episode_reward=-99.83 +/- 0.03
Episode length: 3600.40 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 970000     |
| train/                  |            |
|    approx_kl            | 0.12061628 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.21      |
|    explained_variance   | -0.254     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.254      |
|    n_updates            | 4730       |
|    policy_gradient_loss | 0.00718    |
|    std                  | 0.442      |
|    value_loss           | 0.976      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.39e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 474      |
|    time_elapsed    | 272234   |
|    total_timesteps | 970752   |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.33e+03 |
|    ep_rew_mean          | 1.39e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 475      |
|    time_elapsed         | 272440   |
|    total_timesteps      | 972800   |
| train/                  |          |
|    approx_kl            | 2.553483 |
|    clip_fraction        | 0.469    |
|    clip_range           | 0.2      |
|    entropy_loss         | -4.2     |
|    explained_variance   | 0.000297 |
|    learning_rate        | 0.0003   |
|    loss                 | 11.1     |
|    n_updates            | 4740     |
|    policy_gradient_loss | 0.0191   |
|    std                  | 0.443    |
|    value_loss           | 1.04e+03 |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.41e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 476       |
|    time_elapsed         | 272645    |
|    total_timesteps      | 974848    |
| train/                  |           |
|    approx_kl            | 3.0133755 |
|    clip_fraction        | 0.465     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.21     |
|    explained_variance   | 0.000454  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.265     |
|    n_updates            | 4750      |
|    policy_gradient_loss | 0.0246    |
|    std                  | 0.442     |
|    value_loss           | 0.841     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.41e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 477        |
|    time_elapsed         | 272851     |
|    total_timesteps      | 976896     |
| train/                  |            |
|    approx_kl            | 0.09928325 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.19      |
|    explained_variance   | 0.607      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.536      |
|    n_updates            | 4760       |
|    policy_gradient_loss | 0.0117     |
|    std                  | 0.441      |
|    value_loss           | 0.773      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.41e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 478       |
|    time_elapsed         | 273056    |
|    total_timesteps      | 978944    |
| train/                  |           |
|    approx_kl            | 0.6756805 |
|    clip_fraction        | 0.387     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.19     |
|    explained_variance   | 0.518     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.374     |
|    n_updates            | 4770      |
|    policy_gradient_loss | 0.0292    |
|    std                  | 0.442     |
|    value_loss           | 0.655     |
---------------------------------------
Eval num_timesteps=980000, episode_reward=-99.83 +/- 0.03
Episode length: 3600.40 +/- 1.20
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 980000    |
| train/                  |           |
|    approx_kl            | 0.5108501 |
|    clip_fraction        | 0.365     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.19     |
|    explained_variance   | 0.583     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.36      |
|    n_updates            | 4780      |
|    policy_gradient_loss | 0.0208    |
|    std                  | 0.439     |
|    value_loss           | 0.571     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.41e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 479      |
|    time_elapsed    | 275063   |
|    total_timesteps | 980992   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.41e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 480         |
|    time_elapsed         | 275268      |
|    total_timesteps      | 983040      |
| train/                  |             |
|    approx_kl            | 0.058745794 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.17       |
|    explained_variance   | -0.000918   |
|    learning_rate        | 0.0003      |
|    loss                 | 12.9        |
|    n_updates            | 4790        |
|    policy_gradient_loss | 0.00204     |
|    std                  | 0.439       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.42e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 481       |
|    time_elapsed         | 275474    |
|    total_timesteps      | 985088    |
| train/                  |           |
|    approx_kl            | 3.3710623 |
|    clip_fraction        | 0.403     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.15     |
|    explained_variance   | 0.00692   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.211     |
|    n_updates            | 4800      |
|    policy_gradient_loss | 0.0172    |
|    std                  | 0.437     |
|    value_loss           | 0.658     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.42e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 482        |
|    time_elapsed         | 275680     |
|    total_timesteps      | 987136     |
| train/                  |            |
|    approx_kl            | 0.42511702 |
|    clip_fraction        | 0.335      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.12      |
|    explained_variance   | 0.641      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.398      |
|    n_updates            | 4810       |
|    policy_gradient_loss | 0.02       |
|    std                  | 0.435      |
|    value_loss           | 0.568      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.42e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 483       |
|    time_elapsed         | 275886    |
|    total_timesteps      | 989184    |
| train/                  |           |
|    approx_kl            | 1.5446413 |
|    clip_fraction        | 0.432     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.09     |
|    explained_variance   | 0.54      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.29      |
|    n_updates            | 4820      |
|    policy_gradient_loss | 0.032     |
|    std                  | 0.433     |
|    value_loss           | 0.542     |
---------------------------------------
Eval num_timesteps=990000, episode_reward=-99.85 +/- 0.05
Episode length: 3600.80 +/- 0.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 990000    |
| train/                  |           |
|    approx_kl            | 1.4824054 |
|    clip_fraction        | 0.397     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.08     |
|    explained_variance   | 0.552     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.379     |
|    n_updates            | 4830      |
|    policy_gradient_loss | 0.0167    |
|    std                  | 0.432     |
|    value_loss           | 0.794     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.41e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 484      |
|    time_elapsed    | 277892   |
|    total_timesteps | 991232   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 1.41e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 485       |
|    time_elapsed         | 278097    |
|    total_timesteps      | 993280    |
| train/                  |           |
|    approx_kl            | 1.1695347 |
|    clip_fraction        | 0.356     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.07     |
|    explained_variance   | 0.000594  |
|    learning_rate        | 0.0003    |
|    loss                 | 6.85      |
|    n_updates            | 4840      |
|    policy_gradient_loss | 0.0122    |
|    std                  | 0.431     |
|    value_loss           | 1.05e+03  |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 1.42e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 486      |
|    time_elapsed         | 278303   |
|    total_timesteps      | 995328   |
| train/                  |          |
|    approx_kl            | 6.506958 |
|    clip_fraction        | 0.417    |
|    clip_range           | 0.2      |
|    entropy_loss         | -4.05    |
|    explained_variance   | 0.0679   |
|    learning_rate        | 0.0003   |
|    loss                 | 0.212    |
|    n_updates            | 4850     |
|    policy_gradient_loss | 0.0219   |
|    std                  | 0.431    |
|    value_loss           | 0.564    |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.43e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 487       |
|    time_elapsed         | 278509    |
|    total_timesteps      | 997376    |
| train/                  |           |
|    approx_kl            | 1.3258388 |
|    clip_fraction        | 0.423     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.02     |
|    explained_variance   | 0.509     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.245     |
|    n_updates            | 4860      |
|    policy_gradient_loss | 0.0418    |
|    std                  | 0.429     |
|    value_loss           | 0.597     |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.43e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 488       |
|    time_elapsed         | 278716    |
|    total_timesteps      | 999424    |
| train/                  |           |
|    approx_kl            | 0.7986903 |
|    clip_fraction        | 0.41      |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.99     |
|    explained_variance   | 0.525     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.279     |
|    n_updates            | 4870      |
|    policy_gradient_loss | 0.0316    |
|    std                  | 0.428     |
|    value_loss           | 0.574     |
---------------------------------------
Eval num_timesteps=1000000, episode_reward=-99.85 +/- 0.04
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 1000000    |
| train/                  |            |
|    approx_kl            | 0.15396595 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.97      |
|    explained_variance   | 0.54       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.325      |
|    n_updates            | 4880       |
|    policy_gradient_loss | 0.0158     |
|    std                  | 0.427      |
|    value_loss           | 0.601      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.42e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 489      |
|    time_elapsed    | 280723   |
|    total_timesteps | 1001472  |
---------------------------------
Plot saved as src/FM3_MicRo/control_models/2025-01-21_22-07-43_llm_triton_qwen_7b_continuous_rewards_1_example_explanation_1000000-steps_5-obs_ep-time-360.0/r_ratio_plot.png
 100% ━━━━━━━━━━━━━━━━ 1,001,472/1,000,… [ 3 days, 5:56:08 < 0:00:00 , 10 it/s ]

Detailed evaluation data:
Timesteps (shape=(100,)): [  10000   20000   30000   40000   50000   60000   70000   80000   90000
  100000  110000  120000  130000  140000  150000  160000  170000  180000
  190000  200000  210000  220000  230000  240000  250000  260000  270000
  280000  290000  300000  310000  320000  330000  340000  350000  360000
  370000  380000  390000  400000  410000  420000  430000  440000  450000
  460000  470000  480000  490000  500000  510000  520000  530000  540000
  550000  560000  570000  580000  590000  600000  610000  620000  630000
  640000  650000  660000  670000  680000  690000  700000  710000  720000
  730000  740000  750000  760000  770000  780000  790000  800000  810000
  820000  830000  840000  850000  860000  870000  880000  890000  900000
  910000  920000  930000  940000  950000  960000  970000  980000  990000
 1000000]
Results (shape=(100, 5)):
[[ -99.997243  -99.962446 -100.016927  -99.923096  -99.945098]
 [-100.003134 -100.031418 -100.032766 -100.043871 -100.059425]
 [-100.058947 -100.005311  -99.993381  -99.96134  -100.023833]
 [-100.061715 -100.065962 -100.017477  -99.95682   -99.979594]
 [ -99.881394 -100.03204   -99.964212  -99.973051  -99.899418]
 [ -99.966738  -99.663753  -99.664832  -99.972219  -99.873914]
 [ -99.879213  -99.980419  -99.897244  -99.842999  -99.863522]
 [ -99.881072  -99.972288  -99.893525  -99.894078  -99.977518]
 [ -99.910133  -99.970159  -99.994213  -99.752405  -99.903651]
 [ -99.934876  -99.871055  -99.993113  -99.975972  -99.998398]
 [ -99.985829  -99.992704  -99.89347   -99.83996   -99.803249]
 [ -99.929577  -99.919851  -99.900172  -99.945083  -99.829083]
 [ -99.919142  -99.912735  -99.887212  -99.882345  -99.980123]
 [ -99.800727 -100.03746   -99.996891  -99.866701 -100.074199]
 [ -99.974056 -100.076078 -100.058876  -99.938419  -99.997155]
 [ -99.810225  -99.973087 -100.065996  -99.89069  -100.071695]
 [ -99.912326  -99.926969  -99.868584  -99.951579  -99.84454 ]
 [ -99.965861  -99.87911   -99.832669  -99.857047  -99.916761]
 [ -99.91241   -99.880281  -99.868731  -99.865874  -99.923948]
 [ -99.958376  -99.900674  -99.935484  -99.972202  -99.893207]
 [-100.016329  -99.934853  -99.947306  -99.954248  -99.908451]
 [ -99.965014  -99.902119  -99.958493 -100.001679  -99.899455]
 [ -99.991367  -99.908805  -99.873848  -99.976064  -99.978912]
 [ -99.963469  -99.894314  -99.938135  -99.953966  -99.984532]
 [ -99.906035  -99.919735  -99.920118  -99.953707  -99.870701]
 [ -99.855705  -99.865919  -99.928925  -99.987869  -99.844485]
 [ -99.977503  -99.853094  -99.865105  -99.970719  -99.934265]
 [ -99.931377  -99.875571  -99.839296  -99.957333  -99.782701]
 [ -99.831534  -99.778015  -99.900789  -99.887446  -99.924079]
 [ -99.897136  -99.834876  -99.836635  -99.895073  -99.875898]
 [ -99.850051  -99.862229  -99.815973  -99.849477  -99.954649]
 [ -99.843225  -99.852075  -99.927584  -99.877761  -99.846724]
 [ -99.864655  -99.908184  -99.796412  -99.909003  -99.825798]
 [ -99.913552  -99.954441  -99.862718  -99.848537  -99.872616]
 [ -99.913078  -99.819781  -99.76578   -99.812514  -99.796274]
 [ -99.748388  -99.84456   -99.835705  -99.898287  -99.841054]
 [ -99.83851   -99.7925    -99.866307  -99.79811   -99.787657]
 [ -99.848912  -99.814814  -99.877886  -99.899454  -99.801425]
 [ -99.84277   -99.830096  -99.768886  -99.784542  -99.894833]
 [ -99.837355  -99.780946  -99.834358  -99.853531  -99.773813]
 [ -99.780952  -99.843954  -99.702902  -99.779466  -99.896646]
 [ -99.872529  -99.775511  -99.834761  -99.862456  -99.825768]
 [ -99.74519   -99.871765  -99.73138   -99.763487  -99.827832]
 [ -99.895604  -99.822289  -99.815449  -99.865038  -99.884757]
 [ -99.816882  -99.829175  -99.82614   -99.852813  -99.886455]
 [ -99.863718  -99.875926  -99.888155  -99.895393  -99.871843]
 [ -99.922429  -99.902112  -99.800763  -99.885676  -99.673344]
 [ -99.854562  -99.900419  -99.877678  -99.806304  -99.81482 ]
 [ -99.855994  -99.902477  -99.760359  -99.817161  -99.859748]
 [ -99.848027  -99.842291  -99.846316  -99.784691  -99.778307]
 [ -99.632377  -99.733482  -99.867563  -99.881819  -99.753811]
 [ -99.815582  -99.761262  -99.802004  -99.867223  -99.903868]
 [ -99.884028  -99.799824  -99.755543  -99.727254  -99.780061]
 [ -99.812508  -99.694034  -99.872884  -99.759049  -99.857597]
 [ -99.790219  -99.785389  -99.665276  -99.680632  -99.782869]
 [ -99.841866  -99.86257   -99.899466  -99.871785  -99.898637]
 [ -99.882213  -99.863908  -99.821472  -99.872863  -99.894537]
 [ -99.90266   -99.759329  -99.846422  -99.774757  -99.871253]
 [ -99.844765  -99.857854  -99.756718  -99.832422  -99.854221]
 [ -99.768772  -99.85056   -99.895331  -99.881085  -99.918718]
 [ -99.802747  -99.857384  -99.884648  -99.831268  -99.929025]
 [ -99.798899  -99.770149  -99.776052  -99.851073  -99.799963]
 [ -99.836866  -99.748106  -99.872088  -99.802086  -99.793592]
 [ -99.784239  -99.841497  -99.811028  -99.85981   -99.82341 ]
 [ -99.825371  -99.829468  -99.881889  -99.897012  -99.892875]
 [ -99.762838  -99.885843  -99.787304  -99.894506  -99.892353]
 [ -99.8014    -99.807602  -99.903     -99.853204  -99.860785]
 [ -99.86318   -99.788551  -99.892007  -99.890561  -99.799438]
 [ -99.850567  -99.828094  -99.796954  -99.886289  -99.774222]
 [ -99.853978  -99.878973  -99.798673  -99.815331  -99.826636]
 [ -99.866526  -99.898299  -99.873681  -99.842857  -99.843534]
 [ -99.843503  -99.797194  -99.821052  -99.810281  -99.857409]
 [ -99.889437  -99.852823  -99.84962   -99.816209  -99.77619 ]
 [ -99.935865  -99.799059  -99.807127  -99.79461   -99.789183]
 [ -99.859804  -99.857561  -99.894483  -99.805075  -99.909045]
 [ -99.88168   -99.827463  -99.819702  -99.816672  -99.692306]
 [ -99.772318  -99.849228  -99.899157  -99.772671  -99.797035]
 [ -99.903089  -99.698419  -99.793644  -99.701336  -99.797314]
 [ -99.882859  -99.803892  -99.901498  -99.834247  -99.778465]
 [ -99.800035  -99.835986  -99.882272  -99.896593  -99.83748 ]
 [ -99.792927  -99.802635  -99.815144  -99.839872  -99.813168]
 [ -99.818593  -99.828846  -99.890693  -99.78495   -99.859968]
 [ -99.822783  -99.864738  -99.866249  -99.798073  -99.88077 ]
 [ -99.904057  -99.80161   -99.801246  -99.836772  -99.858345]
 [ -99.829719  -99.915086  -99.777968  -99.854245  -99.869917]
 [ -99.861729  -99.885112  -99.786957  -99.813151  -99.899621]
 [ -99.805696  -99.903002  -99.802936  -99.905578  -99.811227]
 [ -99.830523  -99.870798  -99.805009  -99.86723   -99.782431]
 [ -99.885235  -99.851859  -99.866388  -99.883153  -99.870387]
 [ -99.902945  -99.851402  -99.916443  -99.801675  -99.895256]
 [ -99.894422  -99.881985  -99.86856   -99.898633  -99.920316]
 [ -99.802031  -99.807552  -99.835594  -99.882891  -99.791428]
 [ -99.825507  -99.899074  -99.890744  -99.809579  -99.862648]
 [ -99.842287  -99.847207  -99.832908  -99.892649  -99.869465]
 [ -99.867165  -99.870733  -99.948411  -99.953158  -99.88841 ]
 [ -99.785192  -99.805733  -99.954789  -99.874502  -99.797295]
 [ -99.837594  -99.83351   -99.878607  -99.821598  -99.791921]
 [ -99.866566  -99.782411  -99.812573  -99.859212  -99.816342]
 [ -99.887947  -99.792752  -99.917277  -99.796343  -99.877706]
 [ -99.794278  -99.840386  -99.916305  -99.836064  -99.851683]]
Episode Lengths (shape=(100, 5)):
[[3600 3601 3601 3601 3601]
 [3601 3601 3601 3600 3601]
 [3600 3601 3601 3584 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3599]
 [3601 3601 3601 3601 3584]
 [3601 3601 3601 3601 3601]
 [3582 3601 3600 3601 3601]
 [3601 3601 3601 3601 3584]
 [3601 3601 3601 3601 3601]
 [3580 3598 3601 3601 3601]
 [3601 3601 3601 3587 3597]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3584 3598 3601 3601]
 [3598 3601 3601 3601 3584]
 [3601 3601 3601 3601 3601]
 [3583 3601 3601 3601 3601]
 [3599 3601 3601 3599 3585]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3598 3601 3583 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3600 3595]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3600 3601 3601 3583]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3593 3601 3601 3601 3583]
 [3601 3601 3601 3601 3601]
 [3582 3601 3601 3601 3601]
 [3601 3601 3601 3601 3596]
 [3601 3599 3601 3601 3601]
 [3601 3601 3601 3601 3598]
 [3601 3601 3601 3599 3584]
 [3601 3601 3601 3601 3601]
 [3580 3601 3601 3601 3601]
 [3601 3599 3601 3588 3601]
 [3601 3601 3601 3601 3598]
 [3598 3598 3601 3601 3601]
 [3601 3583 3601 3601 3601]
 [3598 3601 3601 3601 3587]
 [3601 3601 3601 3601 3601]
 [3588 3601 3601 3601 3601]
 [3597 3598 3601 3601 3578]
 [3601 3601 3601 3601 3598]
 [3576 3601 3601 3601 3601]
 [3601 3601 3601 3583 3601]
 [3601 3601 3599 3601 3601]
 [3598 3601 3601 3601 3601]
 [3601 3579 3601 3601 3601]
 [3601 3601 3601 3601 3598]
 [3576 3601 3601 3601 3600]
 [3601 3601 3601 3588 3601]
 [3601 3601 3599 3601 3601]
 [3597 3601 3601 3601 3601]
 [3601 3584 3601 3601 3601]
 [3601 3599 3601 3601 3584]
 [3601 3601 3601 3601 3598]
 [3585 3601 3601 3598 3601]
 [3601 3601 3601 3601 3595]
 [3598 3601 3601 3601 3601]
 [3584 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3580 3601 3601 3601 3601]
 [3601 3601 3601 3589 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3599 3601 3601 3601]
 [3601 3601 3601 3601 3587]
 [3599 3601 3601 3601 3601]
 [3598 3601 3601 3601 3601]
 [3601 3601 3601 3591 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3587 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3600 3601 3601 3583 3601]
 [3601 3601 3601 3601 3601]
 [3599 3601 3601 3601 3601]
 [3601 3601 3585 3601 3601]
 [3601 3601 3601 3601 3601]
 [3593 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3600 3599 3601]
 [3601 3601 3601 3598 3601]
 [3601 3601 3601 3600 3601]
 [3601 3601 3601 3601 3598]]
Time Elapsed: Not available
Plot saved to /scratch/work/sattaru1/FM3-MicRo/src/FM3_MicRo/control_models/2025-01-21_22-07-43_llm_triton_qwen_7b_continuous_rewards_1_example_explanation_1000000-steps_5-obs_ep-time-360.0/rewards_plot.png
Model saved as src/FM3_MicRo/control_models/2025-01-21_22-07-43_llm_triton_qwen_7b_continuous_rewards_1_example_explanation_1000000-steps_5-obs_ep-time-360.0/model
